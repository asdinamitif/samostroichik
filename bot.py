import os
import re
import logging
import mimetypes
import hashlib
from pathlib import Path

URL_RE = re.compile(r"(https?://[^\s)\]\">]+)", re.IGNORECASE)


def extract_urls(*values: str) -> list[str]:
    urls: list[str] = []
    for v in values:
        if not v:
            continue
        s = str(v)
        for m in URL_RE.findall(s):
            u = m.strip().rstrip(".,;")
            if u not in urls:
                urls.append(u)
    return urls

def _token_for_url(url: str) -> str:
    return hashlib.sha1(url.encode("utf-8")).hexdigest()[:10]

def register_url(url: str, name_hint: str = "") -> str:
    t = _token_for_url(url)
    if t not in FILE_TOKEN_MAP:
        FILE_TOKEN_MAP[t] = {"url": url, "name": name_hint or ""}
    return t

def _guess_filename(url: str, fallback: str = "file") -> str:
    try:
        from urllib.parse import urlparse, unquote
        p = urlparse(url)
        seg = unquote(p.path.split("/")[-1])
        if seg and "." in seg:
            return seg
    except Exception:
        pass
    return fallback

def download_external_file(url: str) -> tuple[bytes, str, str]:
    """–°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª –ø–æ URL. –õ–∏–º–∏—Ç –ø–æ —Ä–∞–∑–º–µ—Ä—É: MAX_FILE_MB."""
    headers = {"User-Agent": "Mozilla/5.0 (compatible; SOTBot/1.0)"}
    r = requests.get(url, headers=headers, timeout=90, allow_redirects=True)
    r.raise_for_status()
    content = r.content
    size_mb = len(content) / (1024 * 1024)
    if size_mb > MAX_FILE_MB:
        raise RuntimeError(f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π: {size_mb:.1f} MB (–ª–∏–º–∏—Ç {MAX_FILE_MB} MB)")
    fname = None
    cd = r.headers.get("content-disposition", "")
    m = re.search(r"filename\*=UTF-8''([^;]+)|filename=\"([^\"]+)\"|filename=([^;]+)", cd, flags=re.I)
    if m:
        fname = (m.group(1) or m.group(2) or m.group(3) or "").strip()
    fname = fname or _guess_filename(url, "document")
    mime = r.headers.get("content-type", "") or mimetypes.guess_type(fname)[0] or "application/octet-stream"
    return content, fname, mime

def analyze_file_bytes(data: bytes, filename: str, mime: str) -> str:
    """–õ—ë–≥–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ: PDF/DOCX/TXT."""
    fn = filename.lower()
    if fn.endswith(".pdf") or "pdf" in (mime or ""):
        try:
            import PyPDF2
            from io import BytesIO
            reader = PyPDF2.PdfReader(BytesIO(data))
            text_parts = []
            for page in reader.pages[:10]:
                t = page.extract_text() or ""
                if t.strip():
                    text_parts.append(t)
            text = "\n".join(text_parts).strip()
            if not text:
                return "PDF –∑–∞–≥—Ä—É–∂–µ–Ω, –Ω–æ —Ç–µ–∫—Å—Ç –Ω–µ –∏–∑–≤–ª–µ–∫–∞–µ—Ç—Å—è (–≤–æ–∑–º–æ–∂–Ω–æ, —Å–∫–∞–Ω)."
            lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
            return "–ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (—Ñ—Ä–∞–≥–º–µ–Ω—Ç):\n" + "\n".join(lines[:60])
        except Exception as e:
            return f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–æ–±—Ä–∞—Ç—å PDF: {e}"

    if fn.endswith(".docx") or "wordprocessingml" in (mime or ""):
        try:
            from io import BytesIO
            import docx
            doc = docx.Document(BytesIO(data))
            paras = [p.text.strip() for p in doc.paragraphs if p.text and p.text.strip()]
            if not paras:
                return "DOCX –∑–∞–≥—Ä—É–∂–µ–Ω, –Ω–æ —Ç–µ–∫—Å—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."
            return "–¢–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ (—Ñ—Ä–∞–≥–º–µ–Ω—Ç):\n" + "\n".join(paras[:80])
        except Exception as e:
            return f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–æ–±—Ä–∞—Ç—å DOCX: {e}"

    if fn.endswith(".txt") or (mime or "").startswith("text/"):
        try:
            text = data.decode("utf-8", errors="ignore")
            lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
            return "–¢–µ–∫—Å—Ç (—Ñ—Ä–∞–≥–º–µ–Ω—Ç):\n" + "\n".join(lines[:120])
        except Exception as e:
            return f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–æ–±—Ä–∞—Ç—å —Ç–µ–∫—Å—Ç: {e}"

    return "–§–∞–π–ª —Å–∫–∞—á–∞–Ω. –ê–≤—Ç–æ‚Äë–∞–Ω–∞–ª–∏–∑ –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è PDF/DOCX/TXT. –ú–æ–≥—É –ø—Ä–∏—Å–ª–∞—Ç—å —Ñ–∞–π–ª –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞."


import sqlite3
from datetime import datetime, timedelta, date
from io import BytesIO
from typing import Optional, Dict, Any, List, Tuple

import json
import requests
import pandas as pd
from openpyxl import load_workbook  # for reading xlsx with hyperlinks
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
from dotenv import load_dotenv

import base64

# -------------------------------------------------
# YANDEX CLOUD (YandexGPT + SpeechKit) ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç
# -------------------------------------------------
def _get_env_any(*names: str) -> str:
    for n in names:
        v = os.getenv(n)
        if v is None:
            continue
        v = str(v).strip().strip('"').strip("'")
        if v:
            return v
    return ""

# –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –¥–≤–∞ –Ω–µ–π–º–∏–Ω–≥–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö (—Å—Ç–∞—Ä—ã–π YAGPT_* –∏ –Ω–æ–≤—ã–π YANDEX_*)
YANDEX_FOLDER_ID = _get_env_any("YANDEX_FOLDER_ID", "YAGPT_FOLDER_ID")
YANDEX_API_KEY = _get_env_any("YANDEX_API_KEY", "YAGPT_API_KEY")


ENABLE_ASSISTANT = os.getenv("ENABLE_ASSISTANT", "1").strip() == "1"
ENABLE_ASSISTANT_VOICE_REPLY = os.getenv("ENABLE_ASSISTANT_VOICE_REPLY", "1").strip() == "1"

logger = logging.getLogger(__name__)
logger.info("[YANDEX] folder_id_set=%s api_key_set=%s folder_id=%s",
            bool(YANDEX_FOLDER_ID), bool(YANDEX_API_KEY),
            (YANDEX_FOLDER_ID[:6] + "..." + YANDEX_FOLDER_ID[-4:]) if YANDEX_FOLDER_ID else "")

# Google Sheet –¥–ª—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî —Ç–æ, —á—Ç–æ –≤—ã –¥–∞–ª–∏)
CONSULT_SHEET_URL = os.getenv(
    "CONSULT_SHEET_URL",
    "https://docs.google.com/spreadsheets/d/1W_9Cs-LaX6KR4cE9xN71CliE6Lm_TyQqk8t3kQa4FCc/edit?gid=967461758",
).strip()

def _extract_spreadsheet_id_from_url(url: str) -> str:
    if not url:
        return ""
    m = re.search(r"/d/([a-zA-Z0-9-_]+)", url)
    return m.group(1) if m else ""

def _extract_gid_from_url(url: str) -> str:
    if not url:
        return ""
    m = re.search(r"[?&]gid=(\d+)", url)
    return m.group(1) if m else ""

CONSULT_SHEET_ID = os.getenv("CONSULT_SHEET_ID", _extract_spreadsheet_id_from_url(CONSULT_SHEET_URL)).strip()
CONSULT_SHEET_GID = os.getenv("CONSULT_SHEET_GID", _extract_gid_from_url(CONSULT_SHEET_URL)).strip()

CONSULT_SHEET_CACHE_TTL_SEC = int(os.getenv("CONSULT_SHEET_CACHE_TTL_SEC", "600"))
CONSULT_SHEET_CACHE_PATH = os.getenv("CONSULT_SHEET_CACHE_PATH", "consult_sheet_cache.xlsx").strip()

# ==== FILE LINKS (download/analyze) ====
FILES_CACHE_DIR = Path(os.getenv('FILES_CACHE_DIR', '/data/files_cache')).resolve()
FILES_CACHE_DIR.mkdir(parents=True, exist_ok=True)
MAX_FILE_MB = int(os.getenv('MAX_FILE_MB', '25'))
FILE_TOKEN_MAP = {}  # token -> {'url':..., 'name':...}


def _now_ts() -> float:
    return datetime.utcnow().timestamp()

def download_google_sheet_xlsx(spreadsheet_id: str, gid: str, out_path: str) -> None:
    """
    –°–∫–∞—á–∏–≤–∞–µ—Ç Google Sheet –∫–∞–∫ XLSX —á–µ—Ä–µ–∑ export. –î–ª—è –ø—É–±–ª–∏—á–Ω—ã—Ö/–¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø–æ —Å—Å—ã–ª–∫–µ —Ç–∞–±–ª–∏—Ü.
    """
    if not spreadsheet_id:
        raise ValueError("CONSULT_SHEET_ID –ø—É—Å—Ç–æ–π")
    url = f"https://docs.google.com/spreadsheets/d/{spreadsheet_id}/export?format=xlsx"
    if gid:
        url += f"&gid={gid}"
    r = requests.get(url, timeout=60)
    r.raise_for_status()
    Path(out_path).write_bytes(r.content)

def get_consult_df() -> pd.DataFrame:
    """
    –ö—ç—à–∏—Ä—É–µ–º XLSX –ª–æ–∫–∞–ª—å–Ω–æ, —á—Ç–æ–±—ã –Ω–µ –¥—ë—Ä–≥–∞—Ç—å Google –Ω–∞ –∫–∞–∂–¥—ã–π –≤–æ–ø—Ä–æ—Å.
    """
    cache = Path(CONSULT_SHEET_CACHE_PATH)
    meta = cache.with_suffix(".meta.json")
    use_cache = False
    if cache.exists() and meta.exists():
        try:
            m = json.loads(meta.read_text(encoding="utf-8"))
            ts = float(m.get("ts", 0))
            if _now_ts() - ts < CONSULT_SHEET_CACHE_TTL_SEC:
                use_cache = True
        except Exception:
            use_cache = False

    if not use_cache:
        download_google_sheet_xlsx(CONSULT_SHEET_ID, CONSULT_SHEET_GID, str(cache))
        meta.write_text(json.dumps({"ts": _now_ts()}, ensure_ascii=False), encoding="utf-8")

    # —á–∏—Ç–∞–µ–º –ø–µ—Ä–≤—ã–π –ª–∏—Å—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    return pd.read_excel(cache, sheet_name=0)

CASE_NO_RE = re.compile(r"\b\d{2}[-\s]?\d{2}[-\s]?\d{6}\b")

def normalize_case_no(s: str) -> Optional[str]:
    """
    –ü—Ä–∏–≤–æ–¥–∏—Ç –Ω–æ–º–µ—Ä –¥–µ–ª–∞ –∫ —Ñ–æ—Ä–º–∞—Ç—É 00-00-000000.

    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤–∞—Ä–∏–∞–Ω—Ç—ã:
    - '03-46-108600'
    - '03 46 108600'
    - '03 46 108 600'
    - '0 3 4 6 1 0 8 6 0 0' (STT —á–∞—Å—Ç–æ —Ç–∞–∫ –æ—Ç–¥–∞—ë—Ç)
    """
    if not s:
        return None
    s = str(s).strip()
    if not s:
        return None

    # 1) –ò—â–µ–º —É–∂–µ –ø–æ—Ö–æ–∂–∏–π –Ω–∞ –Ω–æ–º–µ—Ä –¥–µ–ª–∞ —à–∞–±–ª–æ–Ω (—Å –¥–µ—Ñ–∏—Å–∞–º–∏/–ø—Ä–æ–±–µ–ª–∞–º–∏)
    m = CASE_NO_RE.search(s.replace("‚Äî", "-").replace("‚Äì", "-"))
    if m:
        return f"{m.group(1)}-{m.group(2)}-{m.group(3)}"

    # 2) –§–æ–ª–±—ç–∫: –≤—ã—Ç–∞—Å–∫–∏–≤–∞–µ–º —Ü–∏—Ñ—Ä—ã –∏ –ø—Ä–æ–±—É–µ–º —Å–æ–±—Ä–∞—Ç—å 2-2-6
    digits = re.sub(r"\D+", "", s)
    if len(digits) == 10:
        return f"{digits[0:2]}-{digits[2:4]}-{digits[4:10]}"

    # –ò–Ω–æ–≥–¥–∞ –≤ —Ç–µ–∫—Å—Ç–µ –º–æ–≥—É—Ç –±—ã—Ç—å –ª–∏—à–Ω–∏–µ —Ü–∏—Ñ—Ä—ã (–¥–∞—Ç—ã –∏ —Ç.–ø.) ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ 10-–∑–Ω–∞—á–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç
    if len(digits) > 10:
        for i in range(0, len(digits) - 9):
            cand = digits[i:i+10]
            # –ø—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –ø–µ—Ä–≤—ã–µ 4 —Å–∏–º–≤–æ–ª–∞ ‚Äî —ç—Ç–æ –¥–≤–µ –≥—Ä—É–ø–ø—ã –ø–æ 2 —Ü–∏—Ñ—Ä—ã
            if re.match(r"^\d{10}$", cand):
                return f"{cand[0:2]}-{cand[2:4]}-{cand[4:10]}"

    return None
def safe_text(v) -> str:
    if v is None:
        return ""
    if isinstance(v, float) and pd.isna(v):
        return ""
    return str(v).strip()

def _yn_contains(val: str, target: str) -> bool:
    return target.lower() in safe_text(val).lower()

def _is_yes(val: str) -> bool:
    v = safe_text(val).lower()
    return v in ("–¥–∞", "—É—Å—Ç—Ä–∞–Ω–µ–Ω–æ", "true", "1", "yes", "y")

def _is_no(val: str) -> bool:
    v = safe_text(val).lower()
    return v in ("–Ω–µ—Ç", "–Ω–µ —É—Å—Ç—Ä–∞–Ω–µ–Ω–æ", "false", "0", "no", "n")

def find_case_rows(df: pd.DataFrame, case_no: str) -> pd.DataFrame:
    # –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∫–æ–ª–æ–Ω–∫—É "–ù–æ–º–µ—Ä –¥–µ–ª–∞" –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º, –∏–Ω–∞—á–µ –∏—â–µ–º –ø–æ –≤—Å–µ–º –∫–æ–ª–æ–Ω–∫–∞–º
    headers = [safe_text(c) for c in df.columns]
    idx_case = None
    for i, h in enumerate(headers):
        if "–Ω–æ–º–µ—Ä" in h.lower() and "–¥–µ–ª" in h.lower():
            idx_case = i
            break
    if idx_case is not None:
        col = df.columns[idx_case]
        mask = df[col].astype(str).str.contains(case_no, na=False)
        out = df[mask].copy()
        if len(out) > 0:
            return out

    # fallback: –ø–æ –≤—Å–µ–º —è—á–µ–π–∫–∞–º
    mask_any = df.astype(str).apply(lambda row: row.str.contains(case_no, na=False)).any(axis=1)
    return df[mask_any].copy()

def pb_status_for_case(df: pd.DataFrame, case_no: str) -> Dict[str, Any]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –ø–æ –ü–ë.
    –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –Ω–∞–π—Ç–∏ –∫–æ–ª–æ–Ω–∫–∏ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º (–ø–æ–∂–∞—Ä/–ø–±), –∏–Ω–∞—á–µ fallback –Ω–∞ Q/R (–∫–∞–∫ –≤ –≤–∞—à–µ–π –ª–æ–≥–∏–∫–µ).
    """
    rows = find_case_rows(df, case_no)
    if rows.empty:
        return {"found": False, "case_no": case_no, "status": "NOT_FOUND"}

    headers = [safe_text(c) for c in df.columns]
    # –ø–æ–∏—Å–∫ –∫–æ–ª–æ–Ω–æ–∫ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º
    pb_cols = []
    for i, h in enumerate(headers):
        hl = h.lower()
        if ("–ø–æ–∂–∞—Ä" in hl) or (hl.startswith("–ø–±")) or ("–ø–±" in hl and "–æ—Ç–º–µ—Ç" in hl):
            pb_cols.append(i)

    # fallback –Ω–∞ Q/R (–∏–Ω–¥–µ–∫—Å—ã 16/17) –µ—Å–ª–∏ –∫–æ–ª–æ–Ω–æ–∫ –º–∞–ª–æ/–Ω–µ –Ω–∞—à–ª–∏
    if not pb_cols:
        # Q=17-—è –∫–æ–ª–æ–Ω–∫–∞ (–∏–Ω–¥–µ–∫—Å 16), R=18-—è (–∏–Ω–¥–µ–∫—Å 17)
        if len(headers) >= 18:
            pb_cols = [16, 17]

    if not pb_cols:
        return {"found": True, "case_no": case_no, "status": "NO_PB_COLUMNS", "details": {}}

    yes_seen = False
    no_seen = False
    details = {}
    for ci in pb_cols:
        colname = df.columns[ci]
        vals = [safe_text(v) for v in rows[colname].tolist()]
        details[safe_text(colname) or f"col_{ci}"] = vals
        for v in vals:
            if _is_no(v):
                no_seen = True
            if _is_yes(v):
                yes_seen = True

    if no_seen:
        st = "NOT_FIXED"
    elif yes_seen:
        st = "FIXED"
    else:
        st = "NO_DATA"

    return {"found": True, "case_no": case_no, "status": st, "details": details}

def retrieve_relevant_rows(df: pd.DataFrame, question: str, max_rows: int = 12) -> str:
    """
    –ü—Ä–æ—Å—Ç–∞—è retrieval-—Å—Ç—Ä–∞—Ç–µ–≥–∏—è: —Å—á–∏—Ç–∞–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –ø–æ —Å—Ç—Ä–æ–∫–∞–º,
    –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (–∑–∞–≥–æ–ª–æ–≤–∫–∏ + —Ç–æ–ø —Å—Ç—Ä–æ–∫).
    """
    q = safe_text(question)
    tokens = [t for t in re.split(r"[\s,;:.!?()]+", q.lower()) if len(t) >= 3]
    if not tokens:
        tokens = [q.lower()] if q else []

    def score_row(row) -> int:
        s = " ".join([safe_text(x).lower() for x in row.values])
        return sum(1 for t in tokens if t in s)

    scored = []
    for i, row in df.iterrows():
        sc = score_row(row)
        if sc > 0:
            scored.append((sc, i))
    scored.sort(reverse=True)

    top_idx = [i for _, i in scored[:max_rows]]
    top = df.loc[top_idx] if top_idx else df.head(min(max_rows, len(df)))

    # –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
    cols = list(df.columns)
    header = " | ".join([safe_text(c) for c in cols])
    lines = [header]
    for _, r in top.iterrows():
        lines.append(" | ".join([safe_text(r[c]) for c in cols]))
    return "\n".join(lines[: max_rows + 1])

def yandex_chat_completion(system: str, user: str, temperature: float = 0.1, max_tokens: int = 800) -> str:
    """
    Yandex Cloud Foundation Models (YandexGPT) completion.

    –í–∞–∂–Ω–æ: —É Yandex Cloud –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ñ–æ—Ä–º–∞—Ç payload —Å modelUri –∏ messages[text],
    –∞ endpoint –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç OpenAI.
    """
    if not YANDEX_API_KEY or not YANDEX_FOLDER_ID:
        raise RuntimeError("YANDEX_API_KEY / YANDEX_FOLDER_ID –Ω–µ –∑–∞–¥–∞–Ω—ã")
    url = "https://llm.api.cloud.yandex.net/foundationModels/v1/completion"
    headers = {
        "Authorization": f"Api-Key {YANDEX_API_KEY}",
        "Content-Type": "application/json",
        "x-folder-id": YANDEX_FOLDER_ID,
    }
    model_uri = os.getenv("YAGPT_MODEL") or f"gpt://{YANDEX_FOLDER_ID}/yandexgpt/latest"
    payload = {
        "modelUri": model_uri,
        "completionOptions": {
            "stream": False,
            "temperature": float(temperature),
            "maxTokens": int(max_tokens),
        },
        "messages": [
            {"role": "system", "text": system},
            {"role": "user", "text": user},
        ],
    }
    r = requests.post(url, headers=headers, json=payload, timeout=90)
    r.raise_for_status()
    data = r.json()
    # –æ–∂–∏–¥–∞–µ–º—ã–π –æ—Ç–≤–µ—Ç: result.alternatives[0].message.text
    try:
        return safe_text(data["result"]["alternatives"][0]["message"]["text"]).strip()
    except Exception:
        # –Ω–∞ —Å–ª—É—á–∞–π –≤–∞—Ä–∏–∞—Ü–∏–π –æ—Ç–≤–µ—Ç–∞
        return safe_text(json.dumps(data, ensure_ascii=False))[:4000]

def yandex_speech_to_text(ogg_bytes: bytes) -> str:
    if not YANDEX_API_KEY or not YANDEX_FOLDER_ID:
        raise RuntimeError("YANDEX_API_KEY / YANDEX_FOLDER_ID –Ω–µ –∑–∞–¥–∞–Ω—ã")
    url = "https://stt.api.cloud.yandex.net/speech/v1/stt:recognize"
    headers = {
        "Authorization": f"Api-Key {YANDEX_API_KEY}",
        "Content-Type": "application/octet-stream",
        "x-folder-id": YANDEX_FOLDER_ID,
    }
    params = {
        "folderId": YANDEX_FOLDER_ID,
        "lang": "ru-RU",
        "format": "oggopus",
    }
    r = requests.post(url, headers=headers, params=params, data=ogg_bytes, timeout=90, allow_redirects=False)
    r.raise_for_status()
    data = r.json()
    return safe_text(data.get("result", "")).strip()

def yandex_text_to_speech(text_in: str) -> bytes:
    if not YANDEX_API_KEY or not YANDEX_FOLDER_ID:
        raise RuntimeError("YANDEX_API_KEY / YANDEX_FOLDER_ID –Ω–µ –∑–∞–¥–∞–Ω—ã")
    url = "https://tts.api.cloud.yandex.net/speech/v1/tts:synthesize"
    headers = {"Authorization": f"Api-Key {YANDEX_API_KEY}", "Content-Type": "application/octet-stream"}
    params = {
        "folderId": YANDEX_FOLDER_ID,
        "text": text_in,
        "lang": "ru-RU",
        "voice": "alena",
        "format": "oggopus",
        "speed": "1.0",
    }
    r = requests.post(url, headers=headers, data=params, timeout=90)
def _find_case_no_in_text(text: str) -> Optional[str]:
    # —Å–Ω–∞—á–∞–ª–∞ ‚Äî –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ –æ–±—â–∏–π –ø–∞—Ä—Å–µ—Ä
    cn = normalize_case_no(text or "")
    if cn:
        return cn
    return None

# -------------------------------------------------
# Assistant: query parsing, normalization, export, snapshots
# -------------------------------------------------
SECTION_SYNONYMS = {
    "–ü–ë": ["–ø–±", "–ø–æ–∂–∞—Ä", "–ø–æ–∂–∞—Ä–∫–∞", "–ø–æ–∂–∞—Ä–Ω–æ–π", "–ø–æ–∂–∞—Ä–Ω–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å", "–ø–æ–∂–∞—Ä–Ω–∞—è"],
    "–ê–†": ["–∞—Ä", "–∞—Ä—Ö", "–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞", "–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä", "–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π"],
    "–ú–ú–ì–ù": ["–º–º–≥–Ω", "–º–≥–Ω", "–º–∞–ª–æ–º–æ–±–∏–ª—å–Ω", "–¥–æ—Å—Ç—É–ø –∏–Ω–≤–∞–ª–∏–¥", "–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å", "–∏–Ω–≤–∞–ª–∏–¥"],
    "–ê–ì–û": ["–∞–≥–æ", "–æ–±–ª–∏–∫", "–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π –æ–±–ª–∏–∫", "–∞—Ä—Ö –æ–±–ª–∏–∫"],
    "–≠–û–ú": ["—ç–æ–º", "—ç–ª–µ–∫—Ç—Ä–æ", "—ç–ª–µ–∫—Ç—Ä–æ—Å–Ω–∞–±–∂", "—ç–ª–µ–∫—Ç—Ä–∏–∫–∞"],
}

def _canon_section(text: str) -> Optional[str]:
    t = (text or "").lower()
    for canon, syns in SECTION_SYNONYMS.items():
        for s in syns:
            if s in t:
                return canon
    return None

def _find_case_no_in_text(text: str) -> Optional[str]:
    return extract_case_number(text)

def _col_by_keywords(df: pd.DataFrame, keywords: List[str]) -> Optional[str]:
    cols = list(df.columns)
    low = [str(c).strip().lower() for c in cols]
    for kw in keywords:
        kwl = kw.lower()
        for i, c in enumerate(low):
            if kwl in c:
                return cols[i]
    return None

def _status_columns(df: pd.DataFrame) -> Dict[str, str]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞–ø–ø–∏–Ω–≥ canonical_section -> column_name (–µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–∞)
    –ü–æ–∏—Å–∫ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º. –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ ‚Äì –æ—Å—Ç–∞–≤–ª—è–µ–º –ø—É—Å—Ç–æ.
    """
    m: Dict[str, str] = {}
    for canon, syns in SECTION_SYNONYMS.items():
        col = _col_by_keywords(df, [canon.lower()] + syns)
        if col:
            m[canon] = col
    return m

def _is_negative_status(v: str) -> bool:
    s = safe_text(v).strip().lower()
    if not s:
        return False
    negatives = ["–Ω–µ—Ç", "–Ω–µ —É—Å—Ç—Ä–∞–Ω", "–Ω–µ —É—Å—Ç—Ä–∞–Ω–µ–Ω–æ", "–Ω–µ –≤—ã–ø–æ–ª–Ω", "–Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ", "0", "false", "‚ùå"]
    return any(n in s for n in negatives)

def _is_positive_status(v: str) -> bool:
    s = safe_text(v).strip().lower()
    if not s:
        return False
    positives = ["–¥–∞", "—É—Å—Ç—Ä–∞–Ω", "—É—Å—Ç—Ä–∞–Ω–µ–Ω–æ", "–≤—ã–ø–æ–ª–Ω", "–≤—ã–ø–æ–ª–Ω–µ–Ω–æ", "1", "true", "‚úÖ"]
    return any(p in s for p in positives) and not _is_negative_status(s)

def _universal_search(df: pd.DataFrame, query: str, limit: int = 30) -> pd.DataFrame:
    q = (query or "").strip()
    if not q:
        return df.head(0)
    ql = q.lower()
    mask = pd.Series([False] * len(df))
    for c in df.columns:
        try:
            mask = mask | df[c].astype(str).str.lower().str.contains(re.escape(ql), na=False)
        except Exception:
            continue
    return df[mask].head(limit)

def _df_case_card(df: pd.DataFrame, case_no: str) -> pd.DataFrame:
    if not case_no:
        return df.head(0)
    # –∏—â–µ–º –ø–æ –≤—Å–µ–º –∫–æ–ª–æ–Ω–∫–∞–º, –Ω–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞ –∫–æ–ª–æ–Ω–∫—É "–Ω–æ–º–µ—Ä –¥–µ–ª–∞"
    col_case = _col_by_keywords(df, ["–Ω–æ–º–µ—Ä –¥–µ–ª–∞", "–¥–µ–ª–æ", "‚Ññ –¥–µ–ª–∞", "–Ω–æ–º–µ—Ä"])
    if col_case:
        d = df[df[col_case].astype(str).str.contains(re.escape(case_no), na=False)]
        if len(d) > 0:
            return d.head(1)
    # fallback ‚Äì —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º –ø–æ–ª—è–º
    d2 = _universal_search(df, case_no, limit=1)
    return d2

def _df_not_fixed(df: pd.DataFrame, section: Optional[str] = None, limit: int = 50) -> pd.DataFrame:
    cols_map = _status_columns(df)
    if section and section in cols_map:
        col = cols_map[section]
        m = df[col].apply(_is_negative_status)
        return df[m].head(limit)
    # –µ—Å–ª–∏ —Ä–∞–∑–¥–µ–ª –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω ‚Äî –∏—â–µ–º –ª—é–±—ã–µ "–Ω–µ—Ç" –ø–æ –≤—Å–µ–º –∫–æ–ª–æ–Ω–∫–∞–º —Å—Ç–∞—Ç—É—Å–æ–≤
    status_cols = list(cols_map.values())
    if not status_cols:
        return df.head(0)
    mask = pd.Series([False] * len(df))
    for c in status_cols:
        mask = mask | df[c].apply(_is_negative_status)
    return df[mask].head(limit)

def _key_fields(df: pd.DataFrame) -> Dict[str, Optional[str]]:
    return {
        "case": _col_by_keywords(df, ["–Ω–æ–º–µ—Ä –¥–µ–ª–∞", "–¥–µ–ª–æ", "‚Ññ –¥–µ–ª–∞", "–Ω–æ–º–µ—Ä"]),
        "address": _col_by_keywords(df, ["–∞–¥—Ä–µ—Å", "–º–µ—Å—Ç–æ–ø–æ–ª–æ–∂", "—Ä–∞—Å–ø–æ–ª–æ–∂", "–ª–æ–∫–∞—Ü"]),
        "developer": _col_by_keywords(df, ["–∑–∞—Å—Ç—Ä–æ–π", "–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü", "–æ–æ–æ", "–∞–æ", "–∏–ø"]),
        "object": _col_by_keywords(df, ["–æ–±—ä–µ–∫—Ç", "–Ω–∞–∏–º–µ–Ω", "–Ω–∞–∑–≤–∞–Ω–∏–µ"]),
    }

def _completeness_report(df: pd.DataFrame, limit: int = 80) -> pd.DataFrame:
    cols = _key_fields(df)
    status_cols = list(_status_columns(df).values())
    def is_empty(x) -> bool:
        s = safe_text(x).strip()
        return (not s) or s.lower() in ["nan", "none", "-", "‚Äî"]
    mask = pd.Series([False] * len(df))
    for k in ["case", "address", "developer", "object"]:
        c = cols.get(k)
        if c:
            mask = mask | df[c].apply(is_empty)
    for c in status_cols:
        mask = mask | df[c].apply(is_empty)
    return df[mask].head(limit)

def _hash_row(row: pd.Series) -> str:
    s = "|".join([safe_text(row.get(c)) for c in row.index])
    return hashlib.sha256(s.encode("utf-8", errors="ignore")).hexdigest()

def _snap_dir() -> Path:
    base = Path(DATA_DIR) if DATA_DIR else Path(".")
    d = base / "assistant_snapshots"
    d.mkdir(parents=True, exist_ok=True)
    return d

def save_snapshot(df: pd.DataFrame) -> Path:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–Ω–∏–º–æ–∫ —Ç–∞–±–ª–∏—Ü—ã (—Ö—ç—à–∏ —Å—Ç—Ä–æ–∫) –Ω–∞ —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É.
    """
    cols = _key_fields(df)
    col_case = cols.get("case")
    snap = {}
    for _, row in df.iterrows():
        key = safe_text(row.get(col_case)) if col_case else ""
        key = extract_case_number(key) or safe_text(row.get(col_case)) or ""
        if not key:
            continue
        snap[key] = {"h": _hash_row(row)}
    p = _snap_dir() / f"{datetime.utcnow().date().isoformat()}.json"
    p.write_text(json.dumps({"ts": _now_ts(), "data": snap}, ensure_ascii=False), encoding="utf-8")
    return p

def _load_snapshot_near(days_ago: int = 7) -> Optional[dict]:
    target = (datetime.utcnow().date() - timedelta(days=days_ago))
    d = _snap_dir()
    if not d.exists():
        return None
    files = sorted(d.glob("*.json"))
    if not files:
        return None
    # –≤—ã–±–∏—Ä–∞–µ–º —Ñ–∞–π–ª —Å –¥–∞—Ç–æ–π –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –±–ª–∏–∑–∫–æ –∫ target (–Ω–µ –ø–æ–∑–∂–µ target)
    best = None
    best_date = None
    for f in files:
        try:
            dt = datetime.strptime(f.stem, "%Y-%m-%d").date()
        except Exception:
            continue
        if dt <= target and (best_date is None or dt > best_date):
            best = f; best_date = dt
    if best is None:
        # fallback ‚Äì —Å–∞–º—ã–π —Ä–∞–Ω–Ω–∏–π –¥–æ—Å—Ç—É–ø–Ω—ã–π
        best = files[0]
    try:
        return json.loads(best.read_text(encoding="utf-8"))
    except Exception:
        return None

def diff_week(df: pd.DataFrame) -> Dict[str, List[str]]:
    """
    –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å —Å–Ω–∏–º–∫–æ–º ~7 –¥–Ω–µ–π –Ω–∞–∑–∞–¥.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–∫–∏: new, removed, changed (case numbers).
    """
    prev = _load_snapshot_near(7)
    if not prev:
        # –µ—Å–ª–∏ –Ω–µ—Ç —Å–Ω–∏–º–∫–æ–≤ ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–π –∏ –≥–æ–≤–æ—Ä–∏–º, —á—Ç–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ –ø–æ–∑–∂–µ
        save_snapshot(df)
        return {"new": [], "removed": [], "changed": [], "note": ["–°–Ω–∏–º–æ–∫ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å–æ–∑–¥–∞–Ω. –ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ –Ω–µ–¥–µ–ª—é."]}
    prev_data = prev.get("data", {}) or {}
    cols = _key_fields(df)
    col_case = cols.get("case")
    cur = {}
    for _, row in df.iterrows():
        key = safe_text(row.get(col_case)) if col_case else ""
        key = extract_case_number(key) or safe_text(row.get(col_case)) or ""
        if not key:
            continue
        cur[key] = {"h": _hash_row(row)}
    new = sorted([k for k in cur.keys() if k not in prev_data])
    removed = sorted([k for k in prev_data.keys() if k not in cur])
    changed = sorted([k for k in cur.keys() if k in prev_data and cur[k]["h"] != prev_data[k].get("h")])
    # —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–π —Å–Ω–∏–º–æ–∫ –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ
    save_snapshot(df)
    return {"new": new, "removed": removed, "changed": changed, "note": []}

def df_to_file_bytes(df: pd.DataFrame, fmt: str = "xlsx") -> Tuple[BytesIO, str]:
    fmt = (fmt or "xlsx").lower()
    bio = BytesIO()
    if fmt == "csv":
        df.to_csv(bio, index=False, encoding="utf-8-sig")
        name = "export.csv"
    else:
        with pd.ExcelWriter(bio, engine="openpyxl") as w:
            df.to_excel(w, index=False, sheet_name="export")
        name = "export.xlsx"
    bio.seek(0)
    bio.name = name
    return bio, name

async def assistant_answer(chat, context, question_text: str, recognized_from_voice: bool = False):
    """
    –ì–ª–∞–≤–Ω–∞—è —Ç–æ—á–∫–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞: –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä –ü–ë) + –æ–±—â–∏–π Q&A –ø–æ —Ç–∞–±–ª–∏—Ü–µ.
    """
    q = safe_text(question_text)
    if recognized_from_voice:
        await chat.send_message(f"üéô –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {q}")

    if not q:
        await chat.send_message("–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∑–∞–ø—Ä–æ—Å. –ü–æ–≤—Ç–æ—Ä–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞.")
        return

    # –±—ã—Å—Ç—Ä—ã–π –≤—ã—Ö–æ–¥
    if q.lower() in ("–≤—ã—Ö–æ–¥", "—Å—Ç–æ–ø", "–Ω–∞–∑–∞–¥"):
        context.user_data["assistant_mode"] = False
        await chat.send_message("–†–µ–∂–∏–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –≤—ã–∫–ª—é—á–µ–Ω.", reply_markup=main_menu())
        return

        # 1) –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –ø–æ —Ç–∞–±–ª–∏—Ü–µ (–ø–æ–∏—Å–∫/–∫–∞—Ä—Ç–æ—á–∫–∞/—Å—Ç–∞—Ç—É—Å—ã/–≤—ã–≥—Ä—É–∑–∫–∞/–∫–æ–Ω—Ç—Ä–æ–ª—å –ø–æ–ª–Ω–æ—Ç—ã/–∏–∑–º–µ–Ω–µ–Ω–∏—è)
        ql = q.lower()

        export_requested = any(w in ql for w in ["–≤—ã–≥—Ä—É–∑", "—ç–∫—Å–ø–æ—Ä—Ç", "csv", "excel", "xlsx", "—Ñ–∞–π–ª", "–ø—Ä–∏—à–ª–∏ —Ñ–∞–π–ª–æ–º", "—Å—Ñ–æ—Ä–º–∏—Ä—É–π"])
        export_fmt = "csv" if "csv" in ql else "xlsx"

        completeness_requested = any(w in ql for w in ["–ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã", "–ø–æ–ª–Ω–æ—Ç–∞", "–ø—É—Å—Ç—ã–µ –ø–æ–ª—è", "–Ω–µ –∑–∞–ø–æ–ª–Ω", "–ø—É—Å—Ç–æ –≤", "–ø—É—Å—Ç—ã–µ"])
        diff_requested = ("—á—Ç–æ –∏–∑–º–µ–Ω" in ql or "–∏–∑–º–µ–Ω–µ–Ω–∏" in ql) and ("–Ω–µ–¥–µ–ª" in ql or "7 " in ql or "—Å–µ–º" in ql)

        section = _canon_section(q)
        case_no = _find_case_no_in_text(q)  # 00-00-000000

        try:
            df = get_consult_df()

            # 1.1) –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∑–∞ –Ω–µ–¥–µ–ª—é (–ø–æ —Å–Ω–∏–º–∫–∞–º)
            if diff_requested:
                d = diff_week(df)
                note = d.get("note", [])
                lines = []
                if note:
                    lines.extend(note)
                else:
                    lines.append("–ò–∑–º–µ–Ω–µ–Ω–∏—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Å–Ω–∏–º–∫–∞ ~7 –¥–Ω–µ–π –Ω–∞–∑–∞–¥:")
                    lines.append(f"‚Ä¢ –ù–æ–≤—ã–µ –¥–µ–ª–∞: {len(d['new'])}")
                    lines.append(f"‚Ä¢ –£–¥–∞–ª–µ–Ω—ã/–ø—Ä–æ–ø–∞–ª–∏: {len(d['removed'])}")
                    lines.append(f"‚Ä¢ –ò–∑–º–µ–Ω–µ–Ω—ã —Å—Ç—Ä–æ–∫–∏: {len(d['changed'])}")
                    # –ø–æ–∫–∞–∑–∞—Ç—å –ø–µ—Ä–≤—ã–µ 20 –Ω–æ–º–µ—Ä–æ–≤
                    if d["new"]:
                        lines.append("–ù–æ–≤—ã–µ (–ø–µ—Ä–≤—ã–µ 20): " + ", ".join(d["new"][:20]))
                    if d["changed"]:
                        lines.append("–ò–∑–º–µ–Ω–µ–Ω—ã (–ø–µ—Ä–≤—ã–µ 20): " + ", ".join(d["changed"][:20]))
                    if d["removed"]:
                        lines.append("–£–¥–∞–ª–µ–Ω—ã (–ø–µ—Ä–≤—ã–µ 20): " + ", ".join(d["removed"][:20]))
                out = "\n".join(lines)
                await chat.send_message(out)
                if ENABLE_ASSISTANT_VOICE_REPLY:
                    try:
                        audio = yandex_text_to_speech(out[:800])
                        bio = BytesIO(audio); bio.name = "answer.ogg"
                        await chat.send_voice(voice=bio)
                    except Exception:
                        pass
                return

            # 1.2) –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã (–ø—É—Å—Ç—ã–µ –∫–ª—é—á–µ–≤—ã–µ –ø–æ–ª—è/—Å—Ç–∞—Ç—É—Å—ã)
            if completeness_requested:
                bad = _completeness_report(df, limit=80)
                if len(bad) == 0:
                    out = "‚úÖ –ü—É—Å—Ç—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–ª–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ (–ø–æ —ç–≤—Ä–∏—Å—Ç–∏–∫–µ: –∞–¥—Ä–µ—Å/–∑–∞—Å—Ç—Ä–æ–π—â–∏–∫/–æ–±—ä–µ–∫—Ç/—Å—Ç–∞—Ç—É—Å—ã)."
                    await chat.send_message(out)
                else:
                    out = (
                        f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω—ã —Å—Ç—Ä–æ–∫–∏ —Å –ø—É—Å—Ç—ã–º–∏ –∫–ª—é—á–µ–≤—ã–º–∏ –ø–æ–ª—è–º–∏/—Å—Ç–∞—Ç—É—Å–∞–º–∏: {len(bad)} (–ø–æ–∫–∞–∑—ã–≤–∞—é –¥–æ 80)."
                    )
                    await chat.send_message(out)
                    # –ï—Å–ª–∏ –ø—Ä–æ—Å–∏–ª–∏ –≤—ã–≥—Ä—É–∑–∫—É ‚Äî —Å—Ä–∞–∑—É –æ—Ç–ø—Ä–∞–≤–∏–º —Ñ–∞–π–ª–æ–º
                    if export_requested:
                        bio, fname = df_to_file_bytes(bad, fmt=export_fmt)
                        await chat.send_document(document=bio, filename=fname, caption="–í—ã–≥—Ä—É–∑–∫–∞: –ø—É—Å—Ç—ã–µ/–Ω–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ –ø–æ–ª—è")
                    else:
                        # –∫—Ä–∞—Ç–∫–∏–π —Å–ø–∏—Å–æ–∫ –ø–æ –Ω–æ–º–µ—Ä—É –¥–µ–ª–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
                        cols = _key_fields(df)
                        col_case = cols.get("case")
                        sample = []
                        if col_case and col_case in bad.columns:
                            for v in bad[col_case].astype(str).head(30).tolist():
                                cn = extract_case_number(v) or v
                                sample.append(cn)
                            await chat.send_message("–ü—Ä–∏–º–µ—Ä—ã (–¥–æ 30): " + ", ".join(sample))
                return

            # 1.3) –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–æ–º–µ—Ä –¥–µ–ª–∞ ‚Äî –∫–∞—Ä—Ç–æ—á–∫–∞/–ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ —Ä–∞–∑–¥–µ–ª–∞
            if case_no:
                row = _df_case_card(df, case_no)
                if len(row) == 0:
                    await chat.send_message(f"–î–µ–ª–æ {case_no}: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —Ç–∞–±–ª–∏—Ü–µ.")
                    return

                # –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞ (–ü–ë/–ê–†/–ú–ú–ì–ù/–ê–ì–û/–≠–û–ú –∏ —Ç.–ø.)
                if section:
                    cols_map = _status_columns(df)
                    col = cols_map.get(section)
                    if not col:
                        await chat.send_message(f"–ü–æ –¥–µ–ª—É {case_no}: –Ω–µ –Ω–∞—à—ë–ª –∫–æ–ª–æ–Ω–∫—É –¥–ª—è —Ä–∞–∑–¥–µ–ª–∞ ¬´{section}¬ª –≤ —Ç–∞–±–ª–∏—Ü–µ.")
                        return
                    val = row.iloc[0].get(col)
                    if _is_positive_status(val):
                        out = f"‚úÖ –ü–æ –¥–µ–ª—É {case_no}: –ø–æ ¬´{section}¬ª —É—Å—Ç—Ä–∞–Ω–µ–Ω–æ."
                    elif _is_negative_status(val):
                        out = f"‚ùå –ü–æ –¥–µ–ª—É {case_no}: –ø–æ ¬´{section}¬ª –ù–ï —É—Å—Ç—Ä–∞–Ω–µ–Ω–æ (–µ—Å—Ç—å ¬´–Ω–µ—Ç¬ª/–∞–Ω–∞–ª–æ–≥)."
                    else:
                        out = f"‚ÑπÔ∏è –ü–æ –¥–µ–ª—É {case_no}: –ø–æ ¬´{section}¬ª –Ω–µ—Ç –æ—Ç–º–µ—Ç–∫–∏/–ø—É—Å—Ç–æ."
                    await chat.send_message(out)
                    if export_requested:
                        bio, fname = df_to_file_bytes(row, fmt=export_fmt)
                        await chat.send_document(document=bio, filename=fname, caption=f"–í—ã–≥—Ä—É–∑–∫–∞: –¥–µ–ª–æ {case_no}")
                    if ENABLE_ASSISTANT_VOICE_REPLY:
                        try:
                            audio = yandex_text_to_speech(out[:800])
                            bio = BytesIO(audio); bio.name = "answer.ogg"
                            await chat.send_voice(voice=bio)
                        except Exception:
                            pass
                    return

                # –µ—Å–ª–∏ —Ä–∞–∑–¥–µ–ª –Ω–µ —É–∫–∞–∑–∞–Ω ‚Äî –ø–æ–∫–∞–∂–µ–º –∫–∞—Ä—Ç–æ—á–∫—É (–∫–æ—Ä–æ—Ç–∫–æ) + –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ –≤—ã–≥—Ä—É–∑–∫—É
                cols = _key_fields(df)
                cols_map = _status_columns(df)
                fields = []
                for k, label in [("case","–ù–æ–º–µ—Ä –¥–µ–ª–∞"),("address","–ê–¥—Ä–µ—Å"),("developer","–ó–∞—Å—Ç—Ä–æ–π—â–∏–∫"),("object","–û–±—ä–µ–∫—Ç")]:
                    c = cols.get(k)
                    if c and c in row.columns:
                        fields.append(f"‚Ä¢ {label}: {safe_text(row.iloc[0].get(c))}")
                # —Å—Ç–∞—Ç—É—Å—ã
                for sec, col in cols_map.items():
                    if col in row.columns:
                        fields.append(f"‚Ä¢ {sec}: {safe_text(row.iloc[0].get(col))}")
                out = "–ö–∞—Ä—Ç–æ—á–∫–∞ –ø–æ –¥–µ–ª—É:\n" + "\n".join(fields) if fields else f"–ù–∞—à—ë–ª —Å—Ç—Ä–æ–∫—É –ø–æ –¥–µ–ª—É {case_no}."
                await chat.send_message(out)
                if export_requested:
                    bio, fname = df_to_file_bytes(row, fmt=export_fmt)
                    await chat.send_document(document=bio, filename=fname, caption=f"–í—ã–≥—Ä—É–∑–∫–∞: –¥–µ–ª–æ {case_no}")
                return

            # 1.4) –°–ø–∏—Å–∫–∏ "–Ω–µ —É—Å—Ç—Ä–∞–Ω–µ–Ω–æ" –ø–æ —Ä–∞–∑–¥–µ–ª—É (–∏–ª–∏ –≤ —Ü–µ–ª–æ–º –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º)
            if any(w in ql for w in ["–Ω–µ —É—Å—Ç—Ä–∞–Ω", "–Ω–µ—É—Å—Ç—Ä–∞–Ω", "–µ—Å—Ç—å –Ω–µ—Ç", "–≥–¥–µ –Ω–µ—Ç", "—Å—Ç–∞—Ç—É—Å –Ω–µ—Ç"]):
                bad = _df_not_fixed(df, section=section, limit=60)
                if len(bad) == 0:
                    await chat.send_message("–ü–æ –∑–∞–ø—Ä–æ—Å—É ¬´–Ω–µ —É—Å—Ç—Ä–∞–Ω–µ–Ω–æ¬ª –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
                    return
                title = f"‚ùå –ù–µ —É—Å—Ç—Ä–∞–Ω–µ–Ω–æ –ø–æ —Ä–∞–∑–¥–µ–ª—É ¬´{section}¬ª" if section else "‚ùå –ù–µ —É—Å—Ç—Ä–∞–Ω–µ–Ω–æ (–ø–æ –¥–æ—Å—Ç—É–ø–Ω—ã–º —Å—Ç–∞—Ç—É—Å-–∫–æ–ª–æ–Ω–∫–∞–º)"
                await chat.send_message(f"{title}\n–ù–∞–π–¥–µ–Ω–æ: {len(bad)} (–ø–æ–∫–∞–∑—ã–≤–∞—é –¥–æ 60).")
                if export_requested:
                    bio, fname = df_to_file_bytes(bad, fmt=export_fmt)
                    await chat.send_document(document=bio, filename=fname, caption="–í—ã–≥—Ä—É–∑–∫–∞: –Ω–µ —É—Å—Ç—Ä–∞–Ω–µ–Ω–æ")
                else:
                    cols = _key_fields(df)
                    col_case = cols.get("case")
                    col_addr = cols.get("address")
                    lines = []
                    for _, r in bad.head(30).iterrows():
                        cn = extract_case_number(safe_text(r.get(col_case))) if col_case else ""
                        addr = safe_text(r.get(col_addr)) if col_addr else ""
                        if cn or addr:
                            lines.append(f"‚Ä¢ {cn or '‚Äî'} ‚Äî {addr[:120]}")
                    if lines:
                        await chat.send_message("\n".join(lines))
                return

            # 1.5) –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –ª—é–±–æ–º—É –ø–æ–ª—é + –≤—ã–≥—Ä—É–∑–∫–∞
            # (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–Ω–∞–π–¥–∏ –ø–æ –∑–∞—Å—Ç—Ä–æ–π—â–∏–∫—É ...", "–Ω–∞–π–¥–∏ –∞–¥—Ä–µ—Å ...", –∏ —Ç.–ø.)
            if ql.startswith("–Ω–∞–π–¥–∏") or ql.startswith("–ø–æ–∫–∞–∂–∏") or export_requested:
                # –∏–∑–≤–ª–µ—á—ë–º "—Ö–≤–æ—Å—Ç" –ø–æ—Å–ª–µ "–Ω–∞–π–¥–∏/–ø–æ–∫–∞–∂–∏"
                q2 = q
                for pfx in ["–Ω–∞–π–¥–∏", "–ø–æ–∫–∞–∂–∏", "–ø–æ–∏—Å–∫", "—Å—Ñ–æ—Ä–º–∏—Ä—É–π", "–≤—ã–≥—Ä—É–∑–∫–∞", "—ç–∫—Å–ø–æ—Ä—Ç"]:
                    if ql.startswith(pfx):
                        q2 = q[len(pfx):].strip(" :,-")
                        break
                res = _universal_search(df, q2 or q, limit=200 if export_requested else 30)
                if len(res) == 0:
                    await chat.send_message("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ –∑–∞–ø—Ä–æ—Å—É.")
                    return
                await chat.send_message(f"–ù–∞–π–¥–µ–Ω–æ —Å—Ç—Ä–æ–∫: {len(res)} (–ø–æ–∫–∞–∑—ã–≤–∞—é –¥–æ {len(res)}).")
                if export_requested:
                    bio, fname = df_to_file_bytes(res, fmt=export_fmt)
                    await chat.send_document(document=bio, filename=fname, caption="–í—ã–≥—Ä—É–∑–∫–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É")
                else:
                    cols = _key_fields(df)
                    col_case = cols.get("case")
                    col_addr = cols.get("address")
                    lines = []
                    for _, r in res.head(25).iterrows():
                        cn = extract_case_number(safe_text(r.get(col_case))) if col_case else ""
                        addr = safe_text(r.get(col_addr)) if col_addr else ""
                        if cn or addr:
                            lines.append(f"‚Ä¢ {cn or '‚Äî'} ‚Äî {addr[:120]}")
                    if lines:
                        await chat.send_message("\n".join(lines))
                return

            # –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ ‚Äî –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –≤ –æ–±—â–∏–π Q&A
        except Exception as e:
            await chat.send_message(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø–æ —Ç–∞–±–ª–∏—Ü–µ: {e}")
            return

# 2) –æ–±—â–∏–π Q&A: retrieval –ø–æ —Ç–∞–±–ª–∏—Ü–µ + YandexGPT
    try:
        df = get_consult_df()
        context_rows = retrieve_relevant_rows(df, q, max_rows=12)
        system = (
            "–¢—ã ‚Äî —Å–ª—É–∂–µ–±–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ì–ª–∞–≤–≥–æ—Å—Å—Ç—Ä–æ–π–Ω–∞–¥–∑–æ—Ä–∞. "
            "–û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –ø–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–º—É —Ñ—Ä–∞–≥–º–µ–Ω—Ç—É —Ç–∞–±–ª–∏—Ü—ã. "
            "–ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî —Å–∫–∞–∂–∏, —á—Ç–æ –≤ —Ç–∞–±–ª–∏—Ü–µ –Ω–µ—Ç —Å–≤–µ–¥–µ–Ω–∏–π, –∏ —É—Ç–æ—á–Ω–∏, —á—Ç–æ –Ω—É–∂–Ω–æ."
        )
        user_prompt = (
            f"–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:\n{q}\n\n"
            f"–§—Ä–∞–≥–º–µ–Ω—Ç —Ç–∞–±–ª–∏—Ü—ã (–∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ —Å—Ç—Ä–æ–∫–∏):\n{context_rows}\n\n"
            "–î–∞–π –∫—Ä–∞—Ç–∫–∏–π, —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç. –ï—Å–ª–∏ –º–æ–∂–Ω–æ ‚Äî —É–∫–∞–∂–∏ –Ω–æ–º–µ—Ä –¥–µ–ª–∞ –∏ –∫–ª—é—á–µ–≤—ã–µ –ø–æ–ª—è."
        )
        answer = yandex_chat_completion(system, user_prompt, temperature=0.1, max_tokens=700)
        await chat.send_message(answer)

        if ENABLE_ASSISTANT_VOICE_REPLY:
            try:
                audio = yandex_text_to_speech(answer[:800])
                bio = BytesIO(audio); bio.name = "answer.ogg"
                await chat.send_voice(voice=bio)
            except Exception:
                pass

    except Exception as e:
        await chat.send_message(
            "–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–ø—Ä–æ–≤–µ—Ä—å—Ç–µ YANDEX_API_KEY/YANDEX_FOLDER_ID –∏ –¥–æ—Å—Ç—É–ø –∫ —Ç–∞–±–ª–∏—Ü–µ). "
            f"–î–µ—Ç–∞–ª–∏: {e}"
        )

from telegram import (
    Update,
    ReplyKeyboardMarkup,
    InlineKeyboardMarkup,
    InlineKeyboardButton,
    InputFile,
)
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    CallbackQueryHandler,
    ContextTypes,
    filters,
)

from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
from openpyxl.worksheet.table import Table, TableStyleInfo

AnyType = Any

# ----------------- –õ–û–ì–ò -----------------
logging.basicConfig(
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    level=logging.INFO,
)
log = logging.getLogger("sot_bot")

# ----------------- –ù–ê–°–¢–†–û–ô–ö–ò –ò .ENV -----------------
load_dotenv()

BOT_TOKEN = (os.getenv("BOT_TOKEN") or "").strip()
DB_PATH = os.getenv("DB_PATH", "sot_bot.db")

TIMEZONE_OFFSET = int(os.getenv("TIMEZONE_OFFSET", "3"))
ANALYTICS_PASSWORD = "051995"

# ----------------- –î–ê–ù–ù–´–ï / PERSISTENCE (Railway Volume) -----------------
# –í Railway –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø–æ–¥–∫–ª—é—á–∏—Ç—å Volume –∏ –ø—Ä–∏–º–æ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ /data,
# —á—Ç–æ–±—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –ø–∞—Ä–æ–ª—å —Å–æ—Ö—Ä–∞–Ω—è–ª–∏—Å—å –º–µ–∂–¥—É –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–º–∏.
DATA_DIR = (os.getenv("DATA_DIR") or "/data").strip() or "/data"
os.makedirs(DATA_DIR, exist_ok=True)

# ----------------- –®–ê–ë–õ–û–ù DOCX (–¢–ó –¥–ª—è –¶–ù–ò–õ) -----------------
# –ú–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è CNIL_T3_TEMPLATE.
# –ò–Ω–∞—á–µ –±–µ—Ä—ë–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø—É—Ç—å –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ (/app) –∏–ª–∏ –≤ Volume (/data).
CNIL_T3_TEMPLATE = (os.getenv("CNIL_T3_TEMPLATE") or os.getenv("TEST_T3_TEMPLATE") or "/app/TEST_T3.docx").strip()

def _resolve_cnil_t3_template(path: str) -> str:
    candidates = [
        path,
        "/app/TEST_T3.docx",
        "/app/TEST_T3_TEMPLATE.docx",
        os.path.join(DATA_DIR, "TEST_T3.docx"),
        os.path.join(DATA_DIR, "TEST_T3_TEMPLATE.docx"),
    ]
    for c in candidates:
        try:
            if c and os.path.exists(c):
                return c
        except Exception:
            pass
    return path

CNIL_T3_TEMPLATE = _resolve_cnil_t3_template(CNIL_T3_TEMPLATE)


# =========================
# üß™ –¢–ó –¥–ª—è –¶–ù–ò–õ: –ø–∞—Ä–æ–ª—å –Ω–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ
# =========================

# –†–µ–∑–µ—Ä–≤–Ω—ã–π –ø–∞—Ä–æ–ª—å (–ù–ï –º–µ–Ω—è–µ—Ç—Å—è –Ω–∏–∫–æ–≥–¥–∞)
CNIL_MASTER_DOWNLOAD_PASSWORD = "051995"

def cnil_password_file() -> str:
    return os.path.join(DATA_DIR, "cnil_download_password.json")

def cnil_load_download_password() -> str:
    """–¢–µ–∫—É—â–∏–π –ø–∞—Ä–æ–ª—å –Ω–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: 1234."""
    path = cnil_password_file()
    try:
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                obj = json.load(f)
            pw = str(obj.get("password", "")).strip()
            return pw or "1234"
    except Exception:
        pass
    return "1234"

def cnil_save_download_password(new_password: str) -> None:
    path = cnil_password_file()
    obj = {"password": str(new_password).strip()}
    tmp = path + ".tmp"
    with open(tmp, "w", encoding="utf-8") as f:
        json.dump(obj, f, ensure_ascii=False)
    os.replace(tmp, path)


def _extract_spreadsheet_id_from_url(url: str) -> str:
    try:
        if "/d/" in url:
            return url.split("/d/")[1].split("/")[0]
    except Exception:
        pass
    return ""


SCHEDULE_URL_ENV = (os.getenv("SCHEDULE_URL") or "").strip()

_default_sheet_id = _extract_spreadsheet_id_from_url(SCHEDULE_URL_ENV)
if not _default_sheet_id:
    _default_sheet_id = (os.getenv("GSHEETS_SPREADSHEET_ID") or "").strip()
if not _default_sheet_id:
    _default_sheet_id = "1W_9Cs-LaX6KR4cE9xN71CliE6Lm_TyQqk8t3kQa4FCc"

GSHEETS_SPREADSHEET_ID = _default_sheet_id

if SCHEDULE_URL_ENV:
    GOOGLE_SHEET_URL_DEFAULT = SCHEDULE_URL_ENV
else:
    GOOGLE_SHEET_URL_DEFAULT = (
        f"https://docs.google.com/spreadsheets/d/{GSHEETS_SPREADSHEET_ID}/edit?usp=sharing"
    )

GSHEETS_SERVICE_ACCOUNT_JSON = (os.getenv("GSHEETS_SERVICE_ACCOUNT_JSON") or "").strip()
SHEETS_SERVICE = None

DEFAULT_APPROVERS = [
    "@asdinamitif",
    "@FrolovAlNGSN",
    "@cappit_G59",
    "@sergeybektiashkin",
    "@scri4",
    "@Kirill_Victorovi4",
]

RESPONSIBLE_USERNAMES: Dict[str, List[str]] = {
    "–±–µ–∫—Ç—è—à–∫–∏–Ω": ["sergeybektiashkin"],
    "—Å–º–∏—Ä–Ω–æ–≤": ["scri4"],
}

INSPECTOR_SHEET_NAME = "–ü–ë, –ê–†,–ú–ú–ì–ù, –ê–ì–û (2025)"
HARD_CODED_ADMINS = {398960707}

SCHEDULE_NOTIFY_CHAT_ID_ENV = (os.getenv("SCHEDULE_NOTIFY_CHAT_ID") or "").strip()
SCHEDULE_NOTIFY_CHAT_ID = (
    int(SCHEDULE_NOTIFY_CHAT_ID_ENV) if SCHEDULE_NOTIFY_CHAT_ID_ENV else None
)

# –í–¢–û–†–ê–Ø –¢–ê–ë–õ–ò–¶–ê ‚Äî –∏—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
FINAL_CHECKS_SPREADSHEET_ID = (
    os.getenv(
        "FINAL_CHECKS_SPREADSHEET_ID",
        "1dUO3neTKzKI3D8P6fs_LJLmWlL7jw-FhohtJkjz4KuE",
    ).strip()
)


FINAL_CHECKS_LOCAL_PATH = os.getenv(
    "FINAL_CHECKS_LOCAL_PATH",
    "final_checks.xlsx",
).strip()



def is_admin(uid: int) -> bool:
    return uid in HARD_CODED_ADMINS


def local_now() -> datetime:
    return datetime.utcnow() + timedelta(hours=TIMEZONE_OFFSET)


def get_current_remarks_sheet_name() -> str:
    year = local_now().year
    return f"–ü–ë, –ê–†,–ú–ú–ì–ù, –ê–ì–û ({year})"


# -------------------------------------------------
# Google Sheets helpers
# -------------------------------------------------
def get_sheets_service():
    global SHEETS_SERVICE

    if SHEETS_SERVICE is not None:
        return SHEETS_SERVICE

    if not GSHEETS_SERVICE_ACCOUNT_JSON:
        log.error(
            "GSHEETS_SERVICE_ACCOUNT_JSON –Ω–µ –∑–∞–¥–∞–Ω ‚Äì Google Sheets API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω."
        )
        return None

    try:
        info = json.loads(GSHEETS_SERVICE_ACCOUNT_JSON)
        creds = Credentials.from_service_account_info(
            info,
            scopes=["https://www.googleapis.com/auth/spreadsheets"],
        )
        service = build("sheets", "v4", credentials=creds)
        SHEETS_SERVICE = service
        return service
    except Exception as e:
        log.error("–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞ Google Sheets: %s", e)
        return None


def build_export_url(spreadsheet_id: str) -> str:
    return f"https://docs.google.com/spreadsheets/d/{spreadsheet_id}/export?format=xlsx"


def detect_header_row(values: List[List[str]]) -> int:
    for i, row in enumerate(values[:30]):
        row_lower = [str(c).lower() for c in row]
        if any("–¥–∞—Ç–∞ –≤—ã–µ–∑–¥–∞" in c for c in row_lower):
            return i
    return 0


def read_sheet_to_dataframe(
    sheet_id: str, sheet_name: str, header_row_index: Optional[int] = None
) -> Optional[pd.DataFrame]:
    service = get_sheets_service()
    if service is None:
        log.error("Google Sheets —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Äì –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å –ª–∏—Å—Ç.")
        return None

    try:
        result = (
            service.spreadsheets()
            .values()
            .get(spreadsheetId=sheet_id, range=f"'{sheet_name}'!A1:ZZZ1000")
            .execute()
        )
        values = result.get("values", [])

        if not values:
            log.warning("–õ–∏—Å—Ç '%s' –ø—É—Å—Ç.", sheet_name)
            return pd.DataFrame()

        if header_row_index is None:
            header_row_index = detect_header_row(values)

        headers = values[header_row_index]
        data_rows = values[header_row_index + 1 :]

        df = pd.DataFrame(data_rows, columns=headers)
        df = df.dropna(how="all").reset_index(drop=True)
        return df
    except Exception as e:
        log.error("–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ª–∏—Å—Ç–∞ '%s' –∏–∑ Google Sheets: %s", sheet_name, e)
        return None


# -------------------------------------------------
# –†–∞–±–æ—Ç–∞ —Å–æ —Å—Ç–æ–ª–±—Ü–∞–º–∏ Excel
# -------------------------------------------------
def excel_col_to_index(col: str) -> int:
    col = col.upper().strip()
    idx = 0
    for ch in col:
        if "A" <= ch <= "Z":
            idx = idx * 26 + (ord(ch) - ord("A") + 1)
    return idx - 1


def get_col_by_letter(df: pd.DataFrame, letters: str) -> Optional[str]:
    idx = excel_col_to_index(letters)
    if 0 <= idx < len(df.columns):
        return df.columns[idx]
    return None


def get_col_index_by_header(
    df: pd.DataFrame, search_substr: str, fallback_letter: str
) -> Optional[int]:
    search_substr = search_substr.lower()
    for i, col in enumerate(df.columns):
        if search_substr in str(col).lower():
            return i
    idx = excel_col_to_index(fallback_letter)
    if 0 <= idx < len(df.columns):
        return idx
    return None


def normalize_onzs_value(val) -> Optional[str]:
    if val is None:
        return None
    s = str(val).strip()
    if not s:
        return None
    try:
        n = int(float(s.replace(",", ".")))
        return str(n)
    except Exception:
        pass
    return s


def normalize_case_number(val) -> str:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–æ–º–µ—Ä–∞ –¥–µ–ª–∞:

    - –ø—Ä–∏–≤–æ–¥–∏–º –≤—Å–µ –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Ç–∏—Ä–µ –∫ –æ–±—ã—á–Ω–æ–º—É '-';
    - —É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã;
    - –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º –ª—é–±—ã–µ —Å–∏–º–≤–æ–ª—ã, –∫—Ä–æ–º–µ —Ü–∏—Ñ—Ä –∏ '-'.

    –ü—Ä–∏–º–µ—Ä—ã:
    '–î–µ–ª–æ ‚Ññ 03‚Äì46‚Äì108600 (–ü–ü)' -> '03-46-108600'
    ' 01-29-099900 ' -> '01-29-099900'
    """
    if val is None:
        return ""
    s = str(val).strip()
    if not s:
        return ""

    # –≤—Å–µ ¬´–∫–æ—Å—ã–µ¬ª —Ç–∏—Ä–µ –≤ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ
    hyphens = ["\u2010", "\u2011", "\u2012", "\u2013", "\u2014", "\u2212"]
    for h in hyphens:
        s = s.replace(h, "-")

    # —É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã
    s = s.replace(" ", "")

    # –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã –∏ '-'
    cleaned_chars = []
    for ch in s:
        if ch.isdigit() or ch == "-":
            cleaned_chars.append(ch)

    return "".join(cleaned_chars)


def get_case_col_index(df: pd.DataFrame) -> Optional[int]:
    idx_i = excel_col_to_index("I")
    if 0 <= idx_i < len(df.columns):
        return idx_i
    return get_col_index_by_header(df, "–Ω–æ–º–µ—Ä –¥–µ–ª–∞", "I")


# -------------------------------------------------
# –ë–ê–ó–ê –î–ê–ù–ù–´–•
# -------------------------------------------------
def get_db() -> sqlite3.Connection:
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    return conn


def init_db() -> None:
    conn = get_db()
    c = conn.cursor()

    c.execute(
        """CREATE TABLE IF NOT EXISTS schedule_settings (
               key TEXT PRIMARY KEY,
               value TEXT
           )"""
    )

    c.execute(
        """CREATE TABLE IF NOT EXISTS approvers (
               id INTEGER PRIMARY KEY AUTOINCREMENT,
               label TEXT UNIQUE
           )"""
    )

    c.execute(
        """CREATE TABLE IF NOT EXISTS schedule_files (
               version INTEGER PRIMARY KEY,
               name TEXT,
               uploaded_at TEXT
           )"""
    )

    c.execute(
        """CREATE TABLE IF NOT EXISTS schedule_approvals (
               id INTEGER PRIMARY KEY AUTOINCREMENT,
               version INTEGER,
               approver TEXT,
               status TEXT,
               comment TEXT,
               decided_at TEXT,
               requested_at TEXT
           )"""
    )

    c.execute(
        """CREATE TABLE IF NOT EXISTS inspector_visits (
               id INTEGER PRIMARY KEY AUTOINCREMENT,
               date TEXT,
               area TEXT,
               floors TEXT,
               onzs TEXT,
               developer TEXT,
               object TEXT,
               address TEXT,
               case_no TEXT,
               check_type TEXT,
               created_at TEXT
           )"""
    )

    c.execute("SELECT COUNT(*) AS c FROM approvers")
    if c.fetchone()["c"] == 0:
        c.executemany(
            "INSERT OR IGNORE INTO approvers (label) VALUES (?)",
            [(lbl,) for lbl in DEFAULT_APPROVERS],
        )

    c.execute("SELECT value FROM schedule_settings WHERE key='schedule_version'")
    if not c.fetchone():
        c.execute(
            "INSERT INTO schedule_settings (key, value) VALUES ('schedule_version', '1')"
        )

    c.execute("SELECT value FROM schedule_settings WHERE key='last_notified_version'")
    if not c.fetchone():
        c.execute(
            "INSERT INTO schedule_settings (key, value) VALUES ('last_notified_version', '0')"
        )

    if SCHEDULE_NOTIFY_CHAT_ID_ENV:
        c.execute(
            "INSERT OR REPLACE INTO schedule_settings (key, value) VALUES (?, ?)",
            ("schedule_notify_chat_id", SCHEDULE_NOTIFY_CHAT_ID_ENV),
        )

    conn.commit()
    conn.close()


def get_schedule_state() -> dict:
    conn = get_db()
    c = conn.cursor()
    c.execute("SELECT key, value FROM schedule_settings")
    rows = c.fetchall()
    conn.close()
    return {r["key"]: r["value"] for r in rows}


def get_schedule_version(settings: dict) -> int:
    try:
        return int(settings.get("schedule_version") or "1")
    except Exception:
        return 1


def get_current_approvers(settings: dict) -> List[str]:
    val = settings.get("current_approvers")
    if val:
        arr = [v.strip() for v in val.split(",") if v.strip()]
        if arr:
            return arr
    return []


def set_current_approvers_for_version(approvers: List[str], version: int) -> None:
    conn = get_db()
    c = conn.cursor()

    c.execute(
        "INSERT OR REPLACE INTO schedule_settings (key, value) VALUES ('current_approvers', ?)",
        (",".join(approvers),),
    )

    c.execute("DELETE FROM schedule_approvals WHERE version = ?", (version,))

    now = local_now().isoformat()
    for appr in approvers:
        c.execute(
            """INSERT INTO schedule_approvals
               (version, approver, status, comment, decided_at, requested_at)
               VALUES (?, ?, 'pending', NULL, NULL, ?)""",
            (version, appr, now),
        )

    conn.commit()
    conn.close()


def get_schedule_approvals(version: int) -> List[sqlite3.Row]:
    conn = get_db()
    c = conn.cursor()
    c.execute(
        "SELECT * FROM schedule_approvals WHERE version = ? ORDER BY approver",
        (version,),
    )
    rows = c.fetchall()
    conn.close()
    return rows


def update_schedule_approval_status(
    version: int, approver: str, status: str, comment: Optional[str] = None
):
    conn = get_db()
    c = conn.cursor()
    now = local_now().isoformat()

    c.execute(
        """UPDATE schedule_approvals
           SET status=?, comment=?, decided_at=?
           WHERE version=? AND approver=?""",
        (status, comment, now, version, approver),
    )
    conn.commit()
    conn.close()


# -------------------------------------------------
# –ò–Ω—Å–ø–µ–∫—Ç–æ—Ä: –ë–î
# -------------------------------------------------
def save_inspector_to_db(form: Dict[str, Any]) -> bool:
    try:
        conn = get_db()
        c = conn.cursor()
        date_obj = form.get("date")
        date_str = date_obj.strftime("%Y-%m-%d") if date_obj else None
        c.execute(
            """INSERT INTO inspector_visits
               (date, area, floors, onzs, developer, object, address,
                case_no, check_type, created_at)
               VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
            (
                date_str,
                form.get("area", ""),
                form.get("floors", ""),
                form.get("onzs", ""),
                form.get("developer", ""),
                form.get("object", ""),
                form.get("address", ""),
                form.get("case", ""),
                form.get("check_type", ""),
                local_now().isoformat(),
            ),
        )
        conn.commit()
        conn.close()
        return True
    except Exception as e:
        log.error("–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω—Å–ø–µ–∫—Ç–æ—Ä–∞ –≤ –ª–æ–∫–Ω—É—é –ë–î: %s", e)
        return False


def fetch_inspector_visits(limit: int = 50) -> List[sqlite3.Row]:
    conn = get_db()
    c = conn.cursor()
    c.execute(
        """SELECT * FROM inspector_visits
           ORDER BY date DESC, id DESC
           LIMIT ?""",
        (limit,),
    )
    rows = c.fetchall()
    conn.close()
    return rows


def clear_inspector_visits() -> None:
    conn = get_db()
    c = conn.cursor()
    c.execute("DELETE FROM inspector_visits")
    conn.commit()
    conn.close()


# -------------------------------------------------
# –ö–ª–∞–≤–∏–∞—Ç—É—Ä—ã
# -------------------------------------------------
def main_menu() -> ReplyKeyboardMarkup:
    return ReplyKeyboardMarkup(
        [
            ["üìÖ –ì—Ä–∞—Ñ–∏–∫", "üìù –ó–∞–º–µ—á–∞–Ω–∏—è"],
            ["–ò–Ω—Å–ø–µ–∫—Ç–æ—Ä", "üìà –ê–Ω–∞–ª–∏—Ç–∏–∫–∞"],
            ["–ò—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏"],
            ["üö® –ö—Ä–∞—Å–Ω—ã–µ –ª–∞–º–ø–æ—á–∫–∏"],
            ["üß™ –¢–ó –¥–ª—è –¶–ù–ò–õ"],
            ["üó£ –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç"],
        ],
        resize_keyboard=True,
    )


def build_schedule_inline(
    is_admin_flag: bool, settings: dict, user_tag: Optional[str] = None
) -> InlineKeyboardMarkup:
    buttons = [
        [
            InlineKeyboardButton("üîÑ –û–±–Ω–æ–≤–∏—Ç—å", callback_data="schedule_refresh"),
            InlineKeyboardButton("üì• –°–∫–∞—á–∞—Ç—å", callback_data="schedule_download"),
        ],
        [InlineKeyboardButton("üì§ –ó–∞–≥—Ä—É–∑–∏—Ç—å", callback_data="schedule_upload")],
    ]
    if is_admin_flag:
        buttons.append(
            [InlineKeyboardButton("üë• –°–æ–≥–ª–∞—Å—É—é—â–∏–µ", callback_data="schedule_approvers")]
        )

    approvers = get_current_approvers(settings)
    if user_tag and user_tag in approvers:
        buttons.append(
            [
                InlineKeyboardButton(
                    f"‚úÖ –°–æ–≥–ª–∞—Å–æ–≤–∞—Ç—å ({user_tag})",
                    callback_data=f"schedule_approve:{user_tag}",
                ),
                InlineKeyboardButton(
                    f"‚úèÔ∏è –ù–∞ –¥–æ—Ä–∞–±–æ—Ç–∫—É ({user_tag})",
                    callback_data=f"schedule_rework:{user_tag}",
                ),
            ]
        )

    return InlineKeyboardMarkup(buttons)


def remarks_menu_inline() -> InlineKeyboardMarkup:
    return InlineKeyboardMarkup(
        [
            [
                InlineKeyboardButton(
                    "üîé –ü–æ–∏—Å–∫ –ø–æ –Ω–æ–º–µ—Ä—É –¥–µ–ª–∞", callback_data="remarks_search_case"
                )
            ],
            [InlineKeyboardButton("üèó –û–ù–∑–°", callback_data="remarks_onzs")],
            [InlineKeyboardButton("üì• –û—Ç–∫—Ä—ã—Ç—å —Ñ–∞–π–ª", callback_data="remarks_download")],
        ]
    )


def inspector_menu_inline() -> InlineKeyboardMarkup:
    return InlineKeyboardMarkup(
        [
            [InlineKeyboardButton("‚ûï –î–æ–±–∞–≤–∏—Ç—å –≤—ã–µ–∑–¥", callback_data="inspector_add")],
            [
                InlineKeyboardButton("üìã –°–ø–∏—Å–æ–∫ –≤—ã–µ–∑–¥–æ–≤", callback_data="inspector_list"),
                InlineKeyboardButton(
                    "üì• –°–∫–∞—á–∞—Ç—å Excel", callback_data="inspector_download"
                ),
            ],
            [
                InlineKeyboardButton(
                    "üîÑ –û–±–Ω–æ–≤–∏—Ç—å", callback_data="inspector_reset"
                )
            ],
        ]
    )


def final_checks_menu_inline() -> InlineKeyboardMarkup:
    return InlineKeyboardMarkup(
        [
            [
                InlineKeyboardButton("üìÖ –ó–∞ –Ω–µ–¥–µ–ª—é", callback_data="final_week"),
                InlineKeyboardButton("üìÜ –ó–∞ –º–µ—Å—è—Ü", callback_data="final_month"),
            ],
            [
                InlineKeyboardButton(
                    "üìä –í—ã–±—Ä–∞—Ç—å –ø–µ—Ä–∏–æ–¥", callback_data="final_period"
                )
            ],
            [
                InlineKeyboardButton(
                    "üîé –ü–æ –Ω–æ–º–µ—Ä—É –¥–µ–ª–∞", callback_data="final_search_case"
                )
            ],
        ]
    )


# -------------------------------------------------
# –ì—Ä–∞—Ñ–∏–∫
# -------------------------------------------------
def get_schedule_df() -> Optional[pd.DataFrame]:
    SHEET = "–ì—Ä–∞—Ñ–∏–∫"
    url = build_export_url(GSHEETS_SPREADSHEET_ID)

    try:
        resp = requests.get(url, timeout=30)
        resp.raise_for_status()
    except Exception as e:
        log.error("–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è Excel (–≥—Ä–∞—Ñ–∏–∫): %s", e)
        return None

    try:
        xls = pd.ExcelFile(BytesIO(resp.content))
        if SHEET not in xls.sheet_names:
            log.error("–í —Ñ–∞–π–ª–µ –Ω–µ—Ç –ª–∏—Å—Ç–∞ '%s'", SHEET)
            return None
        df = pd.read_excel(xls, sheet_name=SHEET)
        df = df.dropna(how="all").reset_index(drop=True)
        return df
    except Exception as e:
        log.error("–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ª–∏—Å—Ç–∞ –≥—Ä–∞—Ñ–∏–∫–∞: %s", e)
        return None


HEADER_FILL = PatternFill(start_color="305496", end_color="305496", fill_type="solid")
HEADER_FONT = Font(color="FFFFFF", bold=True)
BORDER = Border(
    left=Side(style="thin"),
    right=Side(style="thin"),
    top=Side(style="thin"),
    bottom=Side(style="thin"),
)


async def send_schedule_xlsx(
    chat_id: int, dataframe: pd.DataFrame, context: ContextTypes.DEFAULT_TYPE
):
    df = dataframe.copy().reset_index(drop=True)
    headers = list(df.columns)

    date_col_name: Optional[str] = None
    for h in headers:
        if "–¥–∞—Ç–∞ –≤—ã–µ–∑–¥–∞" in str(h).lower():
            date_col_name = h
            break
    if date_col_name:
        try:
            df[date_col_name] = pd.to_datetime(
                df[date_col_name], errors="coerce", dayfirst=True
            )
        except Exception:
            pass

    settings = get_schedule_state()
    version = get_schedule_version(settings)
    approvals = get_schedule_approvals(version)

    bio = BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as writer:
        df.to_excel(
            writer,
            sheet_name="–ì—Ä–∞—Ñ–∏–∫ –≤—ã–µ–∑–¥–æ–≤",
            index=False,
            startrow=2,
            header=False,
        )

        wb = writer.book
        ws = writer.sheets["–ì—Ä–∞—Ñ–∏–∫ –≤—ã–µ–∑–¥–æ–≤"]

        for col_num, value in enumerate(headers, 1):
            cell = ws.cell(row=2, column=col_num, value=value)
            cell.fill = HEADER_FILL
            cell.font = HEADER_FONT
            cell.alignment = Alignment(horizontal="center", vertical="center")

        for column in ws.columns:
            max_length = 0
            col_letter = column[0].column_letter
            for cell in column:
                try:
                    if cell.value is not None and len(str(cell.value)) > max_length:
                        max_length = len(str(cell.value))
                except Exception:
                    pass
            ws.column_dimensions[col_letter].width = min(max_length + 4, 50)

        ws.freeze_panes = ws["A3"]

        last_col_letter = ws.cell(row=2, column=len(headers)).column_letter
        ws.auto_filter.ref = f"A2:{last_col_letter}{len(df) + 2}"

        for row in ws[f"A3:{last_col_letter}{len(df) + 2}"]:
            for cell in row:
                cell.border = BORDER

        LIGHT_FILL = PatternFill(
            start_color="F0F0F0", end_color="F0F0F0", fill_type="solid"
        )
        for idx, row in enumerate(
            ws.iter_rows(min_row=3, max_row=len(df) + 2), start=3
        ):
            if idx % 2 == 0:
                for cell in row:
                    cell.fill = LIGHT_FILL

        tab = Table(
            displayName="ScheduleTable",
            ref=f"A2:{last_col_letter}{len(df) + 2}",
        )
        tab.tableStyleInfo = TableStyleInfo(
            name="TableStyleMedium9",
            showFirstColumn=False,
            showLastColumn=False,
            showRowStripes=True,
            showColumnStripes=False,
        )
        ws.add_table(tab)

        date_idx = None
        onzs_idx = None
        dev_idx = None
        obj_idx = None

        for i, h in enumerate(headers, start=1):
            h_low = str(h).lower()
            if date_idx is None and "–¥–∞—Ç–∞ –≤—ã–µ–∑–¥–∞" in h_low:
                date_idx = i
            if onzs_idx is None and "–æ–Ω–∑—Å" in h_low:
                onzs_idx = i
            if dev_idx is None and "–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∑–∞—Å—Ç—Ä–æ–π—â–∏–∫–∞" in h_low:
                dev_idx = i
            if obj_idx is None and "–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞" in h_low:
                obj_idx = i

        for row_idx in range(3, len(df) + 3):
            if date_idx:
                cell = ws.cell(row=row_idx, column=date_idx)
                cell.number_format = "DD.MM.YYYY"
            if onzs_idx:
                cell = ws.cell(row=row_idx, column=onzs_idx)
                cell.alignment = Alignment(
                    horizontal="center", vertical="center", wrap_text=False
                )
            if dev_idx:
                cell = ws.cell(row=row_idx, column=dev_idx)
                cell.alignment = Alignment(
                    horizontal="left", vertical="center", wrap_text=True
                )
            if obj_idx:
                cell = ws.cell(row=row_idx, column=obj_idx)
                cell.alignment = Alignment(
                    horizontal="left", vertical="center", wrap_text=True
                )

        if approvals:
            last_data_row = len(df) + 2
            summary_start = last_data_row + 2

            header = build_schedule_header(version, approvals)
            ws.merge_cells(f"A{summary_start}:{last_col_letter}{summary_start}")
            cell_header = ws[f"A{summary_start}"]
            cell_header.value = header
            cell_header.font = Font(bold=True, size=12, color="FFFFFF")
            cell_header.fill = PatternFill(
                start_color="4F81BD", end_color="4F81BD", fill_type="solid"
            )
            cell_header.alignment = Alignment(horizontal="center", vertical="center")

            sub_row = summary_start + 1
            ws.merge_cells(f"A{sub_row}:{last_col_letter}{sub_row}")
            cell_sub = ws[f"A{sub_row}"]
            cell_sub.value = "–°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–æ –≤—Å–µ–º–∏:"
            cell_sub.font = Font(bold=True, size=11)
            cell_sub.alignment = Alignment(horizontal="left", vertical="center")

            row_ptr = sub_row + 1
            approved_rows = [r for r in approvals if r["status"] == "approved"]
            others = [r for r in approvals if r["status"] != "approved"]

            list_fill = PatternFill(
                start_color="D9E1F2", end_color="D9E1F2", fill_type="solid"
            )

            for r in approved_rows:
                line = f"‚Ä¢ {r['approver']} ‚Äî {_format_dt(r['decided_at'])} ‚úÖ"
                ws.merge_cells(f"A{row_ptr}:{last_col_letter}{row_ptr}")
                cell = ws[f"A{row_ptr}"]
                cell.value = line
                cell.fill = list_fill
                cell.font = Font(size=11)
                cell.alignment = Alignment(horizontal="left", vertical="center")
                for col_idx in range(1, len(headers) + 1):
                    ws.cell(row=row_ptr, column=col_idx).border = BORDER
                row_ptr += 1

            if others:
                ws.merge_cells(f"A{row_ptr}:{last_col_letter}{row_ptr}")
                cell_pending = ws[f"A{row_ptr}"]
                cell_pending.value = "‚ö† –ï—Å—Ç—å –Ω–µ—Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω—ã–µ/–Ω–∞ –¥–æ—Ä–∞–±–æ—Ç–∫–µ."
                cell_pending.font = Font(italic=True, color="C00000")
                cell_pending.alignment = Alignment(
                    horizontal="left", vertical="center"
                )
                for col_idx in range(1, len(headers) + 1):
                    ws.cell(row=row_ptr, column=col_idx).border = BORDER

    bio.seek(0)
    filename = f"–ì—Ä–∞—Ñ–∏–∫_–≤—ã–µ–∑–¥–æ–≤_–°–û–¢_{date.today().strftime('%d.%m.%Y')}.xlsx"

    await context.bot.send_document(
        chat_id=chat_id,
        document=InputFile(bio, filename=filename),
        caption="–ì—Ä–∞—Ñ–∏–∫ –≤—ã–µ–∑–¥–æ–≤ –æ—Ç–¥–µ–ª–∞ –°–û–¢",
    )


# -------------------------------------------------
# –¢–µ–∫—Å—Ç –≥—Ä–∞—Ñ–∏–∫–∞
# -------------------------------------------------
def _format_dt(iso_str: Optional[str]) -> str:
    if not iso_str:
        return ""
    try:
        dt = datetime.fromisoformat(iso_str)
        return dt.strftime("%d.%m.%Y %H:%M")
    except Exception:
        return iso_str


def _compute_schedule_dates(
    approvals: List[sqlite3.Row],
) -> (Optional[date], Optional[date]):
    dates: List[date] = []
    for r in approvals:
        if r["status"] == "approved" and r["decided_at"]:
            try:
                dt = datetime.fromisoformat(r["decided_at"])
                dates.append(dt.date())
            except Exception:
                pass
    if not dates:
        return None, None
    base = max(dates)
    d_from = base
    d_to = base + timedelta(days=4)
    return d_from, d_to


def build_schedule_header(version: int, approvals: List[sqlite3.Row]) -> str:
    d_from, d_to = _compute_schedule_dates(approvals)
    if not d_from or not d_to:
        return f"üìÖ –ì—Ä–∞—Ñ–∏–∫ –≤—ã–µ–∑–¥–æ–≤ (–≤–µ—Ä—Å–∏—è {version})"
    return f"üìÖ –ì—Ä–∞—Ñ–∏–∫ –≤—ã–µ–∑–¥–æ–≤ —Å {d_from:%d.%m.%Y} –ø–æ {d_to:%d.%m.%Y} –≥"


def write_schedule_summary_to_sheet(version: int, approvals: List[sqlite3.Row]) -> None:
    service = get_sheets_service()
    if service is None:
        log.error(
            "Google Sheets —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Äì –Ω–µ –º–æ–≥—É –∑–∞–ø–∏—Å–∞—Ç—å –∏—Ç–æ–≥ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è –≤ '–ì—Ä–∞—Ñ–∏–∫'."
        )
    else:
        sheet_name = "–ì—Ä–∞—Ñ–∏–∫"
        header = build_schedule_header(version, approvals)
        rows = [
            [""],
            [header],
            ["–°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–æ –≤—Å–µ–º–∏:"],
        ]
        for r in approvals:
            rows.append(
                [f"{r['approver']} ‚Äî {_format_dt(r['decided_at'])} ‚úÖ"]
            )

        body = {"values": rows}

        try:
            service.spreadsheets().values().append(
                spreadsheetId=GSHEETS_SPREADSHEET_ID,
                range=f"'{sheet_name}'!A1",
                valueInputOption="USER_ENTERED",
                insertDataOption="INSERT_ROWS",
                body=body,
            ).execute()
            log.info(
                "–ò—Ç–æ–≥ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è –≤–µ—Ä—Å–∏–∏ %s –¥–æ–ø–∏—Å–∞–Ω –≤ –ª–∏—Å—Ç '%s'.",
                version,
                sheet_name,
            )
        except Exception as e:
            log.error(
                "–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –∏—Ç–æ–≥–∞ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è –≤ –ª–∏—Å—Ç '%s': %s", sheet_name, e
            )


def build_schedule_text(is_admin_flag: bool, settings: dict) -> str:
    version = get_schedule_version(settings)
    approvals = get_schedule_approvals(version)
    approvers = get_current_approvers(settings)

    header = build_schedule_header(version, approvals)
    lines = [header, ""]

    if not approvers:
        lines.append("–°–æ–≥–ª–∞—Å—É—é—â–∏–µ –Ω–µ –Ω–∞–∑–Ω–∞—á–µ–Ω—ã.")
        return "\n".join(lines)

    pending: List[str] = []
    approved: List[sqlite3.Row] = []
    rework: List[sqlite3.Row] = []

    by_approver = {r["approver"]: r for r in approvals}

    for a in approvers:
        r = by_approver.get(a)
        if not r or r["status"] == "pending":
            pending.append(a)
        elif r["status"] == "approved":
            approved.append(r)
        elif r["status"] == "rework":
            rework.append(r)

    if rework:
        lines.append("–û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –Ω–∞ –¥–æ—Ä–∞–±–æ—Ç–∫—É:")
        for r in rework:
            lines.append(
                f"‚Ä¢ {r['approver']} ‚Äî {_format_dt(r['decided_at'])} (–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: {r['comment'] or '–Ω–µ—Ç'})"
            )
    elif pending:
        lines.append("–ù–∞ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–∏ —É:")
        for a in pending:
            lines.append(
                f"‚Ä¢ {a} ‚Äî –∑–∞–ø—Ä–æ—à–µ–Ω–æ {_format_dt(by_approver[a]['requested_at'])}"
            )
        if approved:
            lines.append("")
            lines.append("–£–∂–µ —Å–æ–≥–ª–∞—Å–æ–≤–∞–ª–∏:")
            for r in approved:
                lines.append(f"‚Ä¢ {r['approver']} ‚Äî {_format_dt(r['decided_at'])} ‚úÖ")
    else:
        lines.append("–°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–æ –≤—Å–µ–º–∏:")
        for r in approved:
            lines.append(f"‚Ä¢ {r['approver']} ‚Äî {_format_dt(r['decided_at'])} ‚úÖ")

    return "\n".join(lines)


# -------------------------------------------------
# –ó–∞–º–µ—á–∞–Ω–∏—è: –ù–ï –£–°–¢–†–ê–ù–ï–ù–´
# -------------------------------------------------
def build_remarks_not_done_text(df: pd.DataFrame) -> str:
    COLS = {
        "case": "I",
        "pb": "Q",
        "pb_zk": "R",
        "ar": "X",
        "eom": "AD",
    }

    TITLES = {
        "pb": "–û—Ç–º–µ—Ç–∫–∞ –æ–± —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–∏ –∑–∞–º–µ—á–∞–Ω–∏–π –ü–ë –¥–∞/–Ω–µ—Ç",
        "pb_zk": "–û—Ç–º–µ—Ç–∫–∞ –æ–± —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–∏ –∑–∞–º–µ—á–∞–Ω–∏–π –ü–ë –≤ –ó–ö –ö–ù–î –¥–∞/–Ω–µ—Ç",
        "ar": "–û—Ç–º–µ—Ç–∫–∞ –æ–± —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–∏ –Ω–∞—Ä—É—à–µ–Ω–∏–π –ê–†, –ú–ú–ì–ù, –ê–ì–û –¥–∞/–Ω–µ—Ç",
        "eom": "–û—Ç–º–µ—Ç–∫–∞ –æ–± —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–∏ –Ω–∞—Ä—É—à–µ–Ω–∏–π –≠–û–ú –¥–∞/–Ω–µ—Ç",
    }

    idx_case = excel_col_to_index(COLS["case"])
    idx_pb = excel_col_to_index(COLS["pb"])
    idx_pb_zk = excel_col_to_index(COLS["pb_zk"])
    idx_ar = excel_col_to_index(COLS["ar"])
    idx_eom = excel_col_to_index(COLS["eom"])

    def is_net(val):
        if val is None:
            return False
        text = str(val).lower().replace("\n", " ").strip()
        if not text or text in {"-", "–Ω/–¥"}:
            return False
        return text.startswith("–Ω–µ—Ç")

    grouped: Dict[str, Dict[str, Any]] = {}

    for _, row in df.iterrows():
        case = str(row.iloc[idx_case]).strip() if idx_case < len(row) else ""
        if not case:
            continue

        sheet_src = ""
        try:
            sheet_src = str(row.get("_remarks_sheet", "")).strip()
        except Exception:
            sheet_src = ""

        flags = {
            "pb": is_net(row.iloc[idx_pb]) if idx_pb < len(row) else False,
            "pb_zk": is_net(row.iloc[idx_pb_zk]) if idx_pb_zk < len(row) else False,
            "ar": is_net(row.iloc[idx_ar]) if idx_ar < len(row) else False,
            "eom": is_net(row.iloc[idx_eom]) if idx_eom < len(row) else False,
        }

        if not any(flags.values()):
            continue

        if case not in grouped:
            grouped[case] = {"pb": set(), "ar": set(), "eom": set(), "sheets": set()}

        if sheet_src:
            grouped[case]["sheets"].add(sheet_src)

        if flags["pb"]:
            grouped[case]["pb"].add(TITLES["pb"])
        if flags["pb_zk"]:
            grouped[case]["pb"].add(TITLES["pb_zk"])
        if flags["ar"]:
            grouped[case]["ar"].add(TITLES["ar"])
        if flags["eom"]:
            grouped[case]["eom"].add(TITLES["eom"])

    if not grouped:
        return "–í–æ –≤—Å–µ—Ö —Å—Ç—Ä–æ–∫–∞—Ö –Ω–µ—Ç —Å—Ç–∞—Ç—É—Å–æ–≤ ¬´–Ω–µ—Ç¬ª."

    sheets_present: List[str] = []
    try:
        sheets_present = sorted(
            {
                str(x).strip()
                for x in df.get("_remarks_sheet", pd.Series([])).dropna().unique().tolist()
                if str(x).strip()
            }
        )
    except Exception:
        sheets_present = []

    sheets_line = " / ".join(sheets_present) if sheets_present else "‚Äî"

    lines = [
        "–°—Ç—Ä–æ–∫–∏ —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º ¬´–ù–ï –£–°–¢–†–ê–ù–ï–ù–´ (–Ω–µ—Ç)¬ª",
        "",
        "–õ–∏—Å—Ç—ã: " + sheets_line,
        "",
    ]

    for case, blocks in grouped.items():
        parts = []
        if blocks["pb"]:
            parts.append("–ü–æ–∂–∞—Ä–Ω–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: " + ", ".join(b + " - –Ω–µ—Ç" for b in blocks["pb"]))
        if blocks["ar"]:
            parts.append("–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, –ú–ú–ì–ù, –ê–ì–û: " + ", ".join(b + " - –Ω–µ—Ç" for b in blocks["ar"]))
        if blocks["eom"]:
            parts.append("–≠–ª–µ–∫—Ç—Ä–æ—Å–Ω–∞–±–∂–µ–Ω–∏–µ: " + ", ".join(b + " - –Ω–µ—Ç" for b in blocks["eom"]))

        src = ""
        if blocks.get("sheets"):
            src = " (" + " / ".join(sorted(blocks["sheets"])) + ")"

        lines.append(f"‚Ä¢ {case}{src} ‚Äî " + "; ".join(parts))

    return "\n".join(lines)

def build_remarks_not_done_by_onzs(df: pd.DataFrame, onzs_value: str) -> str:
    onzs_idx = get_col_index_by_header(df, "–æ–Ω–∑—Å", "D")
    if onzs_idx is None:
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å—Ç–æ–ª–±–µ—Ü –û–ù–∑–° –≤ —Ñ–∞–π–ª–µ –∑–∞–º–µ—á–∞–Ω–∏–π."

    COLS = {
        "case": "I",
        "pb": "Q",
        "pb_zk": "R",
        "ar": "X",
        "eom": "AD",
    }

    TITLES = {
        "pb": "–û—Ç–º–µ—Ç–∫–∞ –æ–± —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–∏ –∑–∞–º–µ—á–∞–Ω–∏–π –ü–ë –¥–∞/–Ω–µ—Ç",
        "pb_zk": "–û—Ç–º–µ—Ç–∫–∞ –æ–± —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–∏ –∑–∞–º–µ—á–∞–Ω–∏–π –ü–ë –≤ –ó–ö –ö–ù–î –¥–∞/–Ω–µ—Ç",
        "ar": "–û—Ç–º–µ—Ç–∫–∞ –æ–± —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–∏ –Ω–∞—Ä—É—à–µ–Ω–∏–π –ê–†, –ú–ú–ì–ù, –ê–ì–û –¥–∞/–Ω–µ—Ç",
        "eom": "–û—Ç–º–µ—Ç–∫–∞ –æ–± —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–∏ –Ω–∞—Ä—É—à–µ–Ω–∏–π –≠–û–ú –¥–∞/–Ω–µ—Ç",
    }

    idx_case = excel_col_to_index(COLS["case"])
    idx_pb = excel_col_to_index(COLS["pb"])
    idx_pb_zk = excel_col_to_index(COLS["pb_zk"])
    idx_ar = excel_col_to_index(COLS["ar"])
    idx_eom = excel_col_to_index(COLS["eom"])

    def is_net(val):
        if val is None:
            return False
        text = str(val).lower().replace("\n", " ").strip()
        if not text or text in {"-", "–Ω/–¥"}:
            return False
        return text.startswith("–Ω–µ—Ç")

    grouped: Dict[str, Dict[str, Any]] = {}

    num_str = normalize_onzs_value(onzs_value)

    for _, row in df.iterrows():
        try:
            val_raw = row.iloc[onzs_idx]
        except Exception:
            val_raw = None

        val_norm = normalize_onzs_value(val_raw)
        if val_norm != num_str:
            continue

        case = ""
        try:
            case = str(row.iloc[idx_case]).strip()
        except Exception:
            pass

        if not case:
            continue

        sheet_src = ""
        try:
            sheet_src = str(row.get("_remarks_sheet", "")).strip()
        except Exception:
            sheet_src = ""

        flags = {
            "pb": is_net(row.iloc[idx_pb]) if idx_pb < len(row) else False,
            "pb_zk": is_net(row.iloc[idx_pb_zk]) if idx_pb_zk < len(row) else False,
            "ar": is_net(row.iloc[idx_ar]) if idx_ar < len(row) else False,
            "eom": is_net(row.iloc[idx_eom]) if idx_eom < len(row) else False,
        }

        if not any(flags.values()):
            continue

        if case not in grouped:
            grouped[case] = {"pb": set(), "ar": set(), "eom": set(), "sheets": set()}

        if sheet_src:
            grouped[case]["sheets"].add(sheet_src)

        if flags["pb"]:
            grouped[case]["pb"].add(TITLES["pb"])
        if flags["pb_zk"]:
            grouped[case]["pb"].add(TITLES["pb_zk"])
        if flags["ar"]:
            grouped[case]["ar"].add(TITLES["ar"])
        if flags["eom"]:
            grouped[case]["eom"].add(TITLES["eom"])

    sheets_present: List[str] = []
    try:
        sheets_present = sorted(
            {
                str(x).strip()
                for x in df.get("_remarks_sheet", pd.Series([])).dropna().unique().tolist()
                if str(x).strip()
            }
        )
    except Exception:
        sheets_present = []

    sheets_line = " / ".join(sheets_present) if sheets_present else "‚Äî"

    if not grouped:
        return (
            f"–ü–æ –û–ù–∑–° {onzs_value} –Ω–µ—Ç —Å—Ç—Ä–æ–∫ —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º ¬´–Ω–µ—Ç¬ª.\n"
            f"–õ–∏—Å—Ç—ã: {sheets_line}"
        )

    lines = [
        f"–°—Ç—Ä–æ–∫–∏ —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º ¬´–ù–ï –£–°–¢–†–ê–ù–ï–ù–´ (–Ω–µ—Ç)¬ª –ø–æ –û–ù–∑–° {onzs_value}",
        "",
        "–õ–∏—Å—Ç—ã: " + sheets_line,
        "",
    ]

    for case, blocks in grouped.items():
        parts = []
        if blocks["pb"]:
            parts.append("–ü–æ–∂–∞—Ä–Ω–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: " + ", ".join(b + " - –Ω–µ—Ç" for b in blocks["pb"]))
        if blocks["ar"]:
            parts.append("–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, –ú–ú–ì–ù, –ê–ì–û: " + ", ".join(b + " - –Ω–µ—Ç" for b in blocks["ar"]))
        if blocks["eom"]:
            parts.append("–≠–ª–µ–∫—Ç—Ä–æ—Å–Ω–∞–±–∂–µ–Ω–∏–µ: " + ", ".join(b + " - –Ω–µ—Ç" for b in blocks["eom"]))

        src = ""
        if blocks.get("sheets"):
            src = " (" + " / ".join(sorted(blocks["sheets"])) + ")"

        lines.append(f"‚Ä¢ {case}{src} ‚Äî " + "; ".join(parts))

    return "\n".join(lines)

def build_case_cards_text(df: pd.DataFrame, case_no: str) -> str:
    case_no = case_no.strip()
    if not case_no:
        return "–ù–æ–º–µ—Ä –¥–µ–ª–∞ –Ω–µ —É–∫–∞–∑–∞–Ω."

    target = normalize_case_number(case_no)

    idx_case = get_case_col_index(df)
    if idx_case is None:
        return (
            "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å—Ç–æ–ª–±–µ—Ü ¬´–ù–æ–º–µ—Ä –¥–µ–ª–∞ (I)¬ª –≤ —Ñ–∞–π–ª–µ –∑–∞–º–µ—á–∞–Ω–∏–π. "
            "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ª–∏—Å—Ç–∞."
        )

    idx_date = get_col_index_by_header(df, "–¥–∞—Ç–∞ –≤—ã–µ–∑–¥–∞", "B")
    idx_onzs = get_col_index_by_header(df, "–æ–Ω–∑—Å", "D")
    idx_dev = get_col_index_by_header(df, "–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∑–∞—Å—Ç—Ä–æ–π—â–∏–∫–∞", "F")
    idx_obj = get_col_index_by_header(df, "–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞", "G")
    idx_addr = get_col_index_by_header(df, "—Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–π –∞–¥—Ä–µ—Å", "H")

    idx_pb = excel_col_to_index("Q")
    idx_pb_zk = excel_col_to_index("R")
    idx_ar = excel_col_to_index("X")
    idx_eom = excel_col_to_index("AD")

    mask: List[bool] = []
    for _, row in df.iterrows():
        try:
            val_raw = row.iloc[idx_case]
        except Exception:
            val_raw = None
        val_norm = normalize_case_number(val_raw)
        mask.append(val_norm == target)

    if not any(mask):
        return (
            f"–ü–æ –Ω–æ–º–µ—Ä—É –¥–µ–ª–∞ {case_no} –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.\n"
            f"–õ–∏—Å—Ç—ã: " + " / ".join([s for s in get_remarks_sheet_candidates()])
        )

    df_sel = df[mask]


    # –õ–∏—Å—Ç—ã (–∏—Å—Ç–æ—á–Ω–∏–∫–∏) –≤ –≤—ã–±–æ—Ä–∫–µ
    sheets_sel: List[str] = []
    try:
        sheets_sel = sorted(
            {
                str(x).strip()
                for x in df_sel.get("_remarks_sheet", pd.Series([])).dropna().unique().tolist()
                if str(x).strip()
            }
        )
    except Exception:
        sheets_sel = []
    sheets_line = " / ".join(sheets_sel) if sheets_sel else "‚Äî"

    lines: List[str] = [
        f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –ø–æ –Ω–æ–º–µ—Ä—É –¥–µ–ª–∞: {case_no}",
        "",
        "–õ–∏—Å—Ç—ã: " + sheets_line,
        "",
    ]
    for _, row in df_sel.iterrows():

        def safe(idx: Optional[int]) -> str:
            if idx is None:
                return ""
            try:
                return str(row.iloc[idx]).strip()
            except Exception:
                return ""

        date_raw = safe(idx_date)
        date_fmt = date_raw
        try:
            if date_raw:
                dt = pd.to_datetime(date_raw, dayfirst=True, errors="ignore")
                if isinstance(dt, (datetime, pd.Timestamp)):
                    date_fmt = dt.strftime("%d.%m.%Y")
        except Exception:
            pass

        onzs_val = safe(idx_onzs)
        dev_val = safe(idx_dev)
        obj_val = safe(idx_obj)
        addr_val = safe(idx_addr)

        def safe_status(idx: int) -> str:
            try:
                if idx < len(row):
                    return str(row.iloc[idx]).strip()
            except Exception:
                pass
            return ""

        pb_val = safe_status(idx_pb)
        pb_zk_val = safe_status(idx_pb_zk)
        ar_val = safe_status(idx_ar)
        eom_val = safe_status(idx_eom)

        lines.append(f"–ù–æ–º–µ—Ä –¥–µ–ª–∞: {case_no}")
        try:
            sheet_src = str(row.get("_remarks_sheet", "")).strip()
        except Exception:
            sheet_src = ""
        if sheet_src:
            lines.append(f"–õ–∏—Å—Ç: {sheet_src}")
        if date_fmt:
            lines.append(f"–î–∞—Ç–∞ –≤—ã–µ–∑–¥–∞: {date_fmt}")
        if onzs_val:
            lines.append(f"–û–ù–∑–°: {onzs_val}")
        if dev_val:
            lines.append(f"–ó–∞—Å—Ç—Ä–æ–π—â–∏–∫: {dev_val}")
        if obj_val:
            lines.append(f"–û–±—ä–µ–∫—Ç: {obj_val}")
        if addr_val:
            lines.append(f"–ê–¥—Ä–µ—Å: {addr_val}")

        lines.append("")
        lines.append(f"–ü–ë: {pb_val or '-'}")
        lines.append(f"–ü–ë –ó–ö: {pb_zk_val or '-'}")
        lines.append(f"–ê–†/–ú–ú–ì–ù/–ê–ì–û: {ar_val or '-'}")
        lines.append(f"–≠–û–ú: {eom_val or '-'}")
        lines.append("")
        lines.append("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
        lines.append("")

    return "\n".join(lines)


# -------------------------------------------------
# –û—Ç–ø—Ä–∞–≤–∫–∞ –¥–ª–∏–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
# -------------------------------------------------
async def send_long_text(chat, text: str, chunk_size=3500):
    lines = text.split("\n")
    buf = ""

    for line in lines:
        if len(buf) + len(line) + 1 > chunk_size:
            await chat.send_message(buf)
            buf = line
        else:
            buf = buf + "\n" + line if buf else line

    if buf:
        await chat.send_message(buf)


# -------------------------------------------------
# –õ–∏—Å—Ç –∑–∞–º–µ—á–∞–Ω–∏–π (–ø–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ª–µ—Ç)
# -------------------------------------------------

def get_remarks_sheet_candidates() -> List[str]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ª–∏—Å—Ç–æ–≤ –∑–∞–º–µ—á–∞–Ω–∏–π.
    –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –±–µ—Ä—ë–º —Ç–µ–∫—É—â–∏–π –≥–æ–¥ –∏ –ø—Ä–µ–¥—ã–¥—É—â–∏–π –≥–æ–¥ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2026 –∏ 2025),
    —á—Ç–æ–±—ã –∑–∞–º–µ—á–∞–Ω–∏—è –ø–æ–¥—Ç—è–≥–∏–≤–∞–ª–∏—Å—å —Å—Ä–∞–∑—É –∑–∞ –¥–≤–∞ –≥–æ–¥–∞.
    """
    y = local_now().year
    years = [y, y - 1]
    return [f"–ü–ë, –ê–†,–ú–ú–ì–ù, –ê–ì–û ({yy})" for yy in years]


def get_remarks_df_current() -> Optional[pd.DataFrame]:
    """
    –ß–∏—Ç–∞–µ—Ç –ª–∏—Å—Ç(—ã) –∑–∞–º–µ—á–∞–Ω–∏–π –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã GSHEETS_SPREADSHEET_ID.

    –í–∞–∂–Ω–æ:
    - –±–æ—Ç –ø–æ–¥—Ç—è–≥–∏–≤–∞–µ—Ç –∑–∞–º–µ—á–∞–Ω–∏—è –Ω–µ —Ç–æ–ª—å–∫–æ –∑–∞ —Ç–µ–∫—É—â–∏–π –≥–æ–¥, –Ω–æ –∏ –∑–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2026 + 2025);
    - —Å—Ç—Ä–æ–∫–∏ –ø–æ–º–µ—á–∞—é—Ç—Å—è —Å–ª—É–∂–µ–±–Ω–æ–π –∫–æ–ª–æ–Ω–∫–æ–π _remarks_sheet, —á—Ç–æ–±—ã –≤ –æ—Ç–≤–µ—Ç–∞—Ö –º–æ–∂–Ω–æ –±—ã–ª–æ –ø–æ–∫–∞–∑–∞—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫.
    """
    url = build_export_url(GSHEETS_SPREADSHEET_ID)

    try:
        resp = requests.get(url, timeout=30)
        resp.raise_for_status()
        xls = pd.ExcelFile(BytesIO(resp.content))

        frames: List[pd.DataFrame] = []
        for sheet in get_remarks_sheet_candidates():
            if sheet not in xls.sheet_names:
                continue
            df = pd.read_excel(xls, sheet_name=sheet)
            df = df.dropna(how="all")
            if df.empty:
                continue
            df["_remarks_sheet"] = sheet
            frames.append(df)

        if not frames:
            fallback_sheet = get_current_remarks_sheet_name()
            if fallback_sheet not in xls.sheet_names:
                log.error("–í —Ñ–∞–π–ª–µ –Ω–µ—Ç –ª–∏—Å—Ç–æ–≤ –∑–∞–º–µ—á–∞–Ω–∏–π: %s", ", ".join(get_remarks_sheet_candidates()))
                return None
            df = pd.read_excel(xls, sheet_name=fallback_sheet)
            df["_remarks_sheet"] = fallback_sheet
            return df

        return pd.concat(frames, ignore_index=True)

    except Exception as e:
        log.error("–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ª–∏—Å—Ç–∞(–æ–≤) –∑–∞–º–µ—á–∞–Ω–∏–π: %s", e)
        return None


# -------------------------------------------------
# –ò—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏: —á—Ç–µ–Ω–∏–µ, —Ñ–∏–ª—å—Ç—Ä, —Ç–µ–∫—Å—Ç, Excel
# -------------------------------------------------
def refresh_final_checks_local_file() -> bool:
    """
    –û–±–Ω–æ–≤–ª—è–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫:
    - —É–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª (–µ—Å–ª–∏ –µ—Å—Ç—å);
    - —Å–∫–∞—á–∏–≤–∞–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é –∏–∑ Google Sheets –ø–æ FINAL_CHECKS_SPREADSHEET_ID.
    """
    sheet_id = FINAL_CHECKS_SPREADSHEET_ID
    if not sheet_id:
        log.error("FINAL_CHECKS_SPREADSHEET_ID –Ω–µ –∑–∞–¥–∞–Ω.")
        return False

    url = build_export_url(sheet_id)
    path = FINAL_CHECKS_LOCAL_PATH

    # —É–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª, –µ—Å–ª–∏ –µ—Å—Ç—å
    try:
        if os.path.exists(path):
            os.remove(path)
    except Exception as e:
        log.warning(
            "–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ %s: %s",
            path,
            e,
        )

    try:
        resp = requests.get(url, timeout=30)
        resp.raise_for_status()
    except Exception as e:
        log.error("–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è Excel (–∏—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏): %s", e)
        return False

    try:
        with open(path, "wb") as f:
            f.write(resp.content)
        log.info("–§–∞–π–ª –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –ª–æ–∫–∞–ª—å–Ω–æ: %s", path)
        return True
    except Exception as e:
        log.error(
            "–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ %s: %s",
            path,
            e,
        )
        return False


def get_final_checks_df() -> Optional[pd.DataFrame]:
    """
    –ß–∏—Ç–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ FINAL_CHECKS_LOCAL_PATH,
    –∫–æ—Ç–æ—Ä—ã–π –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –ø—Ä–∏ –≤—Ö–æ–¥–µ –≤ —Ä–∞–∑–¥–µ–ª ¬´–ò—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏¬ª.
    –°–æ–±–∏—Ä–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å–æ –≤—Å–µ—Ö –ª–∏—Å—Ç–æ–≤ –∫–Ω–∏–≥–∏ –∏ —Å–∫–ª–µ–∏–≤–∞–µ—Ç –∏—Ö –≤ –æ–¥–∏–Ω DataFrame.
    """
    path = FINAL_CHECKS_LOCAL_PATH
    if not path:
        log.error("FINAL_CHECKS_LOCAL_PATH –Ω–µ –∑–∞–¥–∞–Ω.")
        return None

    if not os.path.exists(path):
        log.error("–õ–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω: %s", path)
        return None

    try:
        xls = pd.ExcelFile(path)
        if not xls.sheet_names:
            log.error("–§–∞–π–ª –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ –ø—É—Å—Ç (–Ω–µ—Ç –ª–∏—Å—Ç–æ–≤).")
            return None

        frames: List[pd.DataFrame] = []
        for sheet_name in xls.sheet_names:
            try:
                df_sheet = pd.read_excel(xls, sheet_name=sheet_name)
                df_sheet = df_sheet.dropna(how="all")
                if not df_sheet.empty:
                    frames.append(df_sheet)
            except Exception as e:
                log.warning(
                    "–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ª–∏—Å—Ç–∞ '%s' –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫: %s",
                    sheet_name,
                    e,
                )

        if not frames:
            log.error("–í–æ –≤—Å–µ—Ö –ª–∏—Å—Ç–∞—Ö –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö.")
            return None

        df = pd.concat(frames, ignore_index=True)
        df = df.reset_index(drop=True)
        return df
    except Exception as e:
        log.error("–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫: %s", e)
        return None




def _parse_final_date(val) -> Optional[date]:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ —Å—Ç–æ–ª–±—Ü–æ–≤ O/P –≤ –¥–∞—Ç—É.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
    - datetime / Timestamp;
    - —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞—Ç—ã ("22.12.2025", "22.12.25", "22.12", "22.12.2025 –≥.");
    - —á–∏—Å–ª–æ–≤—ã–µ Excel‚Äë—Å–µ—Ä–∏–π–Ω—ã–µ –¥–∞—Ç—ã (—Ü–µ–ª–æ–µ/float).
    –í—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç date –∏–ª–∏ None.
    """
    # 1. –ü—É—Å—Ç—ã–µ / –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
    if val is None or (isinstance(val, float) and pd.isna(val)) or (not isinstance(val, (int, float, datetime, pd.Timestamp)) and pd.isna(val)):
        return None

    # 2. –£–∂–µ datetime / Timestamp
    if isinstance(val, (datetime, pd.Timestamp)):
        try:
            year = val.year
        except Exception:
            return None
        if year < 1900 or year > 2100:
            return None
        return val.date()

    # 3. –ß–∏—Å—Ç–æ —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è ‚Äî Excel serial (float/int)
    if isinstance(val, (int, float)):
        serial = float(val)
        # –æ—Ç—Å–µ–∫–∞–µ–º –∑–∞–≤–µ–¥–æ–º–æ –º—É—Å–æ—Ä–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–∫–∞–∫ –≤ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è—Ö openpyxl)
        if 20000 <= serial <= 80000:  # ~1945‚Äì2120 –≥–≥.
            excel_epoch = date(1899, 12, 30)
            return excel_epoch + timedelta(days=int(serial))
        else:
            return None

    # 4. –í—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ ‚Äî –ø—Ä–æ–±—É–µ–º –ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ —Å—Ç—Ä–æ–∫—É
    s = str(val).strip()
    if not s:
        return None

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä–æ–∫–∏
    s_norm = (
        s.replace("–≥.", "")
         .replace("–≥", "")
         .replace("\xa0", "")
         .replace(" ", "")
         .replace("‚Äì", "-")
         .replace("‚Äî", "-")
    )

    # –ï—Å–ª–∏ –æ—Å—Ç–∞–ª–∞—Å—å —Ç–æ–ª—å–∫–æ 1‚Äì2 —Ü–∏—Ñ—Ä—ã ‚Äî —ç—Ç–æ –Ω–µ –¥–∞—Ç–∞
    if re.fullmatch(r"\d{1,2}$", s_norm):
        return None

    # 5. –Ø–≤–Ω—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞—Ç—ã
    for fmt in ("%d.%m.%Y", "%d.%m.%y", "%d.%m"):
        try:
            dt_obj = datetime.strptime(s_norm, fmt)
            if fmt == "%d.%m":
                dt_obj = dt_obj.replace(year=date.today().year)
            if dt_obj.year < 1900 or dt_obj.year > 2100:
                return None
            return dt_obj.date()
        except ValueError:
            continue

    # 6. –°—Ç—Ä–æ–∫–æ–≤—ã–π Excel‚Äë—Å–µ—Ä–∏–π–Ω—ã–π –Ω–æ–º–µ—Ä
    if re.fullmatch(r"\d{4,6}", s_norm):
        try:
            serial = float(s_norm)
            if 20000 <= serial <= 80000:
                excel_epoch = date(1899, 12, 30)
                return excel_epoch + timedelta(days=int(serial))
        except Exception:
            pass

    return None


# -------------------------------------------------
# üö® –ö—Ä–∞—Å–Ω—ã–µ –ª–∞–º–ø–æ—á–∫–∏ ‚Äî –∑–∞–≥—Ä—É–∑–∫–∞ Excel –∏ BI-–ø–∞–Ω–µ–ª—å
# -------------------------------------------------

REDLAMPS_TOLERANCE_DAYS_DEFAULT = 5

REDLAMPS_LOW_RISK_KEYWORDS = [
    "–æ—á–∏—Å—Ç–Ω—ã–µ",
    "–∫–æ—Ç–µ–ª—å–Ω",
    "–¥–æ—Ä–æ–≥",
    "–º–æ—Å—Ç",
    "—Ç–ø",
    "–ª–∏–Ω–µ–π–Ω",
    "–≤–∑—É",
    "–∫–∞–Ω–∞–ª–∏–∑–∞—Ü",
    "–ª—ç–ø",
    "–∏–Ω–∂–µ–Ω–µ—Ä–Ω",
]

def _rl_has_text(val: Any) -> bool:
    if val is None:
        return False
    try:
        if isinstance(val, float) and pd.isna(val):
            return False
    except Exception:
        pass
    s = str(val).strip()
    if not s or s.lower() == "nan":
        return False
    return True


def _rl_cell_filled(val: Any) -> bool:
    """–°—Ç—Ä–æ–≥–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç–∏ —è—á–µ–π–∫–∏ (–¥–ª—è O/T)."""
    if val is None:
        return False
    try:
        if pd.isna(val):
            return False
    except Exception:
        pass
    s = str(val).strip()
    if not s:
        return False
    bad = {"nan", "none", "null", "<na>", "nat", "-", "‚Äî"}
    if s.lower() in bad:
        return False
    return True

def _rl_contains(val: Any, needle: str) -> bool:
    if not _rl_has_text(val):
        return False
    return needle.lower() in str(val).lower()

def _rl_contains_any_keywords(val: Any, keywords: List[str]) -> bool:
    if not _rl_has_text(val):
        return False
    s = str(val).lower()
    return any(k in s for k in keywords)

def redlamps_menu_inline() -> InlineKeyboardMarkup:
    return InlineKeyboardMarkup(
        [
            [InlineKeyboardButton("üì§ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª", callback_data="redlamps_upload")],
            [InlineKeyboardButton("üìÖ –í—ã–±—Ä–∞—Ç—å –ø–µ—Ä–∏–æ–¥ (K‚ÄìL)", callback_data="redlamps_period")],
            [InlineKeyboardButton("üìä –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å BI-–ø–∞–Ω–µ–ª—å", callback_data="redlamps_build")],
            [InlineKeyboardButton("üóë –°–±—Ä–æ—Å–∏—Ç—å", callback_data="redlamps_reset")],
        ]
    )

def _redlamps_process_bytes(
    xlsx_bytes: bytes,
    date_from: date,
    date_to: date,
    tolerance_days: int = REDLAMPS_TOLERANCE_DAYS_DEFAULT,
) -> str:
    # —á–∏—Ç–∞–µ–º –±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤, —á—Ç–æ–±—ã —Ä–∞–±–æ—Ç–∞—Ç—å –ø–æ –±—É–∫–≤–∞–º –∫–æ–ª–æ–Ω–æ–∫ –∫–∞–∫ –≤ Excel
    df = pd.read_excel(BytesIO(xlsx_bytes), header=None)
    if df is None or df.empty:
        return "–§–∞–π–ª –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å Excel."

    # –ò–Ω–¥–µ–∫—Å—ã –∫–æ–ª–æ–Ω–æ–∫ (0-based) –ø–æ –±—É–∫–≤–∞–º Excel
    IDX_B = excel_col_to_index("B")
    IDX_E = excel_col_to_index("E")
    IDX_I = excel_col_to_index("I")
    IDX_K = excel_col_to_index("K")
    IDX_L = excel_col_to_index("L")
    IDX_O = excel_col_to_index("O")
    IDX_T = excel_col_to_index("T")
    IDX_AA = excel_col_to_index("AA")

    # –∑–∞—â–∏—Ç–∞ –æ—Ç —Ñ–∞–π–ª–æ–≤, –≥–¥–µ –º–µ–Ω—å—à–µ –∫–æ–ª–æ–Ω–æ–∫
    max_idx = max(IDX_B, IDX_E, IDX_I, IDX_K, IDX_L, IDX_O, IDX_T, IDX_AA)
    if len(df.columns) <= max_idx:
        return (
            "–í –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º —Ñ–∞–π–ª–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.\n"
            "–ù—É–∂–Ω–æ, —á—Ç–æ–±—ã –±—ã–ª–∏ –∫–æ–ª–æ–Ω–∫–∏ –∫–∞–∫ –º–∏–Ω–∏–º—É–º –¥–æ AA (–≤–∫–ª—é—á–∞—è B, E, I, K, L, O, T, AA)."
        )

    # 1) –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ –ø–æ AA: ¬´–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞¬ª
    aa = df.iloc[:, IDX_AA]
    mask_aa = aa.apply(lambda v: _rl_contains(v, "–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞"))
    df = df[~mask_aa]

    # 2) –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ –ø–æ E (–Ω–∏–∑–∫–∏–π —Ä–∏—Å–∫)
    e = df.iloc[:, IDX_E]
    mask_low_risk = e.apply(lambda v: _rl_contains_any_keywords(v, REDLAMPS_LOW_RISK_KEYWORDS))
    df = df[~mask_low_risk]

    # 3) –£–¥–∞–ª—è–µ–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –ø–æ I –∫—Ä–æ–º–µ ¬´–ü—Ä–æ–≥—Ä–∞–º–º–∞ –ø—Ä–æ–≤–µ—Ä–æ–∫¬ª
    i_col = df.iloc[:, IDX_I]
    mask_program = i_col.apply(lambda v: _rl_contains(v, "–ü—Ä–æ–≥—Ä–∞–º–º–∞ –ø—Ä–æ–≤–µ—Ä–æ–∫"))
    df = df[mask_program]

    if df.empty:
        return (
            "–ü–æ—Å–ª–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤ (AA/–Ω–∏–∑–∫–∏–π —Ä–∏—Å–∫ E/—Ç–æ–ª—å–∫–æ ¬´–ü—Ä–æ–≥—Ä–∞–º–º–∞ –ø—Ä–æ–≤–µ—Ä–æ–∫¬ª –≤ I) "
            "–Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å —Å—Ç—Ä–æ–∫."
        )

    # 4) –§–∏–ª—å—Ç—Ä –ø–æ –ø–µ—Ä–∏–æ–¥—É K/L —Å –¥–æ–ø—É—Å–∫–æ–º ¬±N –¥–Ω–µ–π
    k_raw = df.iloc[:, IDX_K]
    l_raw = df.iloc[:, IDX_L]

    k_dates = k_raw.apply(_parse_final_date)
    l_dates = l_raw.apply(_parse_final_date)

    start = date_from - timedelta(days=tolerance_days)
    end = date_to + timedelta(days=tolerance_days)

    def _in_range(d: Optional[date]) -> bool:
        if not d:
            return False
        return start <= d <= end

    mask_period = k_dates.apply(_in_range) | l_dates.apply(_in_range)
    df = df[mask_period]

    if df.empty:
        return (
            f"–ü–æ –ø–µ—Ä–∏–æ–¥—É {date_from:%d.%m.%Y} ‚Äî {date_to:%d.%m.%Y} (¬±{tolerance_days} –¥–Ω–µ–π) "
            "–Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."
        )

    # 5) –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –Ω–æ–º–µ—Ä—É –¥–µ–ª–∞ (B) + –ø–æ–¥—Å—á—ë—Ç—ã O/T
    stats: Dict[str, Dict[str, int]] = {}
    for _, row in df.iterrows():
        case_norm = normalize_case_number(row.iloc[IDX_B])
        if not case_norm:
            continue

        acts_inc = 1 if _rl_cell_filled(row.iloc[IDX_O]) else 0
        prot_inc = 1 if _rl_cell_filled(row.iloc[IDX_T]) else 0

        if case_norm not in stats:
            stats[case_norm] = {"acts": 0, "protocols": 0}

        stats[case_norm]["acts"] += acts_inc
        stats[case_norm]["protocols"] += prot_inc

    if not stats:
        return "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –Ω–æ–º–µ—Ä–∞ –¥–µ–ª (–∫–æ–ª–æ–Ω–∫–∞ B) –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤."

    # 6) BI-–ø–∞–Ω–µ–ª—å
    total_cases = len(stats)
    total_acts = sum(v["acts"] for v in stats.values())
    total_prot = sum(v["protocols"] for v in stats.values())
    bad = 0

    lines: List[str] = []
    lines.append("üö® –ö—Ä–∞—Å–Ω—ã–µ –ª–∞–º–ø–æ—á–∫–∏ ‚Äî BI-–ø–∞–Ω–µ–ª—å")
    lines.append(f"–ü–µ—Ä–∏–æ–¥: {date_from:%d.%m.%Y} ‚Äî {date_to:%d.%m.%Y} (¬±{tolerance_days} –¥–Ω–µ–π)")
    lines.append(f"–î–µ–ª: {total_cases} | –ê–∫—Ç–æ–≤: {total_acts} | –ü—Ä–æ—Ç–æ–∫–æ–ª–æ–≤: {total_prot}")
    lines.append("")

    for case_no in sorted(stats.keys()):
        acts = stats[case_no]["acts"]
        prots = stats[case_no]["protocols"]

        # –ø—Ä–∞–≤–∏–ª–æ: –µ—Å–ª–∏ –∞–∫—Ç–æ–≤ >= 4, –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–∏–Ω–∏–º—É–º floor(acts/2)
        if acts >= 4:
            need = acts // 2
            if prots < need:
                bad += 1
                lines.append(f"‚ùó {case_no} ‚Äî –ê–∫—Ç—ã: {acts}; –ü—Ä–æ—Ç–æ–∫–æ–ª—ã: {prots} (–Ω—É–∂–Ω–æ ‚â• {need})")
            else:
                lines.append(f"‚úÖ {case_no} ‚Äî –ê–∫—Ç—ã: {acts}; –ü—Ä–æ—Ç–æ–∫–æ–ª—ã: {prots}")
        else:
            lines.append(f"‚úÖ {case_no} ‚Äî –ê–∫—Ç—ã: {acts}; –ü—Ä–æ—Ç–æ–∫–æ–ª—ã: {prots}")

    lines.insert(4, f"–ü—Ä–æ–±–ª–µ–º–Ω—ã—Ö –¥–µ–ª: {bad}")

    return "\n".join(lines)
def filter_final_checks_df(
    df: pd.DataFrame,
    start_date: Optional[date] = None,
    end_date: Optional[date] = None,
    case_no: Optional[str] = None,
    basis: str = "any",  # "start" -> —Ç–æ–ª—å–∫–æ O, "end" -> —Ç–æ–ª—å–∫–æ P, "any" -> O –∏–ª–∏ P
) -> pd.DataFrame:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫:
    - –ø–æ –ø–µ—Ä–∏–æ–¥—É (O / P –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç basis);
    - –ø–æ –Ω–æ–º–µ—Ä—É –¥–µ–ª–∞.
    –†–∞–±–æ—Ç–∞–µ—Ç –≤ —Å–≤—è–∑–∫–µ —Å –∫–Ω–æ–ø–∫–∞–º–∏:
      ‚Ä¢ –ó–∞ –Ω–µ–¥–µ–ª—é / –ó–∞ –º–µ—Å—è—Ü (basis = "start" –∏–ª–∏ "end");
      ‚Ä¢ –í—ã–±—Ä–∞—Ç—å –ø–µ—Ä–∏–æ–¥;
      ‚Ä¢ –ü–æ –Ω–æ–º–µ—Ä—É –¥–µ–ª–∞.
    """
    if df is None or df.empty:
        return df.iloc[0:0].copy()

    # –ò–Ω–¥–µ–∫—Å—ã –∫–æ–ª–æ–Ω–æ–∫ –≤ –∏—Ç–æ–≥–æ–≤–æ–π —Ç–∞–±–ª–∏—Ü–µ:
    # B ‚Äî –Ω–æ–º–µ—Ä –¥–µ–ª–∞, O ‚Äî –¥–∞—Ç–∞ –Ω–∞—á–∞–ª–∞, P ‚Äî –¥–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è
    idx_case = excel_col_to_index("B")
    idx_start = excel_col_to_index("O")
    idx_end = excel_col_to_index("P")

    basis = (basis or "any").lower()
    if basis not in ("start", "end", "any"):
        basis = "any"

    result = df.copy()

    # ---------- –§–∏–ª—å—Ç—Ä –ø–æ –Ω–æ–º–µ—Ä—É –¥–µ–ª–∞ ----------
    if case_no:
        case_filter_norm = normalize_case_number(case_no)
        if not case_filter_norm:
            return result.iloc[0:0].copy()

        try:
            ser_case = result.iloc[:, idx_case]
        except Exception:
            # –µ—Å–ª–∏ –≤–¥—Ä—É–≥ –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ B ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π df
            return result.iloc[0:0].copy()

        def _norm(v):
            return normalize_case_number(v)

        mask_case = ser_case.apply(lambda v: _norm(v) == case_filter_norm)
        result = result[mask_case]

        if result.empty:
            return result

    # ---------- –§–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–∞–º O/P ----------
    if start_date or end_date:
        # –±–µ—Ä—ë–º "—Å—ã—Ä—ã–µ" –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ O –∏ P
        try:
            ser_start_raw = result.iloc[:, idx_start]
        except Exception:
            ser_start_raw = pd.Series([None] * len(result), index=result.index)

        try:
            ser_end_raw = result.iloc[:, idx_end]
        except Exception:
            ser_end_raw = pd.Series([None] * len(result), index=result.index)

        # –ø—Ä–∏–≤–æ–¥–∏–º –∫–∞–∂–¥–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∫ date (–∏–ª–∏ None)
        ser_start = ser_start_raw.apply(_parse_final_date)
        ser_end = ser_end_raw.apply(_parse_final_date)

        # –≤—ã–±–∏—Ä–∞–µ–º –±–∞–∑–æ–≤—É—é –¥–∞—Ç—É –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞
        if basis == "start":
            base = ser_start
        elif basis == "end":
            base = ser_end
        else:  # "any" ‚Äî —Å–Ω–∞—á–∞–ª–∞ O, –µ—Å–ª–∏ –ø—É—Å—Ç–æ, –±–µ—Ä—ë–º P
            base = ser_start.where(ser_start.notna(), ser_end)

        # –ø–µ—Ä–µ–≤–æ–¥–∏–º –≤ Timestamp, —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω
        base_dt = pd.to_datetime(base, errors="coerce")

        mask = pd.Series(True, index=result.index)
        if start_date:
            mask &= base_dt >= pd.to_datetime(start_date)
        if end_date:
            mask &= base_dt <= pd.to_datetime(end_date)

        result = result[mask]

    return result.reset_index(drop=True)



def compute_auto_period_for_final(df: pd.DataFrame, basis: str, mode: str) -> Optional[tuple[date, date]]:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–∏–æ–¥ –¥–ª—è –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫.

    basis:
        'start' ‚Äî –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–æ–ª–±–µ—Ü O (–¥–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –∏—Ç–æ–≥–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏)
        'end'   ‚Äî –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–æ–ª–±–µ—Ü P (–¥–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –∏—Ç–æ–≥–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏)

    mode:
        'week'  ‚Äî –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π –æ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–∞—Ç—ã
        'month' ‚Äî –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π –æ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–∞—Ç—ã
    """
    if df is None or df.empty:
        return None

    basis = (basis or "start").lower()
    if basis not in ("start", "end"):
        basis = "start"

    # –í—ã–±–∏—Ä–∞–µ–º –Ω—É–∂–Ω—ã–π —Å—Ç–æ–ª–±–µ—Ü (O –∏–ª–∏ P)
    idx_col = excel_col_to_index("O" if basis == "start" else "P")
    if not (0 <= idx_col < len(df.columns)):
        return None

    try:
        ser_raw = df.iloc[:, idx_col]
    except Exception:
        return None

    # –ü—Ä–∏–≤–æ–¥–∏–º –∑–Ω–∞—á–µ–Ω–∏—è –∫ –¥–∞—Ç–∞–º
    dates = ser_raw.apply(_parse_final_date).dropna()
    if dates.empty:
        return None

    last_date = max(dates)
    if mode == "week":
        start = last_date - timedelta(days=7)
    else:
        # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—á–∏—Ç–∞–µ–º –º–µ—Å—è—Ü –∫–∞–∫ 30 –¥–Ω–µ–π
        start = last_date - timedelta(days=30)
    end = last_date
    return start, end


def build_final_checks_text_filtered(
    df: pd.DataFrame,
    start_date: Optional[date] = None,
    end_date: Optional[date] = None,
    case_no: Optional[str] = None,
    header: str = "üìã –ò—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏",
    basis: str = "any",  # "start" / "end" / "any"
) -> str:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –≤—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫:
    - —Ñ–∏–ª—å—Ç—Ä –ø–æ –ø–µ—Ä–∏–æ–¥—É (start_date / end_date) –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –±–∞–∑–µ (O –∏–ª–∏ P);
    - —Ñ–∏–ª—å—Ç—Ä –ø–æ –Ω–æ–º–µ—Ä—É –¥–µ–ª–∞ (case_no).
    """
    df_f = filter_final_checks_df(
        df,
        start_date=start_date,
        end_date=end_date,
        case_no=case_no,
        basis=basis,
    )

    idx_case = excel_col_to_index("B")
    idx_obj = excel_col_to_index("D")
    idx_addr = excel_col_to_index("E")
    idx_start = excel_col_to_index("O")
    idx_end = excel_col_to_index("P")

    lines: List[str] = [header, ""]

    if df_f.empty:
        if case_no:
            return (
                f"–ü–æ –Ω–æ–º–µ—Ä—É –¥–µ–ª–∞ {case_no} –≤ —Ç–∞–±–ª–∏—Ü–µ –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."
            )
        if start_date and end_date:
            return (
                f"–ó–∞ –ø–µ—Ä–∏–æ–¥ {start_date:%d.%m.%Y} ‚Äî {end_date:%d.%m.%Y} "
                f"–∏—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."
            )
        return "–í —Ç–∞–±–ª–∏—Ü–µ –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ –Ω–µ—Ç —Å—Ç—Ä–æ–∫ —Å –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–º –Ω–æ–º–µ—Ä–æ–º –¥–µ–ª–∞ (B)."

    for _, row in df_f.iterrows():

        def safe_text(idx: int) -> str:
            try:
                val = row.iloc[idx]
            except Exception:
                return ""
            if pd.isna(val):
                return ""
            return str(val).strip()

        case_val = safe_text(idx_case)
        if not case_val:
            continue

        obj = safe_text(idx_obj)
        addr = safe_text(idx_addr)

        d_start_raw = row.iloc[idx_start] if idx_start < len(row) else None
        d_end_raw = row.iloc[idx_end] if idx_end < len(row) else None

        row_start = _parse_final_date(d_start_raw)
        row_end = _parse_final_date(d_end_raw)

        def fmt_date(d: Optional[date]) -> str:
            return d.strftime("%d.%m.%Y") if d else ""

        d_start = fmt_date(row_start)
        d_end = fmt_date(row_end)

        lines.append(f"–ù–æ–º–µ—Ä –¥–µ–ª–∞: {case_val}")
        if obj:
            lines.append(f"–û–±—ä–µ–∫—Ç: {obj}")
        if addr:
            lines.append(f"–ê–¥—Ä–µ—Å: {addr}")
        if d_start or d_end:
            if d_start and d_end:
                lines.append(f"–ü–µ—Ä–∏–æ–¥ –∏—Ç–æ–≥–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏: {d_start} ‚Äî {d_end}")
            elif d_start:
                lines.append(f"–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –∏—Ç–æ–≥–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏: {d_start}")
            else:
                lines.append(f"–î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –∏—Ç–æ–≥–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏: {d_end}")
        lines.append("")
        lines.append("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
        lines.append("")

    return "\n".join(lines)


def build_final_checks_text(df: pd.DataFrame) -> str:
    """
    –°—Ç–∞—Ä—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å (–±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–æ–≤) ‚Äî –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π.
    """
    return build_final_checks_text_filtered(df)


# -------------------------------------------------
# –ò—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏: ¬´BI‚Äë–ø–∞–Ω–µ–ª—å¬ª –ø–æ –Ω–∞—Ä—É—à–µ–Ω–∏—è–º (1‚Äì10 –¥–Ω–µ–π)
# -------------------------------------------------

FINAL_CHECKS_TARGET_SHEETS_HINTS = [
    ("–º–∫–¥", ["2025", "–º–∫–¥"]),
    ("—Å–æ—Ü–æ–±—ä–µ–∫—Ç—ã", ["2025", "—Å–æ—Ü", "–æ–±—ä–µ–∫—Ç"]),
    ("–æ—Å—Ç–∞–ª—å–Ω–æ–µ", ["2025", "–æ—Å—Ç–∞–ª"]),
]


def _pick_final_checks_target_sheets(all_sheets: List[str]) -> List[str]:
    """
    –í—ã–±–∏—Ä–∞–µ—Ç –Ω—É–∂–Ω—ã–µ –ª–∏—Å—Ç—ã –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ –ø–æ ¬´–º—è–≥–∫–∏–º¬ª –ø—Ä–∞–≤–∏–ª–∞–º,
    —á—Ç–æ–±—ã –Ω–µ –∑–∞–≤–∏—Å–µ—Ç—å –æ—Ç —Ç–æ—á–Ω—ã—Ö –ø—Ä–æ–±–µ–ª–æ–≤ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏.
    –¢—Ä–µ–±—É–µ–º—ã–µ –ª–∏—Å—Ç—ã –ø–æ –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–µ:
      ‚Ä¢ 2025 ... –ú–ö–î
      ‚Ä¢ 2025 ... –°–û–¶–û–ë–™–ï–ö–¢–´
      ‚Ä¢ 2025 ... –û—Å—Ç–∞–ª—å–Ω–æ–µ
    """
    if not all_sheets:
        return []

    picked: List[str] = []
    for sheet in all_sheets:
        s = str(sheet).lower().replace("\xa0", " ").strip()
        s_compact = re.sub(r"\s+", " ", s)

        # –ú–ö–î
        if ("2025" in s_compact) and ("–º–∫–¥" in s_compact):
            picked.append(sheet)
            continue

        # –°–û–¶–û–ë–™–ï–ö–¢–´ (—Ä–∞–∑–Ω—ã–µ –Ω–∞–ø–∏—Å–∞–Ω–∏—è)
        if ("2025" in s_compact) and ("—Å–æ—Ü" in s_compact) and ("–æ–±—ä–µ–∫—Ç" in s_compact):
            picked.append(sheet)
            continue

        # –û—Å—Ç–∞–ª—å–Ω–æ–µ
        if ("2025" in s_compact) and ("–æ—Å—Ç–∞–ª" in s_compact):
            picked.append(sheet)
            continue

    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Ä—è–¥–æ–∫
    uniq: List[str] = []
    for x in picked:
        if x not in uniq:
            uniq.append(x)
    return uniq


def get_final_checks_df_target_sheets() -> Optional[pd.DataFrame]:
    """
    –ß–∏—Ç–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ –∏ —Å–∫–ª–µ–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Ü–µ–ª–µ–≤—ã–µ –ª–∏—Å—Ç—ã:
    ¬´...–ú–ö–î¬ª, ¬´...–°–û–¶–û–ë–™–ï–ö–¢–´¬ª, ¬´...–û—Å—Ç–∞–ª—å–Ω–æ–µ¬ª –∑–∞ 2025 –≥–æ–¥.
    """
    path = FINAL_CHECKS_LOCAL_PATH
    if not path or not os.path.exists(path):
        log.error("–õ–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω: %s", path)
        return None

    try:
        xls = pd.ExcelFile(path)
        target_sheets = _pick_final_checks_target_sheets(xls.sheet_names)

        if not target_sheets:
            log.warning(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ü–µ–ª–µ–≤—ã–µ –ª–∏—Å—Ç—ã –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ (–ú–ö–î/–°–û–¶–û–ë–™–ï–ö–¢–´/–û—Å—Ç–∞–ª—å–Ω–æ–µ). "
                "–ë—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –≤—Å–µ –ª–∏—Å—Ç—ã."
            )
            target_sheets = list(xls.sheet_names)

        frames: List[pd.DataFrame] = []
        for sh in target_sheets:
            try:
                df_sh = pd.read_excel(xls, sheet_name=sh)
                df_sh = df_sh.dropna(how="all")
                if not df_sh.empty:
                    df_sh["_final_sheet"] = sh
                    frames.append(df_sh)
            except Exception as e:
                log.warning("–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ª–∏—Å—Ç–∞ '%s' –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫: %s", sh, e)

        if not frames:
            return pd.DataFrame()

        df = pd.concat(frames, ignore_index=True).reset_index(drop=True)
        return df
    except Exception as e:
        log.error("–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ (—Ü–µ–ª–µ–≤—ã–µ –ª–∏—Å—Ç—ã): %s", e)
        return None


def _cell_has_net(val: Any) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ —Å–ª–æ–≤–∞ ¬´–Ω–µ—Ç¬ª (–≤ –ª—é–±–æ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ) –≤ —è—á–µ–π–∫–µ.
    –£—á–∏—Ç—ã–≤–∞–µ—Ç –≤–∞—Ä–∏–∞–Ω—Ç—ã –≤—Ä–æ–¥–µ ¬´–Ω–µ—Ç¬ª, ¬´–Ω–µ—Ç.¬ª ¬´–Ω–µ—Ç/‚Ä¶¬ª, ¬´–ù–µ—Ç¬ª.
    """
    if val is None:
        return False
    try:
        if isinstance(val, float) and pd.isna(val):
            return False
    except Exception:
        pass
    s = str(val).replace("\n", " ").strip().lower()
    if not s:
        return False
    return "–Ω–µ—Ç" in s


def build_final_checks_violations_bi_panel(
    df_final: pd.DataFrame,
    df_remarks: pd.DataFrame,
    days_min: int = 1,
    days_max: int = 10,
    report_day: Optional[date] = None,
) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç ¬´BI‚Äë–ø–∞–Ω–µ–ª—å¬ª:
    1) –ë–µ—Ä—ë—Ç –∏—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑ df_final (–∫–æ–ª–æ–Ω–∫–∞ O ‚Äî –¥–∞—Ç–∞ –Ω–∞—á–∞–ª–∞, –∫–æ–ª–æ–Ω–∫–∞ B ‚Äî –Ω–æ–º–µ—Ä –¥–µ–ª–∞).
    2) –û—Ç–±–∏—Ä–∞–µ—Ç –¥–µ–ª–∞, —É –∫–æ—Ç–æ—Ä—ã—Ö –¥–æ –¥–∞—Ç—ã –Ω–∞—á–∞–ª–∞ (O) –æ—Å—Ç–∞–ª–æ—Å—å 1‚Äì10 –¥–Ω–µ–π.
    3) –î–ª—è –∫–∞–∂–¥–æ–≥–æ –Ω–æ–º–µ—Ä–∞ –¥–µ–ª–∞ –∏—â–µ—Ç —Å—Ç—Ä–æ–∫—É –≤ —Ç–∞–±–ª–∏—Ü–µ –∑–∞–º–µ—á–∞–Ω–∏–π (–∫–æ–ª–æ–Ω–∫–∞ I).
    4) –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ Q, R, Y, AD –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Å–ª–æ–≤–∞ ¬´–Ω–µ—Ç¬ª.
    5) –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ –¥–µ–ª–∞, –≥–¥–µ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ ¬´–Ω–µ—Ç¬ª.

    –í—ã–≤–æ–¥ ‚Äî –ø–æ –æ–±—Ä–∞–∑—Ü—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: –Ω–æ–º–µ—Ä –¥–µ–ª–∞ –∏ –ø–µ—Ä–µ—á–µ–Ω—å –ø—É–Ω–∫—Ç–æ–≤ ¬´‚Ä¶ ‚Äî –Ω–µ—Ç¬ª.
    """
    if report_day is None:
        report_day = local_now().date()

    if df_final is None or df_final.empty:
        return "–í —Ç–∞–±–ª–∏—Ü–µ –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö."

    if df_remarks is None or df_remarks.empty:
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å —Ç–∞–±–ª–∏—Ü—É –∑–∞–º–µ—á–∞–Ω–∏–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–æ–≤ ¬´–Ω–µ—Ç¬ª."

    idx_case_f = excel_col_to_index("B")
    idx_date_o = excel_col_to_index("O")

    if not (0 <= idx_case_f < len(df_final.columns)) or not (0 <= idx_date_o < len(df_final.columns)):
        return (
            "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–∫–∞—Ö "
            "(B ‚Äî –Ω–æ–º–µ—Ä –¥–µ–ª–∞, O ‚Äî –¥–∞—Ç–∞ –Ω–∞—á–∞–ª–∞)."
        )

    # 1) –û—Ç–±–∏—Ä–∞–µ–º –¥–µ–ª–∞ –Ω–∞ 1‚Äì10 –¥–Ω–µ–π –≤–ø–µ—Ä—ë–¥ –ø–æ –¥–∞—Ç–µ O
    candidates: Dict[str, Dict[str, Any]] = {}

    for _, row in df_final.iterrows():
        try:
            case_raw = row.iloc[idx_case_f]
        except Exception:
            continue

        case_norm = normalize_case_number(case_raw)
        if not case_norm:
            continue

        try:
            o_raw = row.iloc[idx_date_o]
        except Exception:
            o_raw = None

        o_date = _parse_final_date(o_raw)
        if not o_date:
            continue

        delta = (o_date - report_day).days
        if delta < days_min or delta > days_max:
            continue

        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–∞—Ç—É (–µ—Å–ª–∏ –¥—É–±–ª–∏)
        prev = candidates.get(case_norm)
        if not prev or o_date < prev["o_date"]:
            candidates[case_norm] = {
                "case": case_norm,
                "o_date": o_date,
                "delta": delta,
                "sheet": str(row.get("_final_sheet", "")).strip(),
            }

    if not candidates:
        return (
            f"–ò—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ {report_day:%d.%m.%Y}:\n"
            f"–í –ø–µ—Ä–∏–æ–¥ {days_min}‚Äì{days_max} –¥–Ω–µ–π (–ø–æ –¥–∞—Ç–µ –Ω–∞—á–∞–ª–∞ O) –¥–µ–ª –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."
        )

    # 2) –ò–Ω–¥–µ–∫—Å—ã –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã –∑–∞–º–µ—á–∞–Ω–∏–π (–≤—Ç–æ—Ä–∞—è —Ç–∞–±–ª–∏—Ü–∞)
    idx_case_r = excel_col_to_index("I")
    if not (0 <= idx_case_r < len(df_remarks.columns)):
        return (
            "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–ª–æ–Ω–∫—É I (–ù–æ–º–µ—Ä –¥–µ–ª–∞) –≤–æ –≤—Ç–æ—Ä–æ–π —Ç–∞–±–ª–∏—Ü–µ (–∑–∞–º–µ—á–∞–Ω–∏—è)."
        )

    idx_q = excel_col_to_index("Q")
    idx_r = excel_col_to_index("R")
    idx_y = excel_col_to_index("Y")
    idx_ad = excel_col_to_index("AD")

    # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Å—á–∏—Ç–∞–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –Ω–æ–º–µ—Ä –¥–µ–ª–∞ –¥–ª—è –≤—Å–µ—Ö —Å—Ç—Ä–æ–∫ –∑–∞–º–µ—á–∞–Ω–∏–π
    try:
        remarks_case_norm = df_remarks.iloc[:, idx_case_r].apply(normalize_case_number)
    except Exception:
        remarks_case_norm = pd.Series([""] * len(df_remarks), index=df_remarks.index)

    ISSUE_TITLES = [
        ("Q", "–û—Ç–º–µ—Ç–∫–∞ –æ–± —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–∏ –∑–∞–º–µ—á–∞–Ω–∏–π –ü–ë"),
        ("R", "–û—Ç–º–µ—Ç–∫–∞ –æ–± —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–∏ –∑–∞–º–µ—á–∞–Ω–∏–π –ü–ë –≤ –ó–ö –ö–ù–î"),
        ("Y", "–û—Ç–º–µ—Ç–∫–∞ –æ–± —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–∏ –Ω–∞—Ä—É—à–µ–Ω–∏–π –ê–†, –ú–ú–ì–ù, –ê–ì–û"),
        ("AD", "–û—Ç–º–µ—Ç–∫–∞ –æ–± —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–∏ –Ω–∞—Ä—É—à–µ–Ω–∏–π –≠–û–ú"),
    ]

    idx_map = {"Q": idx_q, "R": idx_r, "Y": idx_y, "AD": idx_ad}

    # 3) –°–æ–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–∞—Ä—É—à–µ–Ω–∏—è (–µ—Å—Ç—å ¬´–Ω–µ—Ç¬ª)
    out_items: List[Dict[str, Any]] = []

    # —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ –Ω–∞—á–∞–ª–∞ O
    ordered = sorted(candidates.values(), key=lambda x: x["o_date"])

    for item in ordered:
        case_norm = item["case"]
        mask = remarks_case_norm == case_norm
        if not mask.any():
            continue  # –µ—Å–ª–∏ –≤ –∑–∞–º–µ—á–∞–Ω–∏—è—Ö –Ω–µ—Ç –¥–µ–ª–∞ ‚Äî –Ω–µ —Å—á–∏—Ç–∞–µ–º –µ–≥–æ ¬´–Ω–∞—Ä—É—à–µ–Ω–∏–µ–º¬ª

        df_case = df_remarks.loc[mask]

        issues_present: List[str] = []
        for col_key, title in ISSUE_TITLES:
            idx_col = idx_map.get(col_key)
            if idx_col is None or idx_col >= len(df_remarks.columns):
                continue

            has_net = False
            for _, rrow in df_case.iterrows():
                try:
                    v = rrow.iloc[idx_col]
                except Exception:
                    v = None
                if _cell_has_net(v):
                    has_net = True
                    break
            if has_net:
                issues_present.append(title)

        if not issues_present:
            continue

        item_out = dict(item)
        item_out["issues"] = issues_present
        out_items.append(item_out)

    if not out_items:
        return (
            f"–ò—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ {report_day:%d.%m.%Y}:\n"
            f"–í –ø–µ—Ä–∏–æ–¥ {days_min}‚Äì{days_max} –¥–Ω–µ–π (–ø–æ –¥–∞—Ç–µ –Ω–∞—á–∞–ª–∞ O) "
            f"–¥–µ–ª–∞ –µ—Å—Ç—å, –Ω–æ –ø–æ –Ω–∏–º –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç—É—Å–æ–≤ ¬´–Ω–µ—Ç¬ª –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö Q/R/Y/AD."
        )

    # 4) –§–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç
    lines: List[str] = []
    lines.append(f"–ò—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ {report_day:%d.%m.%Y}:")
    lines.append(f"–ü–µ—Ä–∏–æ–¥: {days_min}‚Äì{days_max} –¥–Ω–µ–π (–ø–æ –¥–∞—Ç–µ –Ω–∞—á–∞–ª–∞ O).")
    lines.append("")

    for it in out_items:
        case_no = it["case"]
        lines.append(f"{case_no}")

        issues = it.get("issues") or []
        for n, title in enumerate(issues, start=1):
            lines.append(f"{n}) {title} - –Ω–µ—Ç")
        lines.append("")

    return "\n".join(lines).strip()






def build_final_checks_kpi_dashboard(
    df_final: pd.DataFrame,
    df_remarks: Optional[pd.DataFrame],
    days_min: int = 1,
    days_max: int = 10,
) -> str:
    """
    –°—Ç—Ä–æ–∏—Ç –∫–æ—Ä–æ—Ç–∫–∏–π –¥–∞—à–±–æ—Ä–¥ –ø–æ –∏—Ç–æ–≥–æ–≤—ã–º –ø—Ä–æ–≤–µ—Ä–∫–∞–º –Ω–∞ –±–ª–∏–∂–∞–π—à–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–Ω–µ–π.

    –õ–æ–≥–∏–∫–∞ –æ—Ç–±–æ—Ä–∞:
    - –±–µ—Ä—ë—Ç—Å—è —Å—Ç–æ–ª–±–µ—Ü O ¬´–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –∏—Ç–æ–≥–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ (–≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–¥/–º–º/–≥–≥–≥–≥)¬ª;
    - –¥–∞—Ç–∞ –ø–∞—Ä—Å–∏—Ç—Å—è —á–µ—Ä–µ–∑ pandas.to_datetime c dayfirst=True;
    - —Å—á–∏—Ç–∞–µ–º —Ä–∞–∑–Ω–∏—Ü—É (–≤ –¥–Ω—è—Ö) –º–µ–∂–¥—É –¥–∞—Ç–æ–π –Ω–∞—á–∞–ª–∞ –∏—Ç–æ–≥–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–º –¥–Ω—ë–º;
    - –≤ –≤—ã–±–æ—Ä–∫—É –ø–æ–ø–∞–¥–∞—é—Ç —Ç–æ–ª—å–∫–æ –¥–µ–ª–∞, —É –∫–æ—Ç–æ—Ä—ã—Ö days_min <= delta_days <= days_max.

    –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ, –ø–æ –ª–∏—Å—Ç—É —Å –∑–∞–º–µ—á–∞–Ω–∏—è–º–∏ (–ü–ë, –ê–†, –ú–ú–ì–ù, –ê–ì–û) –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è,
    –µ—Å—Ç—å –ª–∏ –ø–æ –¥–µ–ª—É —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ ¬´–Ω–µ—Ç¬ª –≤ –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö (Q, R, Y, AE).
    """
    today = date.today()
    lines: List[str] = []

    lines.append("üìã –†–∞–∑–¥–µ–ª ¬´–ò—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏¬ª")
    lines.append("")

    # 1. –ë–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
    if df_final is None or df_final.empty:
        lines.append("–í —Ç–∞–±–ª–∏—Ü–µ –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö.")
        return "\n".join(lines)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω—É–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –≤ –∏—Ç–æ–≥–æ–≤–æ–π —Ç–∞–±–ª–∏—Ü–µ
    idx_case = get_col_index_by_header(df_final, "–Ω–æ–º–µ—Ä –¥–µ–ª–∞", "B")
    idx_address = get_col_index_by_header(df_final, "–∞–¥—Ä–µ—Å –æ–±—ä–µ–∫—Ç–∞", "F")
    idx_start = get_col_index_by_header(df_final, "–¥–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –∏—Ç–æ–≥–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏", "O")
    idx_end = get_col_index_by_header(df_final, "–¥–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –∏—Ç–æ–≥–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏", "P")

    if idx_case is None or idx_start is None:
        lines.append(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (–Ω–æ–º–µ—Ä –¥–µ–ª–∞ –∏–ª–∏ –¥–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –∏—Ç–æ–≥–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏)."
        )
        return "\n".join(lines)

    col_case = df_final.columns[idx_case]
    col_address = df_final.columns[idx_address] if idx_address is not None else None
    col_start = df_final.columns[idx_start]
    col_end = df_final.columns[idx_end] if idx_end is not None else None

    # 2. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–∞—Ç—ã –Ω–∞—á–∞–ª–∞ –∏—Ç–æ–≥–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ —á–µ—Ä–µ–∑ pandas
    start_series = pd.to_datetime(df_final[col_start], errors="coerce", dayfirst=True)
    if start_series.notna().sum() == 0:
        lines.append(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –¥–∞—Ç—ã –Ω–∞—á–∞–ª–∞ –∏—Ç–æ–≥–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤ —Å—Ç–æ–ª–±—Ü–µ O."
        )
        return "\n".join(lines)

    today_ts = pd.to_datetime(today)
    deltas = (start_series - today_ts).dt.days

    mask = (deltas >= days_min) & (deltas <= days_max)
    df_window = df_final.loc[mask].copy()

    if df_window.empty:
        lines.append(
            f"–í –±–ª–∏–∂–∞–π—à–∏–µ {days_min}‚Äì{days_max} –¥–Ω–µ–π (–ø–æ –¥–∞—Ç–µ –Ω–∞—á–∞–ª–∞ –∏—Ç–æ–≥–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏, —Å—Ç–æ–ª–±–µ—Ü O) "
            f"–Ω–µ—Ç –¥–µ–ª —Å –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∏—Ç–æ–≥–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π."
        )
        return "\n".join(lines)

    # –î–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –ø–æ –¥–∞—Ç–µ
    df_window["_start_ts"] = pd.to_datetime(
        df_window[col_start], errors="coerce", dayfirst=True
    )
    df_window.sort_values("_start_ts", inplace=True)

    # 3. –°–æ–±–∏—Ä–∞–µ–º –ø–æ –ª–∏—Å—Ç—É –∑–∞–º–µ—á–∞–Ω–∏–π –Ω–æ–º–µ—Ä–∞ –¥–µ–ª, –≥–¥–µ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ ¬´–Ω–µ—Ç¬ª
    cases_with_not_fixed: set[str] = set()
    if df_remarks is not None and not df_remarks.empty:
        idx_case_r = get_col_index_by_header(df_remarks, "–Ω–æ–º–µ—Ä –¥–µ–ª–∞", "I")
        idx_pb_r = get_col_index_by_header(df_remarks, "–ø–æ–∂–∞—Ä", "Q")
        idx_ar_r = get_col_index_by_header(df_remarks, "–∞—Ä—Ö–∏—Ç", "R")
        idx_mgn_r = get_col_index_by_header(df_remarks, "–º–≥–Ω", "Y")
        idx_ago_r = get_col_index_by_header(df_remarks, "–∞–≥–æ", "AE")

        def _is_net(val: Any) -> bool:
            if val is None:
                return False
            if isinstance(val, float) and pd.isna(val):
                return False
            s = str(val).strip().lower()
            return s == "–Ω–µ—Ç"

        if idx_case_r is not None:
            for _, row in df_remarks.iterrows():
                case_num = str(row.iloc[idx_case_r]).strip()
                if not case_num:
                    continue

                has_net = False
                for idx_col in (idx_pb_r, idx_ar_r, idx_mgn_r, idx_ago_r):
                    if idx_col is not None and _is_net(row.iloc[idx_col]):
                        has_net = True
                        break

                if has_net:
                    cases_with_not_fixed.add(case_num)

    # 4. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –æ–∫–Ω—É –¥–∞—Ç
    total_cases = len(df_window)

    # –°—á–∏—Ç–∞–µ–º, —Å–∫–æ–ª—å–∫–æ –∏–∑ —ç—Ç–∏—Ö –¥–µ–ª –∏–º–µ—é—Ç –Ω–µ—É—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã–µ –∑–∞–º–µ—á–∞–Ω–∏—è
    cases_in_window = set()
    cases_in_window_with_not_fixed = set()

    for _, row in df_window.iterrows():
        case_num = str(row[col_case]).strip()
        if not case_num:
            continue
        cases_in_window.add(case_num)
        if case_num in cases_with_not_fixed:
            cases_in_window_with_not_fixed.add(case_num)

    lines.append(
        f"–í –±–ª–∏–∂–∞–π—à–∏–µ {days_min}‚Äì{days_max} –¥–Ω–µ–π (–ø–æ –¥–∞—Ç–µ –Ω–∞—á–∞–ª–∞ –∏—Ç–æ–≥–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏, —Å—Ç–æ–ª–±–µ—Ü O) "
        f"–∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ –¥–µ–ª: {total_cases}."
    )

    if cases_in_window_with_not_fixed:
        lines.append(
            "–ò–∑ –Ω–∏—Ö —Å –Ω–µ—É—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã–º–∏ –∑–∞–º–µ—á–∞–Ω–∏—è–º–∏ –ø–æ –ª–∏—Å—Ç—É ¬´–ü–ë, –ê–†,–ú–ú–ì–ù, –ê–ì–û (2025)¬ª: "
            f"{len(cases_in_window_with_not_fixed)}."
        )
    else:
        lines.append("–ü–æ –¥–∞–Ω–Ω—ã–º –ª–∏—Å—Ç–∞ —Å –∑–∞–º–µ—á–∞–Ω–∏—è–º–∏ –≤ —ç—Ç–æ–º –æ–∫–Ω–µ –Ω–µ—Ç –¥–µ–ª —Å –Ω–µ—É—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã–º–∏ –∑–∞–º–µ—á–∞–Ω–∏—è–º–∏.")

    # 5. –ü–µ—Ä–µ—á–µ–Ω—å –¥–µ–ª
    lines.append("")
    lines.append("–ü–µ—Ä–µ—á–µ–Ω—å –¥–µ–ª (–º–∞–∫—Å–∏–º—É–º 40 —Å—Ç—Ä–æ–∫):")

    max_list = 40
    printed = 0

    for _, row in df_window.iterrows():
        case_num = str(row[col_case]).strip()
        if not case_num:
            continue

        addr = str(row[col_address]).strip() if col_address is not None else ""
        start_ts = row["_start_ts"]
        start_str = start_ts.strftime("%d.%m.%Y") if not pd.isna(start_ts) else "?"

        mark = "‚ùå" if case_num in cases_with_not_fixed else "‚úÖ"
        line = f"{mark} {case_num} ‚Äî –Ω–∞—á–∞–ª–æ –∏—Ç–æ–≥–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ {start_str}"
        if addr:
            line += f"; {addr}"

        lines.append(line)
        printed += 1
        if printed >= max_list:
            if total_cases > printed:
                lines.append(f"... –∏ –µ—â—ë {total_cases - printed} –¥–µ–ª.")
            break

    return "\n".join(lines)


async def send_final_checks_xlsx_filtered(
    chat_id: int,
    df: pd.DataFrame,
    context: ContextTypes.DEFAULT_TYPE,
    start_date: Optional[date] = None,
    end_date: Optional[date] = None,
    case_no: Optional[str] = None,
    filename_suffix: str = "",
    basis: str = "any",
):
    df_f = filter_final_checks_df(
        df,
        start_date=start_date,
        end_date=end_date,
        case_no=case_no,
        basis=basis,
    )
    if df_f.empty:
        await context.bot.send_message(
            chat_id=chat_id,
            text="–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —É—Å–ª–æ–≤–∏—è–º.",
        )
        return

    bio = BytesIO()
    df_f.to_excel(bio, sheet_name="–ò—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏", index=False)
    bio.seek(0)

    fname = "–ò—Ç–æ–≥–æ–≤—ã–µ_–ø—Ä–æ–≤–µ—Ä–∫–∏"
    parts = []
    if case_no:
        parts.append(f"–¥–µ–ª–æ_{case_no}")
    if start_date and end_date:
        parts.append(f"{start_date:%d.%m.%Y}-{end_date:%d.%m.%Y}")
    if filename_suffix:
        parts.append(filename_suffix)
    if parts:
        fname += "_" + "_".join(parts)
    fname += ".xlsx"

    await context.bot.send_document(
        chat_id=chat_id,
        document=InputFile(bio, filename=fname),
        caption="–ò—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ (—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫)",
    )


# -------------------------------------------------
# –ò–Ω—Å–ø–µ–∫—Ç–æ—Ä ‚Üí Google Sheets
# -------------------------------------------------
def append_inspector_row_to_excel(form: Dict[str, Any]) -> bool:
    service = get_sheets_service()
    if service is None:
        log.error("Google Sheets API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")
        return False

    try:
        area_str = str(form.get("area", "")).replace(".", ",")
        floors_str = str(form.get("floors", ""))

        d_value = (
            f"–ü–ª–æ—â–∞–¥—å (–∫–≤.–º): {area_str}\n"
            f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç—Ç–∞–∂–µ–π: {floors_str}"
        )

        row = [
            "",
            form.get("date").strftime("%d.%m.%Y") if form.get("date") else "",
            "",
            d_value,
            form.get("onzs", ""),
            form.get("developer", ""),
            form.get("object", ""),
            form.get("address", ""),
            form.get("case", ""),
            form.get("check_type", ""),
        ]

        body = {"values": [row]}

        response = (
            service.spreadsheets()
            .values()
            .append(
                spreadsheetId=GSHEETS_SPREADSHEET_ID,
                range=f"'{INSPECTOR_SHEET_NAME}'!A1",
                valueInputOption="USER_ENTERED",
                insertDataOption="INSERT_ROWS",
                body=body,
            )
            .execute()
        )

        log.info("–ò–Ω—Å–ø–µ–∫—Ç–æ—Ä: –∑–∞–ø–∏—Å—å –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ Google Sheets: %s", response)
        return True

    except Exception as e:
        log.error("–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –∏–Ω—Å–ø–µ–∫—Ç–æ—Ä–∞ –≤ Google Sheets: %s", e)
        return False


# -------------------------------------------------
# –ò–Ω—Å–ø–µ–∫—Ç–æ—Ä ‚Äî –º–∞—Å—Ç–µ—Ä
# -------------------------------------------------
async def inspector_process(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = update.message.text
    form = context.user_data.get("inspector_form", {}) or {}
    step = form.get("step")

    if not step:
        context.user_data["inspector_form"] = {"step": "date"}
        await update.message.reply_text(
            "üëÆ‚Äç‚ôÇÔ∏è –í—ã–µ–∑–¥ –∏–Ω—Å–ø–µ–∫—Ç–æ—Ä–∞\n\n"
            "1/8. –î–∞—Ç–∞ –≤—ã–µ–∑–¥–∞ (–î–î.–ú–ú.–ì–ì–ì–ì):"
        )
        return

    if step == "date":
        try:
            form["date"] = datetime.strptime(text, "%d.%m.%Y").date()
            form["step"] = "area"
            context.user_data["inspector_form"] = form
            await update.message.reply_text("1/8. –ü–ª–æ—â–∞–¥—å –æ–±—ä–µ–∫—Ç–∞ (–∫–≤.–º):")
        except Exception:
            await update.message.reply_text(
                "–í–≤–µ–¥–∏—Ç–µ –¥–∞—Ç—É –≤ —Ñ–æ—Ä–º–∞—Ç–µ –î–î.–ú–ú.–ì–ì–ì–ì (–Ω–∞–ø—Ä–∏–º–µ—Ä, 30.12.2025)"
            )
        return

    if step == "area":
        form["area"] = text
        form["step"] = "floors"
        context.user_data["inspector_form"] = form
        await update.message.reply_text("2/8. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç—Ç–∞–∂–µ–π:")
        return

    if step == "floors":
        form["floors"] = text
        form["step"] = "onzs"
        context.user_data["inspector_form"] = form
        await update.message.reply_text("3/8. –û–ù–∑–° (1‚Äì12):")
        return

    if step == "onzs":
        form["onzs"] = text
        form["step"] = "developer"
        context.user_data["inspector_form"] = form
        await update.message.reply_text("4/8. –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∑–∞—Å—Ç—Ä–æ–π—â–∏–∫–∞:")
        return

    if step == "developer":
        form["developer"] = text
        form["step"] = "object"
        context.user_data["inspector_form"] = form
        await update.message.reply_text("5/8. –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞:")
        return

    if step == "object":
        form["object"] = text
        form["step"] = "address"
        context.user_data["inspector_form"] = form
        await update.message.reply_text("6/8. –°—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–π –∞–¥—Ä–µ—Å:")
        return

    if step == "address":
        form["address"] = text
        form["step"] = "case"
        context.user_data["inspector_form"] = form
        await update.message.reply_text("7/8. –ù–æ–º–µ—Ä –¥–µ–ª–∞ (—Ñ–æ—Ä–º–∞—Ç 00-00-000000):")
        return

    if step == "case":
        form["case"] = text
        form["step"] = "check_type"
        context.user_data["inspector_form"] = form
        await update.message.reply_text(
            "8/8. –í–∏–¥ –ø—Ä–æ–≤–µ—Ä–∫–∏ (–ü–ü, –∏—Ç–æ–≥–æ–≤–∞—è, –ø—Ä–æ—Ñ–≤–∏–∑–∏—Ç, –ø–æ—Ä—É—á–µ–Ω–∏–µ –∏ —Ç.–ø.):"
        )
        return

    if step == "check_type":
        form["check_type"] = text
        form["step"] = "done"
        context.user_data["inspector_form"] = form

        await update.message.reply_text("‚è≥ –°–æ—Ö—Ä–∞–Ω—è—é –≤—ã–µ–∑–¥...")

        ok_db = save_inspector_to_db(form)
        ok_gs = append_inspector_row_to_excel(form)

        if ok_db and ok_gs:
            msg = "‚úÖ –í—ã–µ–∑–¥ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ –±–æ—Ç–µ –∏ –¥–æ–±–∞–≤–ª–µ–Ω –≤ –æ–±—â—É—é —Ç–∞–±–ª–∏—Ü—É."
        elif ok_db and not ok_gs:
            msg = (
                "‚úÖ –í—ã–µ–∑–¥ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ –±–æ—Ç–µ.\n"
                "‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –≤ Google Sheets (–ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–ª—é—á/–ø—Ä–∞–≤–∞)."
            )
        elif not ok_db and ok_gs:
            msg = (
                "‚ö† –í—ã–µ–∑–¥ –¥–æ–±–∞–≤–ª–µ–Ω –≤ Google Sheets, –Ω–æ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ª–æ–∫–Ω—É—é –∑–∞–ø–∏—Å—å."
            )
        else:
            msg = (
                "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—ã–µ–∑–¥ –Ω–∏ –ª–æ–∫–Ω–æ, –Ω–∏ –≤ Google Sheets.\n"
                "–°–æ–æ–±—â–∏—Ç–µ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫—É."
            )

        await update.message.reply_text(msg)
        context.user_data.pop("inspector_form", None)
        return


# -------------------------------------------------
# –û–ù–∑–°
# -------------------------------------------------
def onzs_menu_inline() -> InlineKeyboardMarkup:
    buttons = []
    row = []
    for i in range(1, 13):
        row.append(InlineKeyboardButton(str(i), callback_data=f"onzs_filter_{i}"))
        if len(row) == 4:
            buttons.append(row)
            row = []
    if row:
        buttons.append(row)
    return InlineKeyboardMarkup(buttons)


def build_onzs_list_by_number(df: pd.DataFrame, number: str) -> str:
    onzs_idx = get_col_index_by_header(df, "–æ–Ω–∑—Å", "D")
    if onzs_idx is None:
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å—Ç–æ–ª–±–µ—Ü –û–ù–∑–° –≤ —Ñ–∞–π–ª–µ –∑–∞–º–µ—á–∞–Ω–∏–π."

    case_idx = get_case_col_index(df)
    addr_idx = get_col_index_by_header(df, "—Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–π –∞–¥—Ä–µ—Å", "H")

    num_str = normalize_onzs_value(number)
    mask: List[bool] = []
    for _, row in df.iterrows():
        try:
            val_raw = row.iloc[onzs_idx]
        except Exception:
            val_raw = None
        val_norm = normalize_onzs_value(val_raw)
        mask.append(val_norm == num_str)

    if not any(mask):
        return f"–ù–µ—Ç –æ–±—ä–µ–∫—Ç–æ–≤ —Å –û–ù–∑–° = {number}."

    df_f = df[mask]

    lines = [f"–û–ù–∑–° = {number}", f"–ù–∞–π–¥–µ–Ω–æ –¥–µ–ª: {len(df_f)}", ""]

    for _, row in df_f.iterrows():

        def safe(idx: Optional[int]) -> str:
            if idx is None:
                return ""
            try:
                val = row.iloc[idx]
            except Exception:
                return ""
            try:
                if pd.isna(val):
                    return ""
            except Exception:
                pass
            s = str(val).strip()
            if not s or s.lower() == "nan":
                return ""
            return s

        case_no = safe(case_idx)
        addr = safe(addr_idx)

        if not case_no and not addr:
            continue

        if case_no and addr:
            lines.append(f"‚Ä¢ {case_no} ‚Äî {addr}")
        elif case_no:
            lines.append(f"‚Ä¢ {case_no}")
        else:
            lines.append(f"‚Ä¢ {addr}")

    return "\n".join(lines)


# -------------------------------------------------
# –ò–Ω—Å–ø–µ–∫—Ç–æ—Ä ‚Äî —Å–ø–∏—Å–æ–∫/Excel
# -------------------------------------------------
def build_inspector_list_text(rows: List[sqlite3.Row]) -> str:
    if not rows:
        return "–ü–æ–∫–∞ –Ω–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –≤—ã–µ–∑–¥–æ–≤ –∏–Ω—Å–ø–µ–∫—Ç–æ—Ä–∞."

    lines: List[str] = ["–ü–æ—Å–ª–µ–¥–Ω–∏–µ –≤—ã–µ–∑–¥—ã –∏–Ω—Å–ø–µ–∫—Ç–æ—Ä–∞:", ""]
    for r in rows:
        d = r["date"] or ""
        try:
            d_fmt = datetime.strptime(d, "%Y-%m-%d").strftime("%d.%m.%Y")
        except Exception:
            d_fmt = d
        lines.append(
            f"‚Ä¢ {d_fmt} ‚Äî –¥–µ–ª–æ {r['case_no'] or '-'}, "
            f"–û–ù–∑–° {r['onzs'] or '-'}, {r['check_type'] or ''}"
        )
        addr = r["address"] or ""
        if addr:
            lines.append(f"  –ê–¥—Ä–µ—Å: {addr}")
        obj = r["object"] or ""
        if obj:
            lines.append(f"  –û–±—ä–µ–∫—Ç: {obj}")
        dev = r["developer"] or ""
        if dev:
            lines.append(f"  –ó–∞—Å—Ç—Ä–æ–π—â–∏–∫: {dev}")
        lines.append("")
    return "\n".join(lines)


async def send_inspector_xlsx(
    chat_id: int, rows: List[sqlite3.Row], context: ContextTypes.DEFAULT_TYPE
):
    if not rows:
        await context.bot.send_message(
            chat_id=chat_id, text="–ü–æ–∫–∞ –Ω–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –≤—ã–µ–∑–¥–æ–≤ –∏–Ω—Å–ø–µ–∫—Ç–æ—Ä–∞."
        )
        return

    data = []
    for r in rows:
        d = r["date"] or ""
        try:
            d_fmt = datetime.strptime(d, "%Y-%m-%d").strftime("%d.%m.%Y")
        except Exception:
            d_fmt = d
        data.append(
            {
                "–î–∞—Ç–∞ –≤—ã–µ–∑–¥–∞": d_fmt,
                "–ü–ª–æ—â–∞–¥—å (–∫–≤.–º)": r["area"] or "",
                "–≠—Ç–∞–∂–Ω–æ—Å—Ç—å": r["floors"] or "",
                "–û–ù–∑–°": r["onzs"] or "",
                "–ó–∞—Å—Ç—Ä–æ–π—â–∏–∫": r["developer"] or "",
                "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞": r["object"] or "",
                "–°—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–π –∞–¥—Ä–µ—Å": r["address"] or "",
                "–ù–æ–º–µ—Ä –¥–µ–ª–∞": r["case_no"] or "",
                "–í–∏–¥ –ø—Ä–æ–≤–µ—Ä–∫–∏": r["check_type"] or "",
            }
        )

    df = pd.DataFrame(data)

    bio = BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as writer:
        df.to_excel(writer, sheet_name="–ò–Ω—Å–ø–µ–∫—Ç–æ—Ä", index=False)

    bio.seek(0)
    filename = f"–ò–Ω—Å–ø–µ–∫—Ç–æ—Ä_–≤—ã–µ–∑–¥—ã_{date.today().strftime('%d.%m.%Y')}.xlsx"

    await context.bot.send_document(
        chat_id=chat_id,
        document=InputFile(bio, filename=filename),
        caption="–í—ã–µ–∑–¥—ã –∏–Ω—Å–ø–µ–∫—Ç–æ—Ä–∞ (–æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª)",
    )


# -------------------------------------------------
# CALLBACK HANDLER
# -------------------------------------------------
async def callback_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    data = query.data
    user = query.from_user
    await query.answer()

    # –¢–ó –¥–ª—è –¶–ù–ò–õ ‚Äî inline-–∫–Ω–æ–ø–∫–∏ –º–∞—Å—Ç–µ—Ä–∞
    if data and str(data).startswith("cnil:"):
        await cnil_callback(update, context)
        return


    settings = get_schedule_state()
    version = get_schedule_version(settings)


    # --- üö® –ö–†–ê–°–ù–´–ï –õ–ê–ú–ü–û–ß–ö–ò ---
    if data == "redlamps_upload":
        context.user_data["awaiting_redlamps_upload"] = True
        await query.message.reply_text(
            "üì§ –û—Ç–ø—Ä–∞–≤—å—Ç–µ Excel-—Ñ–∞–π–ª (.xlsx) –¥–ª—è —Ä–∞–∑–¥–µ–ª–∞ ¬´–ö—Ä–∞—Å–Ω—ã–µ –ª–∞–º–ø–æ—á–∫–∏¬ª."
        )
        return

    if data == "redlamps_period":
        context.user_data["redlamps_period"] = {"step": "start"}
        await query.message.reply_text("–í–≤–µ–¥–∏—Ç–µ –¥–∞—Ç—É –Ω–∞—á–∞–ª–∞ –ø–µ—Ä–∏–æ–¥–∞ (–î–î.–ú–ú.–ì–ì–ì–ì):")
        return

    if data == "redlamps_reset":
        context.user_data.pop("redlamps_file_bytes", None)
        context.user_data.pop("redlamps_file_name", None)
        context.user_data.pop("redlamps_period", None)
        context.user_data.pop("awaiting_redlamps_upload", None)
        await query.message.reply_text("–°–±—Ä–æ—Å –≤—ã–ø–æ–ª–Ω–µ–Ω. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –∑–∞–Ω–æ–≤–æ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏.")
        return

    if data == "redlamps_build":
        xbytes = context.user_data.get("redlamps_file_bytes")
        if not xbytes:
            await query.message.reply_text("–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ Excel-—Ñ–∞–π–ª –∫–Ω–æ–ø–∫–æ–π ¬´üì§ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª¬ª.")
            return

        period = context.user_data.get("redlamps_period") or {}
        d_from = period.get("date_from")
        d_to = period.get("date_to")
        if not d_from or not d_to:
            await query.message.reply_text("–°–Ω–∞—á–∞–ª–∞ –∑–∞–¥–∞–π—Ç–µ –ø–µ—Ä–∏–æ–¥ –∫–Ω–æ–ø–∫–æ–π ¬´üìÖ –í—ã–±—Ä–∞—Ç—å –ø–µ—Ä–∏–æ–¥ (K‚ÄìL)¬ª.")
            return

        try:
            text_out = _redlamps_process_bytes(
                xlsx_bytes=xbytes,
                date_from=d_from,
                date_to=d_to,
                tolerance_days=REDLAMPS_TOLERANCE_DAYS_DEFAULT,
            )
        except Exception as e:
            log.error("REDLAMPS: –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: %s", e)
            await query.message.reply_text("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É Excel.")
            return

        await send_long_text(query.message.chat, text_out)
        return
    # --- –ì–†–ê–§–ò–ö ---
    if data == "schedule_refresh":
        df = get_schedule_df()
        if df is None:
            await query.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –ª–∏—Å—Ç ¬´–ì—Ä–∞—Ñ–∏–∫¬ª.")
        else:
            await query.message.reply_text(f"–õ–∏—Å—Ç ¬´–ì—Ä–∞—Ñ–∏–∫¬ª –ø—Ä–æ—á–∏—Ç–∞–Ω, —Å—Ç—Ä–æ–∫: {len(df)}.")
        return

    if data == "schedule_download":
        df = get_schedule_df()
        if df is None or df.empty:
            await query.message.reply_text(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ª–∏—Å—Ç ¬´–ì—Ä–∞—Ñ–∏–∫¬ª –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏."
            )
            return

        await send_schedule_xlsx(
            chat_id=query.message.chat.id,
            dataframe=df,
            context=context,
        )
        return

    if data == "schedule_upload":
        await query.message.reply_text("–ó–∞–≥—Ä—É–∑–∫–∞ –≥—Ä–∞—Ñ–∏–∫–∞ –≤ —ç—Ç–æ–π —Å–±–æ—Ä–∫–µ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞.")
        return

    if data == "schedule_approvers":
        if not is_admin(user.id):
            await query.message.reply_text(
                "–¢–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä –º–æ–∂–µ—Ç –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å —Å–æ–≥–ª–∞—Å—É—é—â–∏—Ö."
            )
            return
        context.user_data["awaiting_approvers_input"] = {"version": version}
        await query.message.reply_text(
            "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å–ø–∏—Å–æ–∫ —Å–æ–≥–ª–∞—Å—É—é—â–∏—Ö (—é–∑–µ—Ä–Ω–µ–π–º—ã —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª/–∑–∞–ø—è—Ç—É—é/–Ω–æ–≤—É—é —Å—Ç—Ä–æ–∫—É), –Ω–∞–ø—Ä–∏–º–µ—Ä:\n"
            "@asdinamitif @FrolovAlNGSN @cappit_G59"
        )
        return

    if data.startswith("schedule_approve:") or data.startswith("schedule_rework:"):
        action, approver_tag = data.split(":", 1)
        user_username = user.username or ""
        user_tag = f"@{user_username}" if user_username else ""

        if user_tag.lower() != approver_tag.lower():
            await query.answer(
                text=f"–≠—Ç–∞ –∫–Ω–æ–ø–∫–∞ –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–∞ –¥–ª—è {approver_tag}.",
                show_alert=True,
            )
            return

        if action == "schedule_approve":
            update_schedule_approval_status(version, approver_tag, "approved", None)
            await query.message.reply_text(
                f"{approver_tag} —Å–æ–≥–ª–∞—Å–æ–≤–∞–ª(–∞) –≥—Ä–∞—Ñ–∏–∫. –°–ø–∞—Å–∏–±–æ!"
            )

            approvals = get_schedule_approvals(version)
            if approvals and all(r["status"] == "approved" for r in approvals):
                header = build_schedule_header(version, approvals)
                lines = [header, "", "–°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–æ –≤—Å–µ–º–∏:"]
                for r in approvals:
                    lines.append(
                        f"‚Ä¢ {r['approver']} ‚Äî {_format_dt(r['decided_at'])} ‚úÖ"
                    )
                text = "\n".join(lines)

                write_schedule_summary_to_sheet(version, approvals)

                if SCHEDULE_NOTIFY_CHAT_ID is not None:
                    try:
                        await context.bot.send_message(
                            chat_id=SCHEDULE_NOTIFY_CHAT_ID, text=text
                        )
                    except Exception as e:
                        log.error(
                            "–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≥—Ä–∞—Ñ–∏–∫–∞ –≤ –∫–∞–Ω–∞–ª %s: %s",
                            SCHEDULE_NOTIFY_CHAT_ID,
                            e,
                        )
            return

        if action == "schedule_rework":
            context.user_data["awaiting_rework_comment"] = {
                "version": version,
                "approver": approver_tag,
            }
            await query.message.reply_text(
                "–ù–∞–ø–∏—à–∏—Ç–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π, –ø–æ—á–µ–º—É –≥—Ä–∞—Ñ–∏–∫ –Ω—É–∂–Ω–æ –¥–æ—Ä–∞–±–æ—Ç–∞—Ç—å."
            )
            return

    # --- –ó–ê–ú–ï–ß–ê–ù–ò–Ø ---
    if data == "remarks_search_case":
        context.user_data["awaiting_case_search"] = True
        await query.message.reply_text(
            "–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä –¥–µ–ª–∞ (—Ñ–æ—Ä–º–∞—Ç 00-00-000000), –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ –Ω–∞–π—Ç–∏:"
        )
        return

    if data == "remarks_onzs":
        kb = onzs_menu_inline()
        msg = (
            "üèó –†–∞–∑–¥–µ–ª ¬´–û–ù–∑–°¬ª\n\n"
            "–í—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–º–µ—Ä –û–ù–∑–°, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å —Å–ø–∏—Å–æ–∫ –¥–µ–ª (–ù–æ–º–µ—Ä –¥–µ–ª–∞ (I) + –∞–¥—Ä–µ—Å) "
            "–∏–∑ —Ç–µ–∫—É—â–µ–≥–æ —Ñ–∞–π–ª–∞ –∑–∞–º–µ—á–∞–Ω–∏–π.\n"
            "–î–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –û–ù–∑–° –º–æ–∂–Ω–æ –æ—Ç–¥–µ–ª—å–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ª—å–∫–æ –Ω–µ—É—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã–µ –∑–∞–º–µ—á–∞–Ω–∏—è."
        )
        await query.message.reply_text(msg, reply_markup=kb)
        return

    if data == "remarks_not_done":
        await query.message.reply_text("–ò—â—É —Å—Ç—Ä–æ–∫–∏ —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º ¬´–Ω–µ—Ç¬ª...")
        df = get_remarks_df_current()
        if df is None:
            await query.message.reply_text(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ñ–∞–π–ª –∑–∞–º–µ—á–∞–Ω–∏–π. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø –∫ —Ç–∞–±–ª–∏—Ü–µ."
            )
            return
        text = build_remarks_not_done_text(df)
        await send_long_text(query.message.chat, text)
        return

    if data == "remarks_download":
        await query.message.reply_text(
            "–§–∞–π–ª —Å –∑–∞–º–µ—á–∞–Ω–∏—è–º–∏ –∏ –≥—Ä–∞—Ñ–∏–∫–æ–º –º–æ–∂–Ω–æ –æ—Ç–∫—Ä—ã—Ç—å –ø–æ —Å—Å—ã–ª–∫–µ:\n"
            f"{GOOGLE_SHEET_URL_DEFAULT}"
        )
        return

    if data.startswith("onzs_filter_"):
        number = data.replace("onzs_filter_", "")
        df = get_remarks_df_current()
        if df is None:
            await query.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å —Ç–∞–±–ª–∏—Ü—É –û–ù–∑–°.")
            return
        text = build_onzs_list_by_number(df, number)
        await send_long_text(query.message.chat, text)

        kb = InlineKeyboardMarkup(
            [
                [
                    InlineKeyboardButton(
                        f"‚ùå –ù–µ —É—Å—Ç—Ä–∞–Ω–µ–Ω—ã (–û–ù–∑–° {number})",
                        callback_data=f"onzs_not_done_{number}",
                    )
                ]
            ]
        )
        await query.message.reply_text(
            f"–î–ª—è –û–ù–∑–° {number} –º–æ–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ —Å—Ç–∞—Ç—É—Å ¬´–Ω–µ—Ç¬ª.",
            reply_markup=kb,
        )
        return

    if data.startswith("onzs_not_done_"):
        number = data.replace("onzs_not_done_", "")
        df = get_remarks_df_current()
        if df is None:
            await query.message.reply_text(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ñ–∞–π–ª –∑–∞–º–µ—á–∞–Ω–∏–π. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø –∫ —Ç–∞–±–ª–∏—Ü–µ."
            )
            return
        text = build_remarks_not_done_by_onzs(df, number)
        await send_long_text(query.message.chat, text)
        return

    # --- –ò–ù–°–ü–ï–ö–¢–û–† ---
    if data == "inspector_add":
        context.user_data["inspector_form"] = {"step": "date"}
        await query.message.reply_text(
            "üëÆ‚Äç‚ôÇÔ∏è –í—ã–µ–∑–¥ –∏–Ω—Å–ø–µ–∫—Ç–æ—Ä–∞\n\n"
            "–£–∫–∞–∂–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ —à–∞–≥–∞–º.\n"
            "1/8. –î–∞—Ç–∞ –≤—ã–µ–∑–¥–∞ (–î–î.–ú–ú.–ì–ì–ì–ì):"
        )
        return

    if data == "inspector_list":
        rows = fetch_inspector_visits(limit=50)
        text = build_inspector_list_text(rows)
        await send_long_text(query.message.chat, "\n".join(text.split("\n")))
        return

    if data == "inspector_download":
        rows = fetch_inspector_visits(limit=1000)
        await send_inspector_xlsx(
            chat_id=query.message.chat.id, rows=rows, context=context
        )
        return

    if data == "inspector_reset":
        clear_inspector_visits()
        await query.message.reply_text(
            "–°–ø–∏—Å–æ–∫ –≤—ã–µ–∑–¥–æ–≤ –∏–Ω—Å–ø–µ–∫—Ç–æ—Ä–∞ –æ—á–∏—â–µ–Ω.\n"
            "–ù–æ–≤—ã–µ –≤—ã–µ–∑–¥—ã –±—É–¥—É—Ç –ø–æ–ø–∞–¥–∞—Ç—å –≤ Excel –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —á–µ—Ä–µ–∑ –∫–Ω–æ–ø–∫—É ¬´‚ûï –î–æ–±–∞–≤–∏—Ç—å –≤—ã–µ–∑–¥¬ª."
        )
        return

    # --- –ò–¢–û–ì–û–í–´–ï –ü–†–û–í–ï–†–ö–ò ---
    if data == "final_week":
        # –∑–∞–ø–æ–º–∏–Ω–∞–µ–º —Ä–µ–∂–∏–º –∏ —Å–ø—Ä–∞—à–∏–≤–∞–µ–º, –ø–æ –∫–∞–∫–æ–π –¥–∞—Ç–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å
        context.user_data["final_range_choice"] = {"mode": "week"}
        kb = InlineKeyboardMarkup(
            [
                [
                    InlineKeyboardButton(
                        "üìå –ü–æ –¥–∞—Ç–µ –Ω–∞—á–∞–ª–∞ (O)", callback_data="final_basis_start"
                    ),
                    InlineKeyboardButton(
                        "üìå –ü–æ –¥–∞—Ç–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è (P)", callback_data="final_basis_end"
                    ),
                ]
            ]
        )
        await query.message.reply_text(
            "–ó–∞ –Ω–µ–¥–µ–ª—é: –ø–æ –∫–∞–∫–æ–π –¥–∞—Ç–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å?\n\n"
            "‚Ä¢ O ‚Äî –¥–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –∏—Ç–æ–≥–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏\n"
            "‚Ä¢ P ‚Äî –¥–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –∏—Ç–æ–≥–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏",
            reply_markup=kb,
        )
        return

    if data == "final_month":
        context.user_data["final_range_choice"] = {"mode": "month"}
        kb = InlineKeyboardMarkup(
            [
                [
                    InlineKeyboardButton(
                        "üìå –ü–æ –¥–∞—Ç–µ –Ω–∞—á–∞–ª–∞ (O)", callback_data="final_basis_start"
                    ),
                    InlineKeyboardButton(
                        "üìå –ü–æ –¥–∞—Ç–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è (P)", callback_data="final_basis_end"
                    ),
                ]
            ]
        )
        await query.message.reply_text(
            "–ó–∞ –º–µ—Å—è—Ü: –ø–æ –∫–∞–∫–æ–π –¥–∞—Ç–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å?\n\n"
            "‚Ä¢ O ‚Äî –¥–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –∏—Ç–æ–≥–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏\n"
            "‚Ä¢ P ‚Äî –¥–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –∏—Ç–æ–≥–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏",
            reply_markup=kb,
        )
        return

    if data == "final_period":
        context.user_data["final_range_choice"] = {"mode": "period"}
        kb = InlineKeyboardMarkup(
            [
                [
                    InlineKeyboardButton(
                        "üìå –ü–æ –¥–∞—Ç–µ –Ω–∞—á–∞–ª–∞ (O)", callback_data="final_basis_start"
                    ),
                    InlineKeyboardButton(
                        "üìå –ü–æ –¥–∞—Ç–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è (P)", callback_data="final_basis_end"
                    ),
                ]
            ]
        )
        await query.message.reply_text(
            "–í—ã–±–æ—Ä –ø–µ—Ä–∏–æ–¥–∞: –ø–æ –∫–∞–∫–æ–π –¥–∞—Ç–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å?\n\n"
            "‚Ä¢ O ‚Äî –¥–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –∏—Ç–æ–≥–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏\n"
            "‚Ä¢ P ‚Äî –¥–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –∏—Ç–æ–≥–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏",
            reply_markup=kb,
        )
        return

    # –≤—ã–±–æ—Ä –±–∞–∑—ã: O –∏–ª–∏ P
    if data in ("final_basis_start", "final_basis_end"):
        basis = "start" if data == "final_basis_start" else "end"
        state = context.user_data.get("final_range_choice")
        if not state:
            await query.message.reply_text(
                "–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º (–∑–∞ –Ω–µ–¥–µ–ª—é/–∑–∞ –º–µ—Å—è—Ü/–≤—ã–±—Ä–∞—Ç—å –ø–µ—Ä–∏–æ–¥) –≤ —Ä–∞–∑–¥–µ–ª–µ ¬´–ò—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏¬ª."
            )
            return

        mode = state.get("mode")
        # –Ω–µ–¥–µ–ª—å–Ω—ã–π –∏ –º–µ—Å—è—á–Ω—ã–π —Ä–µ–∂–∏–º—ã
        if mode in ("week", "month"):
            df = get_final_checks_df()
            if df is None:
                await query.message.reply_text(
                    "–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å —Ç–∞–±–ª–∏—Ü—É –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫."
                )
                context.user_data.pop("final_range_choice", None)
                return

            period = compute_auto_period_for_final(df, basis=basis, mode=mode)
            if not period:
                await query.message.reply_text(
                    "–í —Ç–∞–±–ª–∏—Ü–µ –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ –Ω–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞—Ç –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —Å—Ç–æ–ª–±—Ü–µ (O –∏–ª–∏ P)."
                )
                context.user_data.pop("final_range_choice", None)
                return

            start, end = period
            if mode == "week":
                mode_text = "–∑–∞ –Ω–µ–¥–µ–ª—é"
            else:
                mode_text = "–∑–∞ –º–µ—Å—è—Ü"

            basis_text = (
                "–ø–æ –¥–∞—Ç–µ –Ω–∞—á–∞–ª–∞ (O)" if basis == "start" else "–ø–æ –¥–∞—Ç–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è (P)"
            )

            header = (
                f"üìã –ò—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ {mode_text} {basis_text}\n"
                f"{start:%d.%m.%Y} ‚Äî {end:%d.%m.%Y}"
            )
            text_out = build_final_checks_text_filtered(
                df,
                start_date=start,
                end_date=end,
                header=header,
                basis=basis,
            )
            await send_long_text(query.message.chat, text_out)
            await send_final_checks_xlsx_filtered(
                chat_id=query.message.chat.id,
                df=df,
                context=context,
                start_date=start,
                end_date=end,
                basis=basis,
            )
            context.user_data.pop("final_range_choice", None)
            return

        # –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø–µ—Ä–∏–æ–¥
        if mode == "period":
            context.user_data["final_period"] = {
                "step": "start",
                "basis": basis,
            }
            context.user_data.pop("final_range_choice", None)
            await query.message.reply_text(
                "–í–≤–µ–¥–∏—Ç–µ –¥–∞—Ç—É –Ω–∞—á–∞–ª–∞ –ø–µ—Ä–∏–æ–¥–∞ (–î–î.–ú–ú.–ì–ì–ì–ì):"
            )
            return

        # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
        context.user_data.pop("final_range_choice", None)
        await query.message.reply_text(
            "–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑ –≤—ã–±—Ä–∞—Ç—å —Ä–µ–∂–∏–º."
        )
        return

    if data == "final_search_case":
        context.user_data["awaiting_final_case_search"] = True
        await query.message.reply_text(
            "–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä –¥–µ–ª–∞ (—Ñ–æ—Ä–º–∞—Ç 00-00-000000), –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ –Ω–∞–π—Ç–∏ "
            "–≤ –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–∫–∞—Ö:"
        )
        return


# -------------------------------------------------
# TEXT ROUTER
# -------------------------------------------------
async def text_router(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = update.message.text.strip()
    chat = update.message.chat


    # –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç (—Ä–µ–∂–∏–º –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ –ø–æ —Ç–∞–±–ª–∏—Ü–µ) ‚Äî –≤–∫–ª—é—á–µ–Ω–∏–µ
    if ENABLE_ASSISTANT and text == "üó£ –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç":
        context.user_data["assistant_mode"] = True
        await update.message.reply_text(
            "üó£ –†–µ–∂–∏–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –≤–∫–ª—é—á—ë–Ω.\n"
            "–ú–æ–∂–Ω–æ –ø–∏—Å–∞—Ç—å –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –≥–æ–ª–æ—Å–æ–º.\n\n"
            "–ü—Ä–∏–º–µ—Ä—ã:\n"
            "‚Ä¢ –ù–∞–π–¥–∏ 03-46-108600, —É—Å—Ç—Ä–∞–Ω–µ–Ω–æ –ª–∏ –ø–æ –ø–æ–∂–∞—Ä–Ω–æ–π\n"
            "‚Ä¢ –ß—Ç–æ –ø–æ –¥–µ–ª—É 09-27-001100?\n"
            "‚Ä¢ –ù–∞–π–¥–∏ –ø–æ –∑–∞—Å—Ç—Ä–æ–π—â–∏–∫—É –ò–ù–í–ï–°–¢–¶–ï–ù–¢–†\n\n"
            "–ß—Ç–æ–±—ã –≤—ã–π—Ç–∏: –Ω–∞–ø–∏—à–∏—Ç–µ ¬´–í—ã—Ö–æ–¥¬ª.",
            reply_markup=main_menu(),
        )
        return

    # –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç ‚Äî –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ä–µ–∂–∏–º–µ
    if ENABLE_ASSISTANT and context.user_data.get("assistant_mode"):
        await assistant_answer(update.message.chat, context, text, recognized_from_voice=False)
        return

    # –¢–ó –¥–ª—è –¶–ù–ò–õ ‚Äî –∑–∞–ø—É—Å–∫ –º–∞—Å—Ç–µ—Ä–∞ –∏–∑ –≥–ª–∞–≤–Ω–æ–≥–æ –º–µ–Ω—é
    if text in ("üß™ –¢–ó –¥–ª—è –¶–ù–ò–õ", "–¢–ó –¥–ª—è –¶–ù–ò–õ"):
        await cnil_start(update, context)
        return

    # –¢–ó –¥–ª—è –¶–ù–ò–õ ‚Äî –¥–µ–π—Å—Ç–≤–∏—è —Ä–∞–∑–¥–µ–ª–∞ (–∫–Ω–æ–ø–∫–∏ –º–µ–Ω—é)
    if text == "üìù –ó–∞–ø–æ–ª–Ω–∏—Ç—å —Ñ–æ—Ä–º—É":
        await cnil_start_form(update, context)
        return

    if text == "‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É":
        context.user_data["cnil_download_wait"] = True
        context.user_data.pop("cnil_change_step", None)
        await update.message.reply_text(
            "–í–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–æ–ª—å –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã –¶–ù–ò–õ:",
            reply_markup=cnil_menu_keyboard(),
        )
        return

    if text == "üîê –ò–∑–º–µ–Ω–∏—Ç—å –ø–∞—Ä–æ–ª—å —Å–∫–∞—á–∏–≤–∞–Ω–∏—è":
        context.user_data["cnil_change_step"] = 1
        context.user_data.pop("cnil_download_wait", None)
        await update.message.reply_text(
            "–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—É—â–∏–π –ø–∞—Ä–æ–ª—å —Å–∫–∞—á–∏–≤–∞–Ω–∏—è (–∏–ª–∏ —Ä–µ–∑–µ—Ä–≤–Ω—ã–π 051995):",
            reply_markup=cnil_menu_keyboard(),
        )
        return

    if text == "‚¨ÖÔ∏è –ù–∞–∑–∞–¥":
        # –æ—á–∏—Å—Ç–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏—è —Ä–∞–∑–¥–µ–ª–∞
        context.user_data.pop("cnil", None)
        context.user_data.pop("cnil_download_wait", None)
        context.user_data.pop("cnil_change_step", None)
        context.user_data.pop("cnil_new_password", None)
        await start(update, context)
        return

    # –¢–ó –¥–ª—è –¶–ù–ò–õ ‚Äî –æ–∂–∏–¥–∞–Ω–∏–µ –≤–≤–æ–¥–∞ –ø–∞—Ä–æ–ª—è –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    if context.user_data.get("cnil_download_wait"):
        entered = text.strip()
        ok = (entered == cnil_load_download_password()) or (entered == CNIL_MASTER_DOWNLOAD_PASSWORD)
        if not ok:
            await update.message.reply_text(
                "‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–æ–ª—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑ –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ ¬´‚¨ÖÔ∏è –ù–∞–∑–∞–¥¬ª.",
                reply_markup=cnil_menu_keyboard(),
            )
            return
        context.user_data.pop("cnil_download_wait", None)
        await cnil_send_results_excel(update, context)
        return

    # –¢–ó –¥–ª—è –¶–ù–ò–õ ‚Äî —Å–º–µ–Ω–∞ –ø–∞—Ä–æ–ª—è (—à–∞–≥ 1: –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ä–æ–≥–æ)
    if context.user_data.get("cnil_change_step") == 1:
        entered = text.strip()
        ok = (entered == cnil_load_download_password()) or (entered == CNIL_MASTER_DOWNLOAD_PASSWORD)
        if not ok:
            await update.message.reply_text(
                "‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–æ–ª—å. –í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—É—â–∏–π –ø–∞—Ä–æ–ª—å —Å–∫–∞—á–∏–≤–∞–Ω–∏—è (–∏–ª–∏ —Ä–µ–∑–µ—Ä–≤–Ω—ã–π 051995):",
                reply_markup=cnil_menu_keyboard(),
            )
            return
        context.user_data["cnil_change_step"] = 2
        await update.message.reply_text(
            "–í–≤–µ–¥–∏—Ç–µ –Ω–æ–≤—ã–π –ø–∞—Ä–æ–ª—å –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è (4‚Äì32 —Å–∏–º–≤–æ–ª–∞):",
            reply_markup=cnil_menu_keyboard(),
        )
        return

    # –¢–ó –¥–ª—è –¶–ù–ò–õ ‚Äî —Å–º–µ–Ω–∞ –ø–∞—Ä–æ–ª—è (—à–∞–≥ 2: –Ω–æ–≤—ã–π –ø–∞—Ä–æ–ª—å)
    if context.user_data.get("cnil_change_step") == 2:
        new_pw = text.strip()
        if len(new_pw) < 4 or len(new_pw) > 32:
            await update.message.reply_text(
                "‚ùå –ü–∞—Ä–æ–ª—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¥–ª–∏–Ω–æ–π 4‚Äì32 —Å–∏–º–≤–æ–ª–∞. –í–≤–µ–¥–∏—Ç–µ –Ω–æ–≤—ã–π –ø–∞—Ä–æ–ª—å:",
                reply_markup=cnil_menu_keyboard(),
            )
            return
        if new_pw == CNIL_MASTER_DOWNLOAD_PASSWORD:
            await update.message.reply_text(
                "‚ùå –≠—Ç–æ—Ç –ø–∞—Ä–æ–ª—å –∑–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω –∏ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π. –í–≤–µ–¥–∏—Ç–µ –¥—Ä—É–≥–æ–π –ø–∞—Ä–æ–ª—å:",
                reply_markup=cnil_menu_keyboard(),
            )
            return
        cnil_save_download_password(new_pw)
        context.user_data.pop("cnil_change_step", None)
        await update.message.reply_text(
            "‚úÖ –ü–∞—Ä–æ–ª—å —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –æ–±–Ω–æ–≤–ª—ë–Ω.\n\n–¢–µ–ø–µ—Ä—å —Ç–∞–±–ª–∏—Ü—É –º–æ–∂–Ω–æ —Å–∫–∞—á–∞—Ç—å –ø–æ –Ω–æ–≤–æ–º—É –ø–∞—Ä–æ–ª—é (–∏–ª–∏ –ø–æ —Ä–µ–∑–µ—Ä–≤–Ω–æ–º—É 051995).",
            reply_markup=cnil_menu_keyboard(),
        )
        return

    # –¢–ó –¥–ª—è –¶–ù–ò–õ ‚Äî –µ—Å–ª–∏ –º–∞—Å—Ç–µ—Ä –∞–∫—Ç–∏–≤–µ–Ω, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —à–∞–≥–∏ –≤–≤–æ–¥–∞
    if context.user_data.get("cnil"):
        await cnil_text_step(update, context)
        return

    # –ò–Ω—Å–ø–µ–∫—Ç–æ—Ä ‚Äî –ø–æ—à–∞–≥–æ–≤—ã–π –º–∞—Å—Ç–µ—Ä
    if "inspector_form" in context.user_data:
        await inspector_process(update, context)
        return

    # –ò—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ ‚Äî –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø–µ—Ä–∏–æ–¥
    if context.user_data.get("final_period"):
        period = context.user_data["final_period"]
        step = period.get("step")
        basis = period.get("basis", "any")

        # –®–ê–ì 1: –≤–≤–æ–¥ –¥–∞—Ç—ã –Ω–∞—á–∞–ª–∞
        if step == "start":
            try:
                start_date = datetime.strptime(text, "%d.%m.%Y").date()
                if start_date.year < 2000 or start_date.year > 2100:
                    raise ValueError("year out of range")

                period["start_date"] = start_date
                period["step"] = "end"
                context.user_data["final_period"] = period
                await update.message.reply_text(
                    "–í–≤–µ–¥–∏—Ç–µ –¥–∞—Ç—É –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø–µ—Ä–∏–æ–¥–∞ (–î–î.–ú–ú.–ì–ì–ì–ì):"
                )
            except Exception:
                await update.message.reply_text(
                    "–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –≤ –Ω–µ–≤–µ—Ä–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ.\n"
                    "–í–≤–µ–¥–∏—Ç–µ –≤ –≤–∏–¥–µ –î–î.–ú–ú.–ì–ì–ì–ì (–Ω–∞–ø—Ä–∏–º–µ—Ä, 05.01.2025)."
                )
            return

        # –®–ê–ì 2: –≤–≤–æ–¥ –¥–∞—Ç—ã –æ–∫–æ–Ω—á–∞–Ω–∏—è
        if step == "end":
            try:
                end_date = datetime.strptime(text, "%d.%m.%Y").date()
                if end_date.year < 2000 or end_date.year > 2100:
                    raise ValueError("year out of range")

                start_date = period.get("start_date")
                if start_date and end_date < start_date:
                    await update.message.reply_text(
                        "–î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è —Ä–∞–Ω—å—à–µ –¥–∞—Ç—ã –Ω–∞—á–∞–ª–∞.\n"
                        "–í–≤–µ–¥–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—É—é –¥–∞—Ç—É –æ–∫–æ–Ω—á–∞–Ω–∏—è (–î–î.–ú–ú.–ì–ì–ì–ì)."
                    )
                    return

                df = get_final_checks_df()
                if df is None:
                    await update.message.reply_text(
                        "–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å —Ç–∞–±–ª–∏—Ü—É –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫."
                    )
                    context.user_data.pop("final_period", None)
                    return

                basis_text = (
                    "–ø–æ –¥–∞—Ç–µ –Ω–∞—á–∞–ª–∞ (O)" if basis == "start" else "–ø–æ –¥–∞—Ç–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è (P)"
                )
                header = (
                    f"üìã –ò—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ {basis_text} "
                    f"–∑–∞ –ø–µ—Ä–∏–æ–¥ {start_date:%d.%m.%Y} ‚Äî {end_date:%d.%m.%Y}"
                )
                text_out = build_final_checks_text_filtered(
                    df,
                    start_date=start_date,
                    end_date=end_date,
                    header=header,
                    basis=basis,
                )
                await send_long_text(chat, text_out)
                await send_final_checks_xlsx_filtered(
                    chat_id=chat.id,
                    df=df,
                    context=context,
                    start_date=start_date,
                    end_date=end_date,
                    basis=basis,
                )
                context.user_data.pop("final_period", None)
            except Exception:
                await update.message.reply_text(
                    "–î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –≤ –Ω–µ–≤–µ—Ä–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ.\n"
                    "–í–≤–µ–¥–∏—Ç–µ –≤ –≤–∏–¥–µ –î–î.–ú–ú.–ì–ì–ì–ì (–Ω–∞–ø—Ä–∏–º–µ—Ä, 12.12.2025)."
                )
            return

    
    # üö® –ö—Ä–∞—Å–Ω—ã–µ –ª–∞–º–ø–æ—á–∫–∏ ‚Äî –≤–≤–æ–¥ –ø–µ—Ä–∏–æ–¥–∞
    if context.user_data.get("redlamps_period"):
        rp = context.user_data["redlamps_period"]
        step = rp.get("step")

        if step == "start":
            try:
                d_from = datetime.strptime(text, "%d.%m.%Y").date()
                rp["date_from"] = d_from
                rp["step"] = "end"
                context.user_data["redlamps_period"] = rp
                await update.message.reply_text("–í–≤–µ–¥–∏—Ç–µ –¥–∞—Ç—É –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø–µ—Ä–∏–æ–¥–∞ (–î–î.–ú–ú.–ì–ì–ì–ì):")
            except Exception:
                await update.message.reply_text(
                    "–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –≤ –Ω–µ–≤–µ—Ä–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ. –í–≤–µ–¥–∏—Ç–µ –î–î.–ú–ú.–ì–ì–ì–ì (–Ω–∞–ø—Ä–∏–º–µ—Ä, 02.06.2025)."
                )
            return

        if step == "end":
            try:
                d_to = datetime.strptime(text, "%d.%m.%Y").date()
                d_from = rp.get("date_from")
                if d_from and d_to < d_from:
                    await update.message.reply_text(
                        "–î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è —Ä–∞–Ω—å—à–µ –¥–∞—Ç—ã –Ω–∞—á–∞–ª–∞. –í–≤–µ–¥–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—É—é –¥–∞—Ç—É –æ–∫–æ–Ω—á–∞–Ω–∏—è (–î–î.–ú–ú.–ì–ì–ì–ì)."
                    )
                    return
                rp["date_to"] = d_to
                rp["step"] = "done"
                context.user_data["redlamps_period"] = rp
                await update.message.reply_text(
                    f"–ü–µ—Ä–∏–æ–¥ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {d_from:%d.%m.%Y} ‚Äî {d_to:%d.%m.%Y} (–¥–æ–ø—É—Å–∫ ¬±{REDLAMPS_TOLERANCE_DAYS_DEFAULT} –¥–Ω–µ–π).\n"
                    "–¢–µ–ø–µ—Ä—å –Ω–∞–∂–º–∏—Ç–µ ¬´üìä –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å BI-–ø–∞–Ω–µ–ª—å¬ª –≤ —Ä–∞–∑–¥–µ–ª–µ ¬´–ö—Ä–∞—Å–Ω—ã–µ –ª–∞–º–ø–æ—á–∫–∏¬ª."
                )
            except Exception:
                await update.message.reply_text(
                    "–î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –≤ –Ω–µ–≤–µ—Ä–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ. –í–≤–µ–¥–∏—Ç–µ –î–î.–ú–ú.–ì–ì–ì–ì (–Ω–∞–ø—Ä–∏–º–µ—Ä, 12.06.2025)."
                )
            return
# –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∫ –¥–æ—Ä–∞–±–æ—Ç–∫–µ –≥—Ä–∞—Ñ–∏–∫–∞
    if context.user_data.get("awaiting_rework_comment"):
        info = context.user_data.pop("awaiting_rework_comment")
        version = info["version"]
        approver = info["approver"]
        comment = text
        update_schedule_approval_status(version, approver, "rework", comment)
        await update.message.reply_text(
            "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Å–æ—Ö—Ä–∞–Ω—ë–Ω. –ì—Ä–∞—Ñ–∏–∫ –ø–æ–º–µ—á–µ–Ω –∫–∞–∫ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –Ω–∞ –¥–æ—Ä–∞–±–æ—Ç–∫—É."
        )
        return

    # –í–≤–æ–¥ —Å–ø–∏—Å–∫–∞ —Å–æ–≥–ª–∞—Å—É—é—â–∏—Ö
    if context.user_data.get("awaiting_approvers_input"):
        info = context.user_data.pop("awaiting_approvers_input")
        version = info["version"]

        raw = text.replace(",", " ").split()
        approvers: List[str] = []
        for token in raw:
            token = token.strip()
            if not token:
                continue
            if not token.startswith("@"):
                token = "@" + token
            approvers.append(token)
        approvers = list(dict.fromkeys(approvers))

        if not approvers:
            await update.message.reply_text("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ —é–∑–µ—Ä–Ω–µ–π–º–∞.")
            return

        set_current_approvers_for_version(approvers, version)

        lines = [
            "–ì—Ä–∞—Ñ–∏–∫ –Ω–∞ –Ω–æ–≤—É—é –Ω–µ–¥–µ–ª—é, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–æ–≥–ª–∞—Å–æ–≤–∞—Ç—å.",
            f"–í–µ—Ä—Å–∏—è: {version}",
            "",
            "–°–æ–≥–ª–∞—Å—É—é—â–∏–µ:",
        ]
        for a in approvers:
            lines.append(f"‚Ä¢ {a}")

        kb = InlineKeyboardMarkup(
            [
                [
                    InlineKeyboardButton(
                        f"‚úÖ –°–æ–≥–ª–∞—Å–æ–≤–∞—Ç—å ({a})", callback_data=f"schedule_approve:{a}"
                    ),
                    InlineKeyboardButton(
                        f"‚úèÔ∏è –ù–∞ –¥–æ—Ä–∞–±–æ—Ç–∫—É ({a})",
                        callback_data=f"schedule_rework:{a}",
                    ),
                ]
                for a in approvers
            ]
        )

        text_to_send = "\n".join(lines)

        await chat.send_message(text_to_send, reply_markup=kb)

        if SCHEDULE_NOTIFY_CHAT_ID is not None:
            try:
                await context.bot.send_message(
                    chat_id=SCHEDULE_NOTIFY_CHAT_ID,
                    text=text_to_send,
                    reply_markup=kb,
                )
            except Exception as e:
                log.error(
                    "–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤ —á–∞—Ç SCHEDULE_NOTIFY_CHAT_ID=%s: %s",
                    SCHEDULE_NOTIFY_CHAT_ID,
                    e,
                )

        await update.message.reply_text("–°–æ–≥–ª–∞—Å—É—é—â–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –∏ —É–≤–µ–¥–æ–º–ª–µ–Ω—ã.")
        return

    # –ü–æ–∏—Å–∫ –ø–æ –Ω–æ–º–µ—Ä—É –¥–µ–ª–∞ –≤ –∑–∞–º–µ—á–∞–Ω–∏—è—Ö
    if context.user_data.get("awaiting_case_search"):
        context.user_data.pop("awaiting_case_search", None)
        case_no = text.strip()
        df = get_remarks_df_current()
        if df is None:
            await update.message.reply_text(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å —Ñ–∞–π–ª –∑–∞–º–µ—á–∞–Ω–∏–π. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø –∫ —Ç–∞–±–ª–∏—Ü–µ."
            )
            return
        out_text = build_case_cards_text(df, case_no)
        await send_long_text(chat, out_text)
        return

    # –ü–æ–∏—Å–∫ –ø–æ –Ω–æ–º–µ—Ä—É –¥–µ–ª–∞ –≤ –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–∫–∞—Ö
    if context.user_data.get("awaiting_final_case_search"):
        context.user_data.pop("awaiting_final_case_search", None)
        case_no = text.strip()
        df = get_final_checks_df()
        if df is None:
            await update.message.reply_text(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å —Ç–∞–±–ª–∏—Ü—É –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫."
            )
            return
        header = f"üìã –ò—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ –Ω–æ–º–µ—Ä—É –¥–µ–ª–∞: {case_no}"
        text_out = build_final_checks_text_filtered(
            df, case_no=case_no, header=header
        )
        await send_long_text(chat, text_out)
        await send_final_checks_xlsx_filtered(
            chat_id=chat.id, df=df, context=context, case_no=case_no
        )
        return

    low = text.lower()


    if low == "üö® –∫—Ä–∞—Å–Ω—ã–µ –ª–∞–º–ø–æ—á–∫–∏":
        kb = redlamps_menu_inline()
        has_file = "‚úÖ" if context.user_data.get("redlamps_file_bytes") else "‚ùå"
        rp = context.user_data.get("redlamps_period") or {}
        has_period = "‚úÖ" if (rp.get("date_from") and rp.get("date_to")) else "‚ùå"
        msg = (
            "üö® –†–∞–∑–¥–µ–ª ¬´–ö—Ä–∞—Å–Ω—ã–µ –ª–∞–º–ø–æ—á–∫–∏¬ª\n\n"
            "1) –ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel-—Ñ–∞–π–ª (.xlsx)\n"
            "2) –í—ã–±–µ—Ä–∏—Ç–µ –ø–µ—Ä–∏–æ–¥ (–∫–æ–ª–æ–Ω–∫–∏ K‚ÄìL, –¥–æ–ø—É—Å–∫ ¬±5 –¥–Ω–µ–π)\n"
            "3) –°—Ñ–æ—Ä–º–∏—Ä—É–π—Ç–µ BI-–ø–∞–Ω–µ–ª—å (—Å—á—ë—Ç—á–∏–∫ –∞–∫—Ç–æ–≤/–ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –ø–æ –¥—É–±–ª—è–º –Ω–æ–º–µ—Ä–∞ –¥–µ–ª–∞)\n\n"
            f"–§–∞–π–ª: {has_file} | –ü–µ—Ä–∏–æ–¥: {has_period}"
        )
        await update.message.reply_text(msg, reply_markup=kb)
        return
    if low == "üìÖ –≥—Ä–∞—Ñ–∏–∫".lower():
        settings = get_schedule_state()
        is_adm = is_admin(update.effective_user.id)
        msg = build_schedule_text(is_adm, settings)
        user_username = update.effective_user.username or ""
        user_tag = f"@{user_username}" if user_username else None
        kb = build_schedule_inline(is_adm, settings, user_tag=user_tag)
        msg_full = (
            "üìÖ –†–∞–∑–¥–µ–ª ¬´–ì—Ä–∞—Ñ–∏–∫ –≤—ã–µ–∑–¥–æ–≤¬ª\n\n"
            "‚Ä¢ –°–º–æ—Ç—Ä–µ—Ç—å —Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è\n"
            "‚Ä¢ –û–±–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ–±—â–µ–π —Ç–∞–±–ª–∏—Ü—ã\n"
            "‚Ä¢ –°–∫–∞—á–∞—Ç—å –∫—Ä–∞—Å–∏–≤–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–Ω—ã–π Excel-—Ñ–∞–π–ª\n\n"
            "–ï—Å–ª–∏ –≤—ã –≤—Ö–æ–¥–∏—Ç–µ –≤ —Å–ø–∏—Å–æ–∫ —Å–æ–≥–ª–∞—Å—É—é—â–∏—Ö, –Ω–∏–∂–µ –±—É–¥—É—Ç –∫–Ω–æ–ø–∫–∏ "
            "¬´–°–æ–≥–ª–∞—Å–æ–≤–∞—Ç—å¬ª –∏ ¬´–ù–∞ –¥–æ—Ä–∞–±–æ—Ç–∫—É¬ª.\n\n"
            f"{msg}"
        )
        await update.message.reply_text(msg_full, reply_markup=kb)
        return

    if low == "üìù –∑–∞–º–µ—á–∞–Ω–∏—è".lower():
        kb = remarks_menu_inline()
        msg = (
            "üìù –†–∞–∑–¥–µ–ª ¬´–ó–∞–º–µ—á–∞–Ω–∏—è¬ª\n\n"
            "–ó–¥–µ—Å—å –¥–æ—Å—Ç—É–ø–Ω—ã:\n"
            "‚Ä¢ üîé –ø–æ–∏—Å–∫ –ø–æ –Ω–æ–º–µ—Ä—É –¥–µ–ª–∞ (—Å—Ç–æ–ª–±–µ—Ü I);\n"
            "‚Ä¢ üèó –û–ù–∑–° ‚Äî –≤—ã–±–æ—Ä 1‚Äì12, —Å–ø–∏—Å–æ–∫ –¥–µ–ª (–ù–æ–º–µ—Ä –¥–µ–ª–∞ (I) + –∞–¥—Ä–µ—Å) –∏ –æ—Ç–¥–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –Ω–µ—É—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã—Ö;\n"
            "‚Ä¢ üì• –æ—Ç–∫—Ä—ã—Ç—å –æ–±—â–∏–π —Ñ–∞–π–ª —Ç–∞–±–ª–∏—Ü—ã.\n\n"
            "–í—ã–±–µ—Ä–∏—Ç–µ –Ω—É–∂–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ:"
        )
        await update.message.reply_text(msg, reply_markup=kb)
        return

    if low in ("–∏–Ω—Å–ø–µ–∫—Ç–æ—Ä", "üëÆ –∏–Ω—Å–ø–µ–∫—Ç–æ—Ä"):
        kb = inspector_menu_inline()
        msg = (
            "üëÆ‚Äç‚ôÇÔ∏è –†–∞–∑–¥–µ–ª ¬´–ò–Ω—Å–ø–µ–∫—Ç–æ—Ä¬ª\n\n"
            "–ó–¥–µ—Å—å –º–æ–∂–Ω–æ:\n"
            "‚Ä¢ ‚ûï –¥–æ–±–∞–≤–∏—Ç—å –≤—ã–µ–∑–¥ –∏–Ω—Å–ø–µ–∫—Ç–æ—Ä–∞;\n"
            "‚Ä¢ üìã –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ –≤—ã–µ–∑–¥—ã;\n"
            "‚Ä¢ üì• —Å–∫–∞—á–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–π Excel —Å –≤—ã–µ–∑–¥–∞–º–∏;\n"
            "‚Ä¢ üîÑ –æ–±–Ω—É–ª–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—ã–µ–∑–¥–æ–≤ (–∫–Ω–æ–ø–∫–∞ ¬´–û–±–Ω–æ–≤–∏—Ç—å¬ª).\n\n"
            "–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ –∫–Ω–æ–ø–∫–∞–º–∏ –Ω–∏–∂–µ."
        )
        await update.message.reply_text(msg, reply_markup=kb)
        return

    if low == "üìà –∞–Ω–∞–ª–∏—Ç–∏–∫–∞".lower():
        conn = get_db()
        c = conn.cursor()
        c.execute(
            """SELECT version, approver, status, comment, decided_at, requested_at
               FROM schedule_approvals
               ORDER BY version DESC, approver"""
        )
        rows = c.fetchall()
        conn.close()

        if not rows:
            await update.message.reply_text("–ü–æ–∫–∞ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—é –≥—Ä–∞—Ñ–∏–∫–∞.")
            return

        by_ver: Dict[int, List[sqlite3.Row]] = {}
        for r in rows:
            by_ver.setdefault(r["version"], []).append(r)

        lines: List[str] = ["üìà –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø–æ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—é –≥—Ä–∞—Ñ–∏–∫–∞:", ""]

        for ver in sorted(by_ver.keys(), reverse=True):
            approvals = by_ver[ver]
            header = build_schedule_header(ver, approvals)
            lines.append("")
            lines.append(header + ":")
            for r in approvals:
                appr = r["approver"]
                status = r["status"] or "pending"
                decided = _format_dt(r["decided_at"])
                requested = _format_dt(r["requested_at"])
                comment = r["comment"] or ""

                if status == "pending":
                    lines.append(f"‚Ä¢ {appr} ‚Äî –æ–∂–∏–¥–∞–µ—Ç, –∑–∞–ø—Ä–æ—à–µ–Ω–æ {requested}")
                elif status == "approved":
                    lines.append(f"‚Ä¢ {appr} ‚Äî –°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–æ {decided} ‚úÖ")
                elif status == "rework":
                    if comment:
                        lines.append(
                            f"‚Ä¢ {appr} ‚Äî –ù–∞ –¥–æ—Ä–∞–±–æ—Ç–∫—É {decided} (–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: {comment})"
                        )
                    else:
                        lines.append(f"‚Ä¢ {appr} ‚Äî –ù–∞ –¥–æ—Ä–∞–±–æ—Ç–∫—É {decided}")

        await send_long_text(chat, "\n".join(lines))
        return

    if low == "–∏—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏":
        # –ö–∞–∂–¥—ã–π —Ä–∞–∑ –ø—Ä–∏ –≤—Ö–æ–¥–µ –≤ —Ä–∞–∑–¥–µ–ª –æ–±–Ω–æ–≤–ª—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫
        ok = refresh_final_checks_local_file()
        if not ok:
            await update.message.reply_text(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å —Ñ–∞–π–ª –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫.\n"
                "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø –∫ Google Sheets –∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é FINAL_CHECKS_SPREADSHEET_ID."
            )
            return

        # 1) –ë–µ—Ä—ë–º –∏—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑ —Ü–µ–ª–µ–≤—ã—Ö –ª–∏—Å—Ç–æ–≤ (–ú–ö–î/–°–û–¶–û–ë–™–ï–ö–¢–´/–û—Å—Ç–∞–ª—å–Ω–æ–µ)
        df_final = get_final_checks_df_target_sheets()

        # 2) –ë–µ—Ä—ë–º —Ç–∞–±–ª–∏—Ü—É –∑–∞–º–µ—á–∞–Ω–∏–π (–≤—Ç–æ—Ä–∞—è —Ç–∞–±–ª–∏—Ü–∞) ‚Äî –ø–æ–∏—Å–∫ –ø–æ –Ω–æ–º–µ—Ä—É –¥–µ–ª–∞ (I)
        df_remarks = get_remarks_df_current()

        if df_final is None:
            await update.message.reply_text(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å —Ç–∞–±–ª–∏—Ü—É –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ (—Ü–µ–ª–µ–≤—ã–µ –ª–∏—Å—Ç—ã)."
            )
            return

        if df_final.empty:
            await update.message.reply_text(
                "–í —Ü–µ–ª–µ–≤—ã—Ö –ª–∏—Å—Ç–∞—Ö –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ –Ω–µ—Ç —Å—Ç—Ä–æ–∫ —Å –¥–∞–Ω–Ω—ã–º–∏."
            )
            return

        if df_remarks is None or df_remarks.empty:
            await update.message.reply_text(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å —Ç–∞–±–ª–∏—Ü—É –∑–∞–º–µ—á–∞–Ω–∏–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞—Ä—É—à–µ–Ω–∏–π."
            )
            return

        # 3) –§–æ—Ä–º–∏—Ä—É–µ–º ¬´BI‚Äë–ø–∞–Ω–µ–ª—å¬ª: –¥–µ–ª–∞ —Å –¥–∞—Ç–æ–π –Ω–∞—á–∞–ª–∞ (O) —á–µ—Ä–µ–∑ 1‚Äì10 –¥–Ω–µ–π –∏ —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º ¬´–Ω–µ—Ç¬ª –≤ Q/R/Y/AD
        try:
            panel_text = build_final_checks_violations_bi_panel(
                df_final=df_final,
                df_remarks=df_remarks,
                days_min=1,
                days_max=10,
                report_day=local_now().date(),
            )
        except Exception as e:
            log.error("–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è BI‚Äë–ø–∞–Ω–µ–ª–∏ –ø–æ –∏—Ç–æ–≥–æ–≤—ã–º –ø—Ä–æ–≤–µ—Ä–∫–∞–º: %s", e)
            await update.message.reply_text(
                "–ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Å–ø–∏—Å–æ–∫ –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ —Å –Ω–∞—Ä—É—à–µ–Ω–∏—è–º–∏."
            )
            return

        await send_long_text(chat, panel_text)
        return

    await update.message.reply_text(
        "–Ø –≤–∞—Å –Ω–µ –ø–æ–Ω—è–ª. –í—ã–±–µ—Ä–∏—Ç–µ –ø—É–Ω–∫—Ç –º–µ–Ω—é –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ /start.",
        reply_markup=main_menu(),
    )


# -------------------------------------------------
# DOCUMENT HANDLER
# -------------------------------------------------

async def document_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # üö® –ö—Ä–∞—Å–Ω—ã–µ –ª–∞–º–ø–æ—á–∫–∏ ‚Äî –ø—Ä–∏–Ω–∏–º–∞–µ–º Excel-—Ñ–∞–π–ª —Ç–æ–ª—å–∫–æ –∫–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–∂–∞–ª ¬´–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª¬ª
    if context.user_data.get("awaiting_redlamps_upload"):
        doc = update.message.document
        if not doc:
            await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ñ–∞–π–ª. –ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –æ—Ç–ø—Ä–∞–≤–∫—É.")
            return

        fname = (doc.file_name or "").lower()
        if not fname.endswith(".xlsx"):
            await update.message.reply_text("–ù—É–∂–µ–Ω —Ñ–∞–π–ª Excel –≤ —Ñ–æ—Ä–º–∞—Ç–µ .xlsx. –û—Ç–ø—Ä–∞–≤—å—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–∞–π–ª.")
            return

        try:
            tg_file = await context.bot.get_file(doc.file_id)
            bio = BytesIO()
            await tg_file.download_to_memory(out=bio)
            bio.seek(0)
            context.user_data["redlamps_file_bytes"] = bio.getvalue()
            context.user_data["redlamps_file_name"] = doc.file_name or "upload.xlsx"
            context.user_data.pop("awaiting_redlamps_upload", None)

            rp = context.user_data.get("redlamps_period") or {}
            has_period = "‚úÖ" if (rp.get("date_from") and rp.get("date_to")) else "‚ùå"

            await update.message.reply_text(
                f"‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: {doc.file_name}\n"
                f"–ü–µ—Ä–∏–æ–¥: {has_period}\n\n"
                "–î–∞–ª–µ–µ: –∑–∞–¥–∞–π—Ç–µ –ø–µ—Ä–∏–æ–¥ –∫–Ω–æ–ø–∫–æ–π ¬´üìÖ –í—ã–±—Ä–∞—Ç—å –ø–µ—Ä–∏–æ–¥ (K‚ÄìL)¬ª –∏ –Ω–∞–∂–º–∏—Ç–µ ¬´üìä –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å BI-–ø–∞–Ω–µ–ª—å¬ª.",
                reply_markup=redlamps_menu_inline(),
            )
            return
        except Exception as e:
            log.error("REDLAMPS: –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: %s", e)
            await update.message.reply_text("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
            return

    # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ –≤ –±–æ—Ç–µ –æ—Ç–∫–ª—é—á–µ–Ω–∞
    await update.message.reply_text(
        "–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ —á–µ—Ä–µ–∑ –±–æ—Ç–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ–±—â—É—é Google-—Ç–∞–±–ª–∏—Ü—É."
    )




# -------------------------------------------------
# VOICE (SpeechKit STT) -> –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç
# -------------------------------------------------
async def voice_router(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not ENABLE_ASSISTANT:
        await update.message.reply_text("–ì–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –æ—Ç–∫–ª—é—á—ë–Ω –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–º.")
        return
    try:
        file = await context.bot.get_file(update.message.voice.file_id)
        ogg = await file.download_as_bytearray()
        text_q = yandex_speech_to_text(bytes(ogg))
        # –≤–∫–ª—é—á–∞–µ–º —Ä–µ–∂–∏–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
        context.user_data["assistant_mode"] = True
        await assistant_answer(update.message.chat, context, text_q, recognized_from_voice=True)
    except Exception as e:
        await update.message.reply_text(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ: {e}")


# -------------------------------------------------
# START / HELP
# -------------------------------------------------
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    msg = (
        "–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ –±–æ—Ç–∞ –æ—Ç–¥–µ–ª–∞ –°–û–¢.\n\n"
        "–û—Å–Ω–æ–≤–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã:\n"
        "‚Ä¢ üìÖ –ì—Ä–∞—Ñ–∏–∫ ‚Äî —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ –≤—ã–µ–∑–¥–æ–≤\n"
        "‚Ä¢ üìù –ó–∞–º–µ—á–∞–Ω–∏—è ‚Äî –ø–æ–∏—Å–∫ –ø–æ –Ω–æ–º–µ—Ä—É –¥–µ–ª–∞, –û–ù–∑–° –∏ —Å—Ç–∞—Ç—É—Å—ã ¬´–Ω–µ—Ç¬ª\n"
        "‚Ä¢ –ò–Ω—Å–ø–µ–∫—Ç–æ—Ä ‚Äî –≤—ã–µ–∑–¥—ã –∏–Ω—Å–ø–µ–∫—Ç–æ—Ä–∞\n"
        "‚Ä¢ –ò—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ ‚Äî –ø–µ—Ä–µ—á–µ–Ω—å –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Ç–∞–±–ª–∏—Ü–µ\n"
        "‚Ä¢ üö® –ö—Ä–∞—Å–Ω—ã–µ –ª–∞–º–ø–æ—á–∫–∏ ‚Äî –∑–∞–≥—Ä—É–∑–∫–∞ Excel –∏ BI-–ø–∞–Ω–µ–ª—å –ø–æ –∞–∫—Ç–∞–º/–ø—Ä–æ—Ç–æ–∫–æ–ª–∞–º\n"
        "‚Ä¢ üìà –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ ‚Äî –∏—Å—Ç–æ—Ä–∏—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–π\n\n"
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–¥–µ–ª —Å –ø–æ–º–æ—â—å—é –∫–Ω–æ–ø–æ–∫ –Ω–∏–∂–µ."
    )
    await update.message.reply_text(msg, reply_markup=main_menu())


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    msg = (
        "–°–ø—Ä–∞–≤–∫–∞ –ø–æ –±–æ—Ç—É –°–û–¢:\n\n"
        "üìÖ –ì—Ä–∞—Ñ–∏–∫ ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è, –æ–±–Ω–æ–≤–∏—Ç—å, —Å–∫–∞—á–∞—Ç—å Excel.\n"
        "üìù –ó–∞–º–µ—á–∞–Ω–∏—è ‚Äî –ø–æ–∏—Å–∫ –ø–æ –Ω–æ–º–µ—Ä—É –¥–µ–ª–∞ (I), —Ä–∞–±–æ—Ç–∞ —Å –û–ù–∑–° –∏ –ø—Ä–æ—Å–º–æ—Ç—Ä —Å—Ç–∞—Ç—É—Å–æ–≤ ¬´–Ω–µ—Ç¬ª.\n"
        "–ò–Ω—Å–ø–µ–∫—Ç–æ—Ä ‚Äî –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏ –≤—ã–≥—Ä—É–∑–∫–∞ –≤—ã–µ–∑–¥–æ–≤ –∏–Ω—Å–ø–µ–∫—Ç–æ—Ä–∞.\n"
        "–ò—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ ‚Äî —Å–ø–∏—Å–æ–∫ –∏ –≤—ã–≥—Ä—É–∑–∫–∞ –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ –∑–∞ –ø–µ—Ä–∏–æ–¥ –∏–ª–∏ –ø–æ –¥–µ–ª—É.\n"
        "üìà –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ ‚Äî –∏—Å—Ç–æ—Ä–∏—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–π –ø–æ –≤–µ—Ä—Å–∏—è–º –≥—Ä–∞—Ñ–∏–∫–∞.\n"
    )
    await update.message.reply_text(msg, reply_markup=main_menu())


# -------------------------------------------------
# MAIN
# -------------------------------------------------
async def cb_file_action(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    q = update.callback_query
    if not q:
        return
    await q.answer()
    data = q.data or ""
    try:
        _, action, token = data.split(":", 2)
    except Exception:
        return
    meta = FILE_TOKEN_MAP.get(token)
    if not meta:
        await q.edit_message_text("–°—Å—ã–ª–∫–∞ —É—Å—Ç–∞—Ä–µ–ª–∞. –ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –∑–∞–ø—Ä–æ—Å.")
        return
    url = meta.get("url", "")
    if not url:
        await q.edit_message_text("–°—Å—ã–ª–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
        return

    if action == "open":
        await q.edit_message_text(f"–û—Ç–∫—Ä—ã—Ç—å —Å—Å—ã–ª–∫—É: {url}", disable_web_page_preview=True)
        return

    try:
        content, fname, mime = download_external_file(url)
    except Exception as e:
        await q.edit_message_text(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª: {e}\n\n–°—Å—ã–ª–∫–∞: {url}", disable_web_page_preview=True)
        return

    if action == "download":
        await context.bot.send_document(
            chat_id=q.message.chat_id,
            document=content,
            filename=fname,
            caption=f"–§–∞–π–ª: {fname}\n–ò—Å—Ç–æ—á–Ω–∏–∫: {url}"
        )
        return

    if action == "analyze":
        analysis = analyze_file_bytes(content, fname, mime)
        await context.bot.send_message(
            chat_id=q.message.chat_id,
            text=f"üîé –ê–Ω–∞–ª–∏–∑: {fname}\n\n{analysis}\n\n–ò—Å—Ç–æ—á–Ω–∏–∫: {url}",
            disable_web_page_preview=True
        )
        await context.bot.send_document(
            chat_id=q.message.chat_id,
            document=content,
            filename=fname,
            caption=f"–§–∞–π–ª –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞: {fname}"
        )
        return


# =================================================
# üß™ –¢–ó –¥–ª—è –¶–ù–ò–õ ‚Äî –ß–µ–∫-–ª–∏—Å—Ç (–º–∞—Å—Ç–µ—Ä)
# =================================================
CNIL_MENU_LABEL = "üß™ –¢–ó –¥–ª—è –¶–ù–ò–õ"
CNIL_CASE_RE = re.compile(r"\b(\d{2})[-\s]?(\d{2})[-\s]?(\d{6})\b")

# –ù–∞—á–∞–ª—å–Ω–∏–∫–∏ —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –æ—Ç–¥–µ–ª–æ–≤ –ì–æ—Å—Å—Ç—Ä–æ–π–Ω–∞–¥–∑–æ—Ä–∞ –ú–û (–ø–æ –ø–µ—Ä–≤—ã–º 2 —Ü–∏—Ñ—Ä–∞–º –Ω–æ–º–µ—Ä–∞ –¥–µ–ª–∞)
CNIL_HEAD_BY_PREFIX = {
    "01": "–ì–µ—Ä–∞—Å–∏–º–µ–Ω–∫–æ –î.–ê.",
    "02": "–ö—É–∑—å–º–∏—á–µ–≤ –ï.–ú.",
    "03": "–ú–∞—Ä–∫–µ–ª–æ–≤ –ê.–°.",
    "04": "–ì—É—Ç–Ω–æ–≤ –ó.–í.",
    "05": "–ê—Ä–º–µ–Ω–∞–∫—è–Ω –ì.–ë.",
    "06": "–ö—Ä–∞—Å–Ω–æ–≤ –í.–ê.",
    "07": "–î–µ–Ω–∏—Å–æ–≤ –î.–ú.",
    "08": "–†–æ–º–∞–Ω–æ–≤–∞ –õ.–ü.",
    "09": "–°–∞–¥–æ—è–Ω –î.–¢.",
    "10": "–ü–∞–≤–ª–æ–≤ –ê.–í.",
    "11": "–ï—Ñ–∏–º–æ–≤ –†.–°.",
    "12": "–ù–µ—Å—Ç–µ—Ä–æ–≤ –ò.–ú.",
}


def cnil_head_for_case(case_no: str) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –§–ò–û –Ω–∞—á–∞–ª—å–Ω–∏–∫–∞ –ø–æ –ø–µ—Ä–≤—ã–º 2 —Ü–∏—Ñ—Ä–∞–º –Ω–æ–º–µ—Ä–∞ –¥–µ–ª–∞."""
    try:
        prefix = (case_no or "").strip().split("-")[0].zfill(2)
    except Exception:
        prefix = ""
    return CNIL_HEAD_BY_PREFIX.get(prefix, "–ì—É—Ç–Ω–æ–≤ –ó.–í.")


def _docx_replace_paragraph_text(paragraph, new_text: str) -> None:
    """–ó–∞–º–µ–Ω—è–µ—Ç —Ç–µ–∫—Å—Ç –∞–±–∑–∞—Ü–∞ —Ü–µ–ª–∏–∫–æ–º (—Ç–µ—Ä—è–µ—Ç —Ä–∞–∑–Ω–æ—Ñ–æ—Ä–º–∞—Ç–Ω—ã–µ run'—ã –≤–Ω—É—Ç—Ä–∏ –∞–±–∑–∞—Ü–∞, –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç–∏–ª—å –∞–±–∑–∞—Ü–∞)."""
    # python-docx: paragraph.text is writable
    paragraph.text = new_text


def _docx_regex_replace(doc, pattern: re.Pattern, repl_func) -> int:
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç regex-–∑–∞–º–µ–Ω—É –∫–æ –≤—Å–µ–º –∞–±–∑–∞—Ü–∞–º (–∏ —Ç–∞–±–ª–∏—Ü–∞–º) –¥–æ–∫—É–º–µ–Ω—Ç–∞. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–∏—Å–ª–æ –∑–∞–º–µ–Ω—ë–Ω–Ω—ã—Ö –∞–±–∑–∞—Ü–µ–≤."""
    changed = 0

    def handle_paragraph(paragraph):
        nonlocal changed
        txt = paragraph.text
        if not txt:
            return
        new_txt = pattern.sub(repl_func, txt)
        if new_txt != txt:
            _docx_replace_paragraph_text(paragraph, new_txt)
            changed += 1

    for para in doc.paragraphs:
        handle_paragraph(para)

    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                for para in cell.paragraphs:
                    handle_paragraph(para)

    return changed


def cnil_generate_t3_docx(row: dict) -> str:
    """Generate filled TEST_T3 .docx based on template.

    The template contains a 3-column table (–ò–Ω–¥–µ–∫—Å —Ä–∞–±–æ—Ç—ã / –°–æ—Å—Ç–∞–≤ —Ä–∞–±–æ—Ç / –ö—Ä–∞—Ç–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è...).
    We rebuild the table rows exactly to the number of selected works so that it automatically
    grows/shrinks depending on the user's selection.

    Expected row keys (best-effort):
      - case_no / –ù–æ–º–µ—Ä –¥–µ–ª–∞
      - works / –†–∞–±–æ—Ç—ã (comma-separated or semicolon-separated string)
      - head_name (optional) - territorial head FIO to be inserted
    """
    from docx import Document
    from docx.shared import Pt
    from docx.oxml import OxmlElement
    from docx.oxml.ns import qn

    # –¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ: –≤–µ—Å—å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å Times New Roman 12
    FONT_NAME = "Times New Roman"
    FONT_SIZE = Pt(12)

    def _set_run_font(run):
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –≤—ã—Å—Ç–∞–≤–ª—è–µ—Ç —à—Ä–∏—Ñ—Ç –∏ –∫–µ–≥–ª—å –¥–ª—è run (–≤–∫–ª—é—á–∞—è EastAsia)."""
        try:
            run.font.name = FONT_NAME
            run.font.size = FONT_SIZE
            rpr = run._element.get_or_add_rPr()
            rfonts = rpr.find(qn('w:rFonts'))
            if rfonts is None:
                rfonts = OxmlElement('w:rFonts')
                rpr.append(rfonts)
            rfonts.set(qn('w:ascii'), FONT_NAME)
            rfonts.set(qn('w:hAnsi'), FONT_NAME)
            rfonts.set(qn('w:cs'), FONT_NAME)
            rfonts.set(qn('w:eastAsia'), FONT_NAME)
        except Exception:
            # –ù–∞ —Å–ª—É—á–∞–π –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º—ã—Ö –≤–µ—Ä—Å–∏–π python-docx: –Ω–µ –ø–∞–¥–∞–µ–º
            pass

    def _set_paragraph_font(p):
        """–í—ã—Å—Ç–∞–≤–ª—è–µ—Ç Times New Roman 12 –¥–ª—è –≤—Å–µ—Ö runs –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ (—Å–æ–∑–¥–∞—ë—Ç run –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏)."""
        if not p.runs:
            _set_run_font(p.add_run(""))
        for r in p.runs:
            _set_run_font(r)

    def _get_case_no(r: dict) -> str:
        for k in ('case_no', '–ù–æ–º–µ—Ä –¥–µ–ª–∞', '–Ω–æ–º–µ—Ä –¥–µ–ª–∞', 'case', '–¥–µ–ª–æ'):
            v = r.get(k)
            if v:
                return str(v).strip()
        return ''

    def _split_works(val) -> list[str]:
        if not val:
            return []
        s = str(val).strip()
        # common separators in this bot
        parts = re.split(r'[\n;]+', s)
        out = [p.strip() for p in parts if p and p.strip()]
        return out

    def _parse_work(item: str) -> tuple[str, str]:
        """Return (index, text). If no explicit index, index is empty."""
        m = re.match(r'^\s*([0-9]+(?:\.[0-9]+)*)\s+(.*)$', item)
        if m:
            return m.group(1), m.group(2).strip()
        return '', item.strip()

    def _set_table_autofit(table):
        # python-docx has limited support; set both flags + XML tblLayout
        try:
            table.autofit = True
        except Exception:
            pass
        tbl = table._tbl
        tblPr = tbl.tblPr
        tblLayout = tblPr.find(qn('w:tblLayout'))
        if tblLayout is None:
            tblLayout = OxmlElement('w:tblLayout')
            tblPr.append(tblLayout)
        tblLayout.set(qn('w:type'), 'autofit')

    def _set_table_borders(table):
        # Ensure visible borders for the whole table (Word can drop gridlines on rebuilt tables)
        try:
            tbl = table._tbl
            tblPr = tbl.tblPr
            # Remove existing tblBorders (if any)
            for el in list(tblPr):
                if el.tag.endswith('tblBorders'):
                    tblPr.remove(el)
            tblBorders = OxmlElement('w:tblBorders')
            for edge in ('top', 'left', 'bottom', 'right', 'insideH', 'insideV'):
                e = OxmlElement(f'w:{edge}')
                e.set(qn('w:val'), 'single')
                e.set(qn('w:sz'), '8')  # 1/8 pt units
                e.set(qn('w:space'), '0')
                e.set(qn('w:color'), '000000')
                tblBorders.append(e)
            tblPr.append(tblBorders)
        except Exception:
            pass

        # Also set borders per-cell for maximum compatibility
        try:
            for row in table.rows:
                for cell in row.cells:
                    tcPr = cell._tc.get_or_add_tcPr()
                    # Remove existing tcBorders (if any)
                    for el in list(tcPr):
                        if el.tag.endswith('tcBorders'):
                            tcPr.remove(el)
                    tcBorders = OxmlElement('w:tcBorders')
                    for edge in ('top', 'left', 'bottom', 'right', 'insideH', 'insideV'):
                        e = OxmlElement(f'w:{edge}')
                        e.set(qn('w:val'), 'single')
                        e.set(qn('w:sz'), '8')
                        e.set(qn('w:space'), '0')
                        e.set(qn('w:color'), '000000')
                        tcBorders.append(e)
                    tcPr.append(tcBorders)
        except Exception:
            pass


    # inputs
    case_no = _get_case_no(row)
    works_items = _split_works(row.get('works') or row.get('–†–∞–±–æ—Ç—ã') or row.get('works_text'))
    head_name = (row.get('head_name') or row.get('–ù–∞—á–∞–ª—å–Ω–∏–∫') or row.get('–ù–∞—á–∞–ª—å–Ω–∏–∫ —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∞–ª—å–Ω–æ–≥–æ –æ—Ç–¥–µ–ª–∞') or '').strip()
    if (not head_name) and case_no:
        head_name = cnil_head_for_case(case_no)


    tpl = CNIL_T3_TEMPLATE
    if not os.path.exists(tpl):
        raise FileNotFoundError(f"CNIL template not found: {tpl}")

    doc = Document(tpl)

    # Ensure newly created/modified text is in Times New Roman 12.
    # Setting Normal helps runs created by python-docx, while we also explicitly
    # enforce on paragraphs/cells we touch.
    try:
        normal_font = doc.styles["Normal"].font
        normal_font.name = FONT_NAME
        normal_font.size = FONT_SIZE
    except Exception:
        pass

    def _apply_font_to_paragraph(paragraph):
        if paragraph is None:
            return
        if not paragraph.runs:
            r = paragraph.add_run("")
            _set_run_font(r)
            return
        for r in paragraph.runs:
            _set_run_font(r)

    # Replace the '–ö–æ–¥ –æ–±—ä–µ–∫—Ç–∞' line robustly (do not rely on a hardcoded code)
    if case_no:
        for p in doc.paragraphs:
            if '–ö–æ–¥ –æ–±—ä–µ–∫—Ç–∞' in p.text:
                # Normalize: '–ö–æ–¥ –æ–±—ä–µ–∫—Ç–∞: ‚Ññ XX-XX-XXXXXX.'
                p.text = re.sub(r'–ö–æ–¥ –æ–±—ä–µ–∫—Ç–∞\s*:\s*‚Ññ\s*[^\.\n]+', f'–ö–æ–¥ –æ–±—ä–µ–∫—Ç–∞: ‚Ññ {case_no}', p.text)
                _apply_font_to_paragraph(p)

    # Replace head FIO if provided (keep template default otherwise)
    if head_name:
        for p in doc.paragraphs:
            if '–ù–∞—á–∞–ª—å–Ω–∏–∫ —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∞–ª—å–Ω–æ–≥–æ –æ—Ç–¥–µ–ª–∞' in p.text and '–ì–æ—Å—Å—Ç—Ä–æ–π–Ω–∞–¥–∑–æ—Ä–∞ –ú–û' in p.text:
                # replace everything after underscore/line to FIO
                p.text = re.sub(r'(–ù–∞—á–∞–ª—å–Ω–∏–∫ —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∞–ª—å–Ω–æ–≥–æ –æ—Ç–¥–µ–ª–∞\s*–ì–æ—Å—Å—Ç—Ä–æ–π–Ω–∞–¥–∑–æ—Ä–∞\s*–ú–û\s*[^_\n]*_\s*)([^\n]+)$', r'\1' + head_name, p.text)
                _apply_font_to_paragraph(p)

                p.text = re.sub(r'(–ù–∞—á–∞–ª—å–Ω–∏–∫ —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∞–ª—å–Ω–æ–≥–æ –æ—Ç–¥–µ–ª–∞\s*–ì–æ—Å—Å—Ç—Ä–æ–π–Ω–∞–¥–∑–æ—Ä–∞\s*–ú–û\s*.*?\s)\S+\s*[–ê-–Ø–Å]\.[–ê-–Ø–Å]\.$', r'\1' + head_name, p.text)
                _apply_font_to_paragraph(p)

    # Rebuild the works table to match number of works
    if works_items:
        # heuristic: choose the first 4-column table whose header contains '–ò–Ω–¥–µ–∫—Å', '–°–æ—Å—Ç–∞–≤' and '–û—Ç–º–µ—Ç–∫–∞'
        target = None
        for t in doc.tables:
            try:
                if (
                    len(t.columns) >= 4
                    and t.cell(0, 0).text.strip().startswith('–ò–Ω–¥–µ–∫—Å')
                    and '–°–æ—Å—Ç–∞–≤' in t.cell(0, 1).text
                    and ('–û—Ç–º–µ—Ç–∫–∞' in t.cell(0, 2).text or '–û–°–ò' in t.cell(0, 2).text)
                ):
                    target = t
                    break
            except Exception:
                continue

        if target is not None:
            _set_table_autofit(target)
            _set_table_borders(target)

            # keep header row (row 0), remove all other rows
            while len(target.rows) > 1:
                target._tbl.remove(target.rows[1]._tr)

            wm = row.get("work_marks") or {}

            for item in works_items:
                idx, txt = _parse_work(item)
                r = target.add_row()
                # column 0: index
                r.cells[0].text = idx
                # column 1: composition
                r.cells[1].text = ('- ' + txt) if txt and not txt.startswith('-') else txt
                # column 2: marks per work
                if isinstance(wm, dict):
                    r.cells[2].text = wm.get(item, '') or wm.get(txt, '')
                else:
                    r.cells[2].text = ''
                # column 3: short info
                r.cells[3].text = ''

                # Enforce font on inserted cell text
                for c in r.cells:
                    for p in c.paragraphs:
                        _set_paragraph_font(p)

    # Output path: do not depend on a global DATA_DIR (it may be None in some deployments)
    try:
        out_dir = str(cnil_data_dir())
    except Exception:
        out_dir = os.getenv("DATA_DIR") or ("/data" if os.path.isdir("/data") else "data")
    os.makedirs(out_dir, exist_ok=True)
    safe_case = case_no if case_no else "NOCASE"
    out_path = os.path.join(out_dir, f"T3_{safe_case}.docx")
    doc.save(out_path)
    return out_path

def cnil_data_dir() -> Path:
    # Railway volume –æ–±—ã—á–Ω–æ –º–æ–Ω—Ç–∏—Ä—É–µ—Ç—Å—è –≤ /data
    env_dir = os.getenv("DATA_DIR")
    if env_dir:
        p = Path(env_dir)
    else:
        p = Path("/data") if Path("/data").exists() else Path("data")
    p.mkdir(parents=True, exist_ok=True)
    return p

def cnil_results_path() -> Path:
    return cnil_data_dir() / "cnil_results.xlsx"


def cnil_append_to_gsheet(row: dict) -> str:
    """
    Append one CNIL record to Google Sheets.

    Config:
      - CNIL_GSHEET_ID: Spreadsheet ID (defaults to the provided sheet)
      - CNIL_SHEET_NAME: Worksheet title (default: "–¢–ó –¥–ª—è –¶–ù–ò–õ")
      - Credentials (one of):
          * GOOGLE_SERVICE_ACCOUNT_JSON : service account json as a string
          * GOOGLE_APPLICATION_CREDENTIALS : path to json file
          * GOOGLE_SERVICE_ACCOUNT_FILE : path to json file
    """
    sheet_id = os.getenv("CNIL_GSHEET_ID", "10sIT5I1WIkg2YzNHUpQOgeW2tN-PeHhZbogzp3G468s")
    ws_name = os.getenv("CNIL_SHEET_NAME", "–¢–ó –¥–ª—è –¶–ù–ò–õ")

    sa_json = os.getenv("GOOGLE_SERVICE_ACCOUNT_JSON")
    sa_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS") or os.getenv("GOOGLE_SERVICE_ACCOUNT_FILE")

    try:
        import gspread
        from google.oauth2.service_account import Credentials
    except Exception as e:
        raise RuntimeError(f"gspread/google-auth –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã: {e}")

    if sa_json:
        try:
            info = json.loads(sa_json)
        except Exception as e:
            raise RuntimeError(f"GOOGLE_SERVICE_ACCOUNT_JSON –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º JSON: {e}")
        creds = Credentials.from_service_account_info(info, scopes=[
            "https://www.googleapis.com/auth/spreadsheets",
            "https://www.googleapis.com/auth/drive",
        ])
    elif sa_path:
        p = Path(sa_path)
        if not p.exists():
            raise RuntimeError(f"–§–∞–π–ª –∫–ª—é—á–∞ service account –Ω–µ –Ω–∞–π–¥–µ–Ω: {sa_path}")
        creds = Credentials.from_service_account_file(str(p), scopes=[
            "https://www.googleapis.com/auth/spreadsheets",
            "https://www.googleapis.com/auth/drive",
        ])
    else:
        raise RuntimeError("–ù–µ –∑–∞–¥–∞–Ω—ã –∫—Ä–µ–¥—ã Google: –∑–∞–¥–∞–π—Ç–µ GOOGLE_SERVICE_ACCOUNT_JSON –∏–ª–∏ GOOGLE_APPLICATION_CREDENTIALS/GOOGLE_SERVICE_ACCOUNT_FILE")

    gc = gspread.authorize(creds)
    sh = gc.open_by_key(sheet_id)
    try:
        ws = sh.worksheet(ws_name)
    except Exception:
        ws = sh.add_worksheet(title=ws_name, rows=1000, cols=20)

    header = ["timestamp", "user_id", "username", "case_no", "stage", "element", "marks_axes", "defects", "works"]
    # if sheet is empty, put header
    try:
        first = ws.row_values(1)
    except Exception:
        first = []
    if not first:
        ws.append_row(header, value_input_option="USER_ENTERED")

    values = [row.get(k, "") for k in header]
    ws.append_row(values, value_input_option="USER_ENTERED")
    return getattr(sh, "url", f"https://docs.google.com/spreadsheets/d/{sheet_id}/edit")


def cnil_save_row(row: dict) -> dict:
    """
    Save CNIL record:
      1) Google Sheets (if creds provided)
      2) Local Excel fallback (/data/cnil_results.xlsx)
    Returns:
      {"backend":"gsheet","url": "..."} or {"backend":"excel","path": "..."}
    """
    prefer_gs = os.getenv("CNIL_SAVE_TO_GSHEETS", "1") not in ("0", "false", "False", "no", "NO")
    if prefer_gs:
        try:
            url = cnil_append_to_gsheet(row)
            return {"backend": "gsheet", "url": url}
        except Exception:
            logging.exception("[CNIL] failed to save to Google Sheets, falling back to local Excel")

    out_path = cnil_results_path()
    if out_path.exists():
        df_old = pd.read_excel(out_path)
        df_new = pd.concat([df_old, pd.DataFrame([row])], ignore_index=True)
    else:
        df_new = pd.DataFrame([row])
    df_new.to_excel(out_path, index=False)
    return {"backend": "excel", "path": str(out_path)}


def cnil_ensure_results_file(path: Path) -> None:
    """–°–æ–∑–¥–∞—ë—Ç —Ñ–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¶–ù–ò–õ —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏, –µ—Å–ª–∏ –æ–Ω –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç."""
    if path.exists():
        return
    df = pd.DataFrame(
        columns=[
            "ts",
            "user_id",
            "username",
            "full_name",
            "case_no",
            "stage",
            "element",
            "marks_axes",
            "defects",
            "works",
        ]
    )
    df.to_excel(path, index=False)


def cnil_pretty_export(src: Path, dst: Path) -> None:
    """–î–µ–ª–∞–µ—Ç '–∫—Ä–∞—Å–∏–≤—É—é' –≤—ã–≥—Ä—É–∑–∫—É: —à–∞–ø–∫–∞, —Ñ–∏–ª—å—Ç—Ä—ã, –∑–∞–∫—Ä–µ–ø–ª–µ–Ω–∏–µ, —à–∏—Ä–∏–Ω—ã, –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫."""
    from openpyxl import load_workbook
    from openpyxl.styles import Font, Alignment, PatternFill

    wb = load_workbook(src)
    ws = wb.active

    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    header_fill = PatternFill("solid", fgColor="F2F2F2")
    header_font = Font(bold=True)
    header_align = Alignment(horizontal="center", vertical="center", wrap_text=True)
    for cell in ws[1]:
        cell.fill = header_fill
        cell.font = header_font
        cell.alignment = header_align

    ws.freeze_panes = "A2"
    ws.auto_filter.ref = ws.dimensions

    # –ü–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫ –¥–ª—è 'defects' –∏ 'works' + –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –ø–æ –≤–µ—Ä—Ö–Ω–µ–º—É –∫—Ä–∞—é
    wrap_top = Alignment(vertical="top", wrap_text=True)
    max_row = ws.max_row
    max_col = ws.max_column
    for r in range(2, max_row + 1):
        for c in range(1, max_col + 1):
            ws.cell(row=r, column=c).alignment = wrap_top

    # –ê–≤—Ç–æ-—à–∏—Ä–∏–Ω—ã (—Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º)
    for col_cells in ws.columns:
        col_letter = col_cells[0].column_letter
        max_len = 0
        for cell in col_cells:
            v = cell.value
            if v is None:
                continue
            s = str(v)
            if len(s) > max_len:
                max_len = len(s)
        ws.column_dimensions[col_letter].width = max(10, min(60, max_len + 2))

    wb.save(dst)


async def cnil_send_results_excel(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ñ–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¶–ù–ò–õ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é (–ø–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–∞—Ä–æ–ª—è)."""
    src = Path(DATA_DIR) / "cnil_results.xlsx"
    cnil_ensure_results_file(src)

    # –§–æ—Ä–º–∏—Ä—É–µ–º '–∫—Ä–∞—Å–∏–≤—É—é' –∫–æ–ø–∏—é –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è (—á—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å —Ñ–∞–π–ª, –∫–æ—Ç–æ—Ä—ã–π –¥–æ–ø–∏—Å—ã–≤–∞–µ–º)
    dst = Path(DATA_DIR) / "cnil_results_pretty.xlsx"
    try:
        cnil_pretty_export(src, dst)
        send_path = dst
    except Exception:
        # –µ—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å ‚Äî –æ—Ç–ø—Ä–∞–≤–∏–º –∏—Å—Ö–æ–¥–Ω–∏–∫
        send_path = src

    await update.message.reply_document(
        document=open(send_path, "rb"),
        filename="cnil_results.xlsx",
        caption=(
            "üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¶–ù–ò–õ\n"
            "–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–º–∏ –∑–∞—è–≤–∫–∞–º–∏."
        ),
        reply_markup=cnil_menu_keyboard(),
    )


def cnil_find_excel() -> Optional[Path]:
    """
    –ò—â–µ–º —Ñ–∞–π–ª —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞ –≤ —Ç–∏–ø–æ–≤—ã—Ö –º–µ—Å—Ç–∞—Ö.
    """
    candidates = [
        Path(os.getenv("CNIL_XLSX", "")) if os.getenv("CNIL_XLSX") else None,
        Path("/data/–ß–µ–∫-–ª–∏—Å—Ç –ì–°–ù-–¶–ù–ò–õ.xlsx"),
        Path("/app/–ß–µ–∫-–ª–∏—Å—Ç –ì–°–ù-–¶–ù–ò–õ.xlsx"),
        Path("–ß–µ–∫-–ª–∏—Å—Ç –ì–°–ù-–¶–ù–ò–õ.xlsx"),
    ]
    for c in candidates:
        if c and c.exists():
            return c
    return None

def cnil_load_catalog() -> dict:
    """
    –°—Ç—Ä–æ–∏–º –∏–µ—Ä–∞—Ä—Ö–∏—é –∏–∑ Excel (–≤–∞—à —á–µ–∫-–ª–∏—Å—Ç):
    stage -> element -> defect -> list(works)

    –í–ê–ñ–ù–û: –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ –ø–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω—ã (5 –∫–æ–ª–æ–Ω–æ–∫),
    –ø–æ—ç—Ç–æ–º—É –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ, —á—Ç–æ–±—ã –∏—Å–∫–ª—é—á–∏—Ç—å –æ—à–∏–±–∫–∏
    —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º.
    –¢–∞–∫–∂–µ ¬´–¶–æ–∫–æ–ª—å¬ª –ø–æ –ª–æ–≥–∏–∫–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ —Ä–∞–∑–¥–µ–ª—É ¬´–§—É–Ω–¥–∞–º–µ–Ω—Ç¬ª,
    –ø–æ—ç—Ç–æ–º—É –º–∞–ø–ø–∏–º stage='–¶–æ–∫–æ–ª—å' -> stage='–§—É–Ω–¥–∞–º–µ–Ω—Ç'.
    """
    xlsx = cnil_find_excel()
    if not xlsx:
        return {}

    try:
        df = pd.read_excel(xlsx, sheet_name=0)
    except Exception:
        logging.exception("[CNIL] failed to read excel")
        return {}

    # –û–∂–∏–¥–∞–µ–º—ã–µ 5 –∫–æ–ª–æ–Ω–æ–∫ (–∫–∞–∫ –≤ —Ñ–∞–π–ª–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)
    if df.shape[1] < 5:
        logging.error("[CNIL] unexpected columns count: %s", df.shape[1])
        return {}

    # –ü–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ (–Ω–∞–¥–µ–∂–Ω–µ–µ, —á–µ–º fuzzy-–ø–æ–∏—Å–∫)
    col_stage = df.columns[0]
    col_elem  = df.columns[1]
    col_def   = df.columns[3]
    col_work  = df.columns[4]

    def clean(x) -> str:
        if x is None:
            return ""
        s = str(x).strip()
        if not s or s.lower() in ("nan", "none"):
            return ""
        # –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –Ω–æ–º–µ—Ä–∞ 1/2/3/4/5 –≤ –≤–µ—Ä—Ö–Ω–∏—Ö —Å—Ç—Ä–æ–∫–∞—Ö
        if re.fullmatch(r"\d+(?:\.\d+)?", s):
            return ""
        return s

    # ffill –¥–ª—è –º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã—Ö –±–ª–æ–∫–æ–≤
    df[col_stage] = df[col_stage].ffill()
    df[col_elem]  = df[col_elem].ffill()
    df[col_def]   = df[col_def].ffill()

    cat: dict = {}
    for _, r in df.iterrows():
        stage_raw = clean(r.get(col_stage))
        elem  = clean(r.get(col_elem))
        defect = clean(r.get(col_def))
        work  = clean(r.get(col_work))

        if not (stage_raw and elem and defect and work):
            continue

        # –ü–æ –¢–ó: ¬´–¶–æ–∫–æ–ª—å¬ª –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ ¬´–§—É–Ω–¥–∞–º–µ–Ω—Ç¬ª
        stage = "–§—É–Ω–¥–∞–º–µ–Ω—Ç" if stage_raw == "–¶–æ–∫–æ–ª—å" else stage_raw

        cat.setdefault(stage, {}).setdefault(elem, {}).setdefault(defect, set()).add(work)

    # set -> sorted list (—Å—Ç–∞–±–∏–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫)
    out: dict = {}
    for st, elems in cat.items():
        out[st] = {}
        for el, defects in elems.items():
            out[st][el] = {}
            for dfct, works in defects.items():
                out[st][el][dfct] = sorted(works)
    return out

CNIL_CATALOG = cnil_load_catalog()

def cnil_norm_case(text: str) -> Optional[str]:
    m = CNIL_CASE_RE.search(text or "")
    if not m:
        return None
    return f"{m.group(1)}-{m.group(2)}-{m.group(3)}"

def cnil_kb_list(items: list[str], prefix: str, page: int = 0, page_size: int = 8) -> InlineKeyboardMarkup:
    total = len(items)
    pages = max(1, (total + page_size - 1) // page_size)
    page = max(0, min(page, pages - 1))
    start = page * page_size
    chunk = items[start:start + page_size]

    rows = []
    for i, label in enumerate(chunk):
        rows.append([InlineKeyboardButton(label, callback_data=f"cnil:{prefix}:pick:{start+i}")])

    nav = []
    if pages > 1:
        if page > 0:
            nav.append(InlineKeyboardButton("‚¨ÖÔ∏è", callback_data=f"cnil:{prefix}:page:{page-1}"))
        nav.append(InlineKeyboardButton(f"{page+1}/{pages}", callback_data="cnil:noop"))
        if page < pages - 1:
            nav.append(InlineKeyboardButton("‚û°Ô∏è", callback_data=f"cnil:{prefix}:page:{page+1}"))
        rows.append(nav)

    rows.append([InlineKeyboardButton("‚úñÔ∏è –û—Ç–º–µ–Ω–∞", callback_data="cnil:cancel")])
    return InlineKeyboardMarkup(rows)

def cnil_kb_multi(items: list[str], selected: set[int], prefix: str, page: int = 0, page_size: int = 8) -> InlineKeyboardMarkup:
    total = len(items)
    pages = max(1, (total + page_size - 1) // page_size)
    page = max(0, min(page, pages - 1))
    start = page * page_size
    chunk = items[start:start + page_size]

    rows = []
    for i, label in enumerate(chunk):
        idx = start + i
        mark = "‚úÖ " if idx in selected else "‚¨úÔ∏è "
        rows.append([InlineKeyboardButton(mark + label, callback_data=f"cnil:{prefix}:toggle:{idx}")])

    nav = []
    if pages > 1:
        if page > 0:
            nav.append(InlineKeyboardButton("‚¨ÖÔ∏è", callback_data=f"cnil:{prefix}:page:{page-1}"))
        nav.append(InlineKeyboardButton(f"{page+1}/{pages}", callback_data="cnil:noop"))
        if page < pages - 1:
            nav.append(InlineKeyboardButton("‚û°Ô∏è", callback_data=f"cnil:{prefix}:page:{page+1}"))
        rows.append(nav)

    rows.append([
        InlineKeyboardButton("üßπ –°–±—Ä–æ—Å", callback_data=f"cnil:{prefix}:reset"),
        InlineKeyboardButton("–î–∞–ª–µ–µ ‚û°Ô∏è", callback_data=f"cnil:{prefix}:next"),
    ])
    rows.append([InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data=f"cnil:{prefix}:back")])
    rows.append([InlineKeyboardButton("‚úñÔ∏è –û—Ç–º–µ–Ω–∞", callback_data="cnil:cancel")])
    return InlineKeyboardMarkup(rows)

def cnil_menu_keyboard() -> ReplyKeyboardMarkup:
    return ReplyKeyboardMarkup(
        [
            ["üìù –ó–∞–ø–æ–ª–Ω–∏—Ç—å —Ñ–æ—Ä–º—É"],
            ["‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É"],
            ["üîê –ò–∑–º–µ–Ω–∏—Ç—å –ø–∞—Ä–æ–ª—å —Å–∫–∞—á–∏–≤–∞–Ω–∏—è"],
            ["‚¨ÖÔ∏è –ù–∞–∑–∞–¥"],
        ],
        resize_keyboard=True,
    )


async def cnil_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û—Ç–∫—Ä—ã—Ç—å —Ä–∞–∑–¥–µ–ª üß™ –¢–ó –¥–ª—è –¶–ù–ò–õ (–º–µ–Ω—é –¥–µ–π—Å—Ç–≤–∏–π)."""
    context.user_data.pop("cnil", None)
    context.user_data.pop("cnil_download_wait", None)
    context.user_data.pop("cnil_change_step", None)
    await update.message.reply_text(
        "üß™ *–¢–ó –¥–ª—è –¶–ù–ò–õ* ‚Äî –≤—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:",
        parse_mode="Markdown",
        reply_markup=cnil_menu_keyboard(),
    )


async def cnil_start_form(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # –∫–∞—Ç–∞–ª–æ–≥ –º–æ–∂–µ—Ç –Ω–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å—Å—è ‚Äî —Ç–æ–≥–¥–∞ –ø—Ä–µ–¥—É–ø—Ä–µ–¥–∏–º
    if not CNIL_CATALOG:
        await update.message.reply_text(
            "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –¶–ù–ò–õ –∏–∑ Excel.\n"
            "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª ¬´–ß–µ–∫-–ª–∏—Å—Ç –ì–°–ù-–¶–ù–ò–õ.xlsx¬ª –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –ø—Ä–æ–µ–∫—Ç–µ (–∫–æ—Ä–µ–Ω—å –∏–ª–∏ /data).\n\n"
            "–ü–æ–∫–∞ –º–∞—Å—Ç–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.",
            reply_markup=main_menu(),
        )
        return

    context.user_data["cnil"] = {
        "step": "case",
        "case_no": None,
        "stage": None,
        "element": None,
        "defects_selected": set(),
        "works_selected": set(),
        "work_marks": {},
        "work_marks_order": [],
        "work_marks_idx": 0,
        "page": 0,
        "items": {},
    }
    await update.message.reply_text(
        "1/5. –í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä –¥–µ–ª–∞ (—Ñ–æ—Ä–º–∞—Ç 00-00-000000):",
        reply_markup=main_menu(),  # –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é –ù–ï —É–±–∏—Ä–∞–µ–º
    )

async def cnil_text_step(update: Update, context: ContextTypes.DEFAULT_TYPE):
    st = context.user_data.get("cnil") or {}
    step = st.get("step")
    msg = (update.message.text or "").strip()

    if step == "case":
        case_no = cnil_norm_case(msg)
        if not case_no:
            await update.message.reply_text("–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç. –í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä –¥–µ–ª–∞: 00-00-000000")
            return
        st["case_no"] = case_no
        st["step"] = "stage"
        st["page"] = 0
        context.user_data["cnil"] = st

        stages = sorted(CNIL_CATALOG.keys())
        st["items"]["stage"] = stages
        kb = cnil_kb_list(stages, prefix="stage", page=0)
        await update.message.reply_text("2/5. –í—ã–±–µ—Ä–∏—Ç–µ —ç—Ç–∞–ø —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞:", reply_markup=kb)
        return

    if step == "work_marks":
        # –í–≤–æ–¥ "–û—Ç–º–µ—Ç–∫–∞ –û–°–ò, –≤—ã—Å–æ—Ç–Ω—ã–µ –æ—Ç–º–µ—Ç–∫–∏" –¥–ª—è –∫–∞–∂–¥–æ–π –≤—ã–±—Ä–∞–Ω–Ω–æ–π —Ä–∞–±–æ—Ç—ã (–º–æ–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å)
        order = st.get("work_marks_order") or []
        idx = int(st.get("work_marks_idx") or 0)

        if not order:
            st["step"] = "works"
            context.user_data["cnil"] = st
            await update.message.reply_text("–í—ã–±–µ—Ä–∏—Ç–µ –≤–∏–¥—ã —Ä–∞–±–æ—Ç –∫–Ω–æ–ø–∫–∞–º–∏ –ø–æ–¥ —Å–æ–æ–±—â–µ–Ω–∏–µ–º.")
            return

        if idx < 0:
            idx = 0
        if idx >= len(order):
            idx = len(order)

        if idx < len(order):
            work_name = order[idx]
            val = (update.message.text or "").strip()
            if val in ("-", "‚Äî", ""):
                val = ""
            st.setdefault("work_marks", {})[work_name] = val
            idx += 1
            st["work_marks_idx"] = idx
            context.user_data["cnil"] = st

            if idx < len(order):
                next_work = order[idx]
                await update.message.reply_text(
                    f"–†–∞–±–æ—Ç–∞: {next_work}\n–í–≤–µ–¥–∏—Ç–µ ¬´–û—Ç–º–µ—Ç–∫–∞ –û–°–ò, –≤—ã—Å–æ—Ç–Ω—ã–µ –æ—Ç–º–µ—Ç–∫–∏¬ª (–º–æ–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å):",
                    reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("‚úñÔ∏è –û—Ç–º–µ–Ω–∞", callback_data="cnil:cancel")]]),
                )
                return

        # --- –í—Å–µ –æ—Ç–º–µ—Ç–∫–∏ —Å–æ–±—Ä–∞–Ω—ã: —Ñ–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—É—é –∑–∞–ø–∏—Å—å –∏ –¥–æ–∫—É–º–µ–Ω—Ç ---
        user = update.effective_user
        stage = st.get("stage")
        element = st.get("element")
        case_no = st.get("case_no")

        defects_all = st.get("items", {}).get("defects", [])
        defects_sel = st.get("defects_selected") or set()
        defects = [defects_all[i] for i in sorted(defects_sel)] if defects_all else []

        works_all = st.get("items", {}).get("works", [])
        works_sel = st.get("works_selected") or set()
        works = [works_all[i] for i in sorted(works_sel)] if works_all else order

        wm = st.get("work_marks") or {}
        marks_axes = "\n".join([f"{w}: {wm.get(w, '')}".rstrip() for w in works]).strip()

        row = {
            "ts": datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S"),
            "user_id": user.id if user else "",
            "username": (user.username or "") if user else "",
            "full_name": f"{(user.first_name or '')} {(user.last_name or '')}".strip() if user else "",
            "case_no": case_no,
            "stage": stage,
            "element": element,
            "marks_axes": marks_axes,
            "defects": "; ".join(defects),
            "works": "; ".join(works),
            "work_marks": wm,
        }

        try:
            save_info = cnil_save_row(row)
        except Exception as e:
            await update.message.reply_text(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {e}")
            context.user_data.pop("cnil", None)
            return

        target_line = (
            f"Google Sheets: {save_info.get('url')}" if save_info.get("backend") == "gsheet" else f"–§–∞–π–ª (fallback): {save_info.get('path')}"
        )

        summary = (
            "‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ.\n\n"
            f"–ù–æ–º–µ—Ä –¥–µ–ª–∞: {case_no}\n"
            f"–≠—Ç–∞–ø: {stage}\n"
            f"–≠–ª–µ–º–µ–Ω—Ç: {element}\n"
            "–û—Ç–º–µ—Ç–∫–∞ –û–°–ò, –≤—ã—Å–æ—Ç–Ω—ã–µ –æ—Ç–º–µ—Ç–∫–∏:\n"
            f"{marks_axes or '-'}\n"
            f"–î–µ—Ñ–µ–∫—Ç—ã: {', '.join(defects) if defects else '-'}\n"
            f"–†–∞–±–æ—Ç—ã: {', '.join(works) if works else '-'}\n\n"
            f"{target_line}"
        )

        await update.message.reply_text(summary)

        try:
            docx_path = cnil_generate_t3_docx(row)
            with open(docx_path, "rb") as f:
                await context.bot.send_document(
                    chat_id=update.effective_chat.id,
                    document=InputFile(f, filename=os.path.basename(docx_path)),
                    caption="–¢–ó (TEST_T3) ‚Äî –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç",
                )
        except Exception as e:
            await context.bot.send_message(chat_id=update.effective_chat.id, text=f"‚ö†Ô∏è –î–æ–∫—É–º–µ–Ω—Ç TEST_T3 –Ω–µ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω: {e}")

        context.user_data.pop("cnil", None)
        return


        return

    # –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–∏—à–µ—Ç –≤–æ –≤—Ä–µ–º—è –≤—ã–±–æ—Ä–∞ –∫–Ω–æ–ø–∫–∞–º–∏ ‚Äî –º—è–≥–∫–æ –ø–æ–¥—Å–∫–∞–∂–µ–º
    if step in ("stage", "element", "defects", "works"):
        await update.message.reply_text("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –ø–æ–¥ —Å–æ–æ–±—â–µ–Ω–∏–µ–º –¥–ª—è –≤—ã–±–æ—Ä–∞.")
        return

async def cnil_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    q = update.callback_query
    data = q.data or ""
    st = context.user_data.get("cnil") or {}
    step = st.get("step")

    if data == "cnil:noop":
        await q.answer()
        return

    if data == "cnil:cancel":
        context.user_data.pop("cnil", None)
        await q.edit_message_text("–ú–∞—Å—Ç–µ—Ä ¬´–¢–ó –¥–ª—è –¶–ù–ò–õ¬ª –æ—Ç–º–µ–Ω—ë–Ω.", reply_markup=None)
        return

    parts = data.split(":")
    # cnil:<scope>:<action>:<value?>
    if len(parts) < 3:
        await q.answer()
        return

    scope = parts[1]
    action = parts[2]
    value = parts[3] if len(parts) > 3 else None

    # ---------- –≠–¢–ê–ü ----------
    if scope == "stage":
        items = st.get("items", {}).get("stage", [])
        if action == "page" and value is not None:
            page = int(value)
            kb = cnil_kb_list(items, prefix="stage", page=page)
            await q.edit_message_reply_markup(reply_markup=kb)
            return
        if action == "pick" and value is not None:
            idx = int(value)
            if idx < 0 or idx >= len(items):
                await q.answer()
                return
            stage = items[idx]
            st["stage"] = stage
            st["step"] = "element"
            st["page"] = 0

            elements = sorted(CNIL_CATALOG.get(stage, {}).keys())
            st["items"]["element"] = elements
            context.user_data["cnil"] = st

            kb = cnil_kb_list(elements, prefix="element", page=0)
            await q.edit_message_text(f"–í—ã–±—Ä–∞–Ω —ç—Ç–∞–ø: {stage}\n\n3/5. –í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç:", reply_markup=kb)
            return

    # ---------- –≠–õ–ï–ú–ï–ù–¢ ----------
    if scope == "element":
        items = st.get("items", {}).get("element", [])
        if action == "page" and value is not None:
            page = int(value)
            kb = cnil_kb_list(items, prefix="element", page=page)
            await q.edit_message_reply_markup(reply_markup=kb)
            return
        if action == "pick" and value is not None:
            idx = int(value)
            if idx < 0 or idx >= len(items):
                await q.answer()
                return
            element = items[idx]
            st["element"] = element
            # –≥–æ—Ç–æ–≤–∏–º –¥–µ—Ñ–µ–∫—Ç—ã –ø–æ —Å–≤—è–∑–∫–µ —ç—Ç–∞–ø+—ç–ª–µ–º–µ–Ω—Ç
            stage = st.get("stage")
            defects = sorted(CNIL_CATALOG.get(stage, {}).get(element, {}).keys())
            st["items"]["defects"] = defects
            st["defects_selected"] = set()
            st["page"] = 0
            st["step"] = "defects"
            context.user_data["cnil"] = st

            kb = cnil_kb_multi(defects, st["defects_selected"], prefix="defects", page=0)
            await q.edit_message_text(
                f"–í—ã–±—Ä–∞–Ω —ç–ª–µ–º–µ–Ω—Ç: {element}\n\n4/6. –í—ã–±–µ—Ä–∏—Ç–µ –¥–µ—Ñ–µ–∫—Ç—ã (–º–æ–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ):",
                reply_markup=kb,
            )
            return

    # ---------- –î–ï–§–ï–ö–¢–´ (–º—É–ª—å—Ç–∏) ----------
    if scope == "defects":
        items = st.get("items", {}).get("defects", [])
        selected: set[int] = st.get("defects_selected") or set()
        if action == "page" and value is not None:
            page = int(value)
            kb = cnil_kb_multi(items, selected, prefix="defects", page=page)
            await q.edit_message_reply_markup(reply_markup=kb)
            return
        if action == "toggle" and value is not None:
            idx = int(value)
            if 0 <= idx < len(items):
                if idx in selected:
                    selected.remove(idx)
                else:
                    selected.add(idx)
                st["defects_selected"] = selected
                context.user_data["cnil"] = st
            kb = cnil_kb_multi(items, selected, prefix="defects", page=st.get("page", 0))
            await q.edit_message_reply_markup(reply_markup=kb)
            return
        if action == "reset":
            st["defects_selected"] = set()
            context.user_data["cnil"] = st
            kb = cnil_kb_multi(items, set(), prefix="defects", page=0)
            await q.edit_message_reply_markup(reply_markup=kb)
            return
        if action == "back":
            st["step"] = "element"
            stage = st.get("stage")
            elements = sorted(CNIL_CATALOG.get(stage, {}).keys())
            st["items"]["element"] = elements
            st["page"] = 0
            context.user_data["cnil"] = st

            kb = cnil_kb_list(elements, prefix="element", page=0)
            await q.edit_message_text(
                f"–í—ã–±—Ä–∞–Ω —ç—Ç–∞–ø: {stage}\n\n3/6. –í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç:",
                reply_markup=kb,
            )
            return
        if action == "next":
            if not selected:
                await q.answer("–í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –¥–µ—Ñ–µ–∫—Ç", show_alert=True)
                return
            # —Ñ–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ —Ä–∞–±–æ—Ç –∫–∞–∫ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –¥–µ—Ñ–µ–∫—Ç–∞–º
            stage = st.get("stage")
            element = st.get("element")
            defect_names = [items[i] for i in sorted(selected)]
            works_set = set()
            for dname in defect_names:
                works_set.update(CNIL_CATALOG.get(stage, {}).get(element, {}).get(dname, []))
            works = sorted(list(works_set))

            st["items"]["works"] = works
            st["works_selected"] = set()
            st["step"] = "works"
            st["page"] = 0
            context.user_data["cnil"] = st

            kb = cnil_kb_multi(works, set(), prefix="works", page=0)
            await q.edit_message_text("5/5. –í—ã–±–µ—Ä–∏—Ç–µ –≤–∏–¥—ã —Ä–∞–±–æ—Ç (–º–æ–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ):", reply_markup=kb)
            return

    # ---------- –†–ê–ë–û–¢–´ (–º—É–ª—å—Ç–∏) ----------
    if scope == "works":
        items = st.get("items", {}).get("works", [])
        selected: set[int] = st.get("works_selected") or set()
        if action == "page" and value is not None:
            page = int(value)
            kb = cnil_kb_multi(items, selected, prefix="works", page=page)
            await q.edit_message_reply_markup(reply_markup=kb)
            return
        if action == "toggle" and value is not None:
            idx = int(value)
            if 0 <= idx < len(items):
                if idx in selected:
                    selected.remove(idx)
                else:
                    selected.add(idx)
                st["works_selected"] = selected
                context.user_data["cnil"] = st
            kb = cnil_kb_multi(items, selected, prefix="works", page=st.get("page", 0))
            await q.edit_message_reply_markup(reply_markup=kb)
            return
        if action == "reset":
            st["works_selected"] = set()
            context.user_data["cnil"] = st
            kb = cnil_kb_multi(items, set(), prefix="works", page=0)
            await q.edit_message_reply_markup(reply_markup=kb)
            return
        if action == "back":
            st["step"] = "defects"
            context.user_data["cnil"] = st
            defects = st["items"].get("defects", [])
            kb = cnil_kb_multi(defects, st.get("defects_selected") or set(), prefix="defects", page=0)
            await q.edit_message_text("4/5. –í—ã–±–µ—Ä–∏—Ç–µ –¥–µ—Ñ–µ–∫—Ç—ã (–º–æ–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ):", reply_markup=kb)
            return
        if action == "next":
            if not selected:
                await q.answer("–í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –≤–∏–¥ —Ä–∞–±–æ—Ç", show_alert=True)
                return

            works = [items[i] for i in sorted(selected)]

            st["works_selected"] = selected
            st["work_marks"] = {}
            st["work_marks_order"] = works
            st["work_marks_idx"] = 0
            st["step"] = "work_marks"
            context.user_data["cnil"] = st

            first = works[0]
            await q.edit_message_text(
                f"–†–∞–±–æ—Ç–∞: {first}\n–í–≤–µ–¥–∏—Ç–µ ¬´–û—Ç–º–µ—Ç–∫–∞ –û–°–ò, –≤—ã—Å–æ—Ç–Ω—ã–µ –æ—Ç–º–µ—Ç–∫–∏¬ª (–º–æ–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å):",
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("‚úñÔ∏è –û—Ç–º–µ–Ω–∞", callback_data="cnil:cancel")]]),
            )
            return

    await q.answer()



async def error_handler(update: object, context: ContextTypes.DEFAULT_TYPE) -> None:
    # Prevent unhandled exceptions from crashing update processing
    logging.exception("Unhandled exception while handling update", exc_info=context.error)

def main():
    if not BOT_TOKEN:
        log.error("BOT_TOKEN –Ω–µ –∑–∞–¥–∞–Ω.")
        raise SystemExit("–£–∫–∞–∂–∏—Ç–µ BOT_TOKEN –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.")

    init_db()

    app = Application.builder().token(BOT_TOKEN).build()
    app.add_error_handler(error_handler)

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_command))

    app.add_handler(CallbackQueryHandler(callback_handler))

    app.add_handler(MessageHandler(filters.VOICE, voice_router))

    app.add_handler(MessageHandler(filters.Document.ALL, document_handler))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, text_router))

    log.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω...")
    app.run_polling()


if __name__ == "__main__":
    main()
